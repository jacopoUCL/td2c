{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative TD2C Comparison with Benchmark Methods\n",
    "\n",
    "This notebook presents a comparative analysis between an Iterative implementation of the `TD2C` method and several benchmark approaches. The `TD2C` algorithm is extended in this work through an iterative process that refines its performance by leveraging dynamic feature selection and causal graph construction.\n",
    "\n",
    "The proposed Iterative `TD2C` method involves the following steps:\n",
    "\n",
    "1. **Model Training and Initial Causal Discovery**: The model is initially trained, and the TD2C algorithm is applied to identify the top K causal connections.\n",
    "2. **Graph Construction**: A causal graph is constructed based on the identified connections.\n",
    "3. **Historical Extension**: The graph is extended to include past states, reflecting the progression from past to present.\n",
    "4. **Application of Meek Rules**: The graph is refined using Meek's Rules to ensure proper orientation of edges and to derive causal implications.\n",
    "5. **Missing Pair Identification and Markov Blanket Derivation**: Missing causal pairs are identified, and the Markov Blanket (MB) is derived if possible from the current graph structure.\n",
    "6. **Descriptor Recalculation**: Descriptors are recalculated using the derived MB, providing refined inputs for subsequent iterations.\n",
    "\n",
    "Through this iterative process, the TD2C method is expected to enhance its accuracy in detecting causal structures, making it a robust tool for temporal causal discovery. The effectiveness of this approach will be evaluated against benchmark methods identified from previous analyses, specifically from the `Compare_TD2C_MB_Strategies` notebook, to assess its performance improvements in terms of ROC-AUC, Precision, Recall adn F1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import pickle \n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from d2c.data_generation.builder import TSBuilder\n",
    "from d2c.descriptors_generation import D2C, DataLoader\n",
    "from d2c.benchmark import D2CWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_JOBS = 40 # number of jobs to run in parallel. For D2C, parallelism is implemented at the observation level: each observation from a single file is processed in parallel\n",
    "SEED = 42 # random seed for reproducibility\n",
    "MB_SIZE = 2 # size to consider when estimating the markov blanket. This is only useful if the MB is actually estimated\n",
    "COUPLES_TO_CONSIDER_PER_DAG = -1 # edges that are considered in total to compute descriptors, for each TS. This can speed up the process. If set to -1, all possible edges are considered\n",
    "maxlags = 5 # maximum lags to consider when considering variable couples\n",
    "noise_std_filter = 0.01  # Example noise standard deviation to filter\n",
    "max_neighborhood_size_filter = 2  # Example filter for neighborhood size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation\n",
    "Data are generated with the `TSBuilder` class and saved in a specific folder. Then, the code checks for missing datasets in the folder and keeps running untill all the possible combinations of parameters have genereted a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET THE TSBUILDER WITH THE DESIRED PARAMETERS\n",
    "def run_process(params):\n",
    "    \"\"\"\n",
    "    Run a single process of the data generation.\n",
    "    \"\"\"\n",
    "    process, n_variables, max_neighborhood_size, noise_std = params\n",
    "    try:\n",
    "        tsbuilder = TSBuilder(observations_per_time_series=250, \n",
    "                              maxlags=5, \n",
    "                              n_variables=n_variables, \n",
    "                              time_series_per_process=40, \n",
    "                              processes_to_use=[process], \n",
    "                              noise_std=noise_std, \n",
    "                              max_neighborhood_size=max_neighborhood_size, \n",
    "                              seed=42, \n",
    "                              max_attempts=200,\n",
    "                              verbose=True)\n",
    "\n",
    "        tsbuilder.build()\n",
    "        tsbuilder.to_pickle(f'/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/P{process}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std}.pkl')\n",
    "        print(f'P{process}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std} done')\n",
    "    except ValueError as e:\n",
    "        print(f'P{process}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std} failed: {e}')\n",
    "\n",
    "# BUILD THE DATA\n",
    "if __name__ == '__main__':\n",
    "    \"\"\"\n",
    "    This script generates the data for different parameters: processes, number of variables, neighborhood sizes and noise levels.\n",
    "    The data is saved in the .data folder.\n",
    "    The if __name__ == '__main__': is used to avoid multiprocessing issues in Jupyter notebooks, i.e. the script is run as a script and not\n",
    "    as a module as it would have been if the script was imported, with the __name__ being the name of the module.\n",
    "    If the script is imported, the __name__ is the name of the module, if it is run as a script, the __name__ is __main__.\n",
    "    So, to run this script in a Jupyter notebook, we write the code inside the if __name__ == '__main__': block, while, if we want to import\n",
    "    the functions from this script, we write \"from script import run_process\".\n",
    "    \"\"\"\n",
    "    parameters = [(process, n_variables, max_neighborhood_size, noise_std)\n",
    "                    for process in [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20] # \n",
    "                    for n_variables in [5] # , 10, 25\n",
    "                    for max_neighborhood_size in [2] # , 4, 8\n",
    "                    for noise_std in [0.01]] # , 0.005, 0.001\n",
    "\n",
    "    with Pool(processes=N_JOBS) as pool:\n",
    "        pool.map(run_process, parameters)\n",
    "\n",
    "\n",
    "# Function to check for missing files\n",
    "def check_missing_files():\n",
    "    missing = []\n",
    "    for process in [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20]:  # \n",
    "        for n_variables in [5]:  # , 10, 25\n",
    "            for max_neighborhood_size in [2]:  # , 4, 8\n",
    "                for noise_std in [0.01]:  # , 0.005, 0.001\n",
    "                    filename = f'/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/P{process}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std}.pkl'\n",
    "                    if not os.path.exists(filename):\n",
    "                        missing.append(filename)\n",
    "    return missing\n",
    "\n",
    "# Function to run the process\n",
    "def run_process(params):\n",
    "    process, n_variables, max_neighborhood_size, noise_std = params\n",
    "    try:  # we change the seed and increase the max_attempts\n",
    "        tsbuilder = TSBuilder(observations_per_time_series=250, \n",
    "                              maxlags=5, \n",
    "                              n_variables=n_variables, \n",
    "                              time_series_per_process=40, \n",
    "                              processes_to_use=[process], \n",
    "                              noise_std=noise_std, \n",
    "                              max_neighborhood_size=max_neighborhood_size, \n",
    "                              seed=24, \n",
    "                              max_attempts=400,\n",
    "                              verbose=True)\n",
    "\n",
    "        tsbuilder.build()\n",
    "        tsbuilder.to_pickle(f'/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/P{process}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std}.pkl')\n",
    "        print(f'P{process}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std} done')\n",
    "    except ValueError as e:\n",
    "        print(f'P{process}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std} failed: {e}')\n",
    "\n",
    "# CHECK FOR MISSING FILES (IT CHEKS THE FILES WITH A DIFFERENT SEED AND MORE MAX_ATTEMPTS UNTILL MISSING IS EMPTY)\n",
    "if __name__ == '__main__':\n",
    "    while True:\n",
    "        missing = check_missing_files()\n",
    "        if not missing:\n",
    "            break\n",
    "\n",
    "        parameters = []\n",
    "        for missing_file in missing:\n",
    "            process = int(missing_file.split('/')[-1].split('_')[0][1:])\n",
    "            n_variables = int(missing_file.split('/')[-1].split('_')[1][1:])\n",
    "            max_neighborhood_size = int(missing_file.split('/')[-1].split('_')[2][2:])\n",
    "            noise_std = float(missing_file.split('/')[-1].split('_')[3][1:-4])\n",
    "            parameters.append((process, n_variables, max_neighborhood_size, noise_std))\n",
    "\n",
    "        with Pool(processes=N_JOBS) as pool:\n",
    "            pool.map(run_process, parameters)\n",
    "\n",
    "len(os.listdir('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptors Generation & Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Estimation of MI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D2C (& D2C but without contemporaneous nodes) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptors Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################### SETTING FOR DESCRIPTORS COMPUTATION ######################################################\n",
    "\n",
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "\n",
    "to_process = [] # list of files to process\n",
    "\n",
    "# This loop is used to filter the files to process and obtain the parameters of the process\n",
    "# The resulting list will be used to parallelize the process and will be passed to the DataLoader.\n",
    "# The result is of the form (file, gen_process_number, n_variables, max_neighborhood_size, noise_std)\n",
    "# asnd is saved in the to_process list.\n",
    "for file in sorted(os.listdir(input_folder)): \n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    if noise_std != 0.01:\n",
    "        continue\n",
    "    \n",
    "    if max_neighborhood_size != 2:\n",
    "        continue\n",
    "\n",
    "    # if n_variables != 5:\n",
    "    #     continue\n",
    "\n",
    "    to_process.append(file)\n",
    "\n",
    "\n",
    "############################################################### COMPUTE DESCRIPTORS ################################################################\n",
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/D2C/'  \n",
    "\n",
    "# create output folder if it does not exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# This loop processes the files in the input folder (to_process) and saves the descriptors in the output folder.\n",
    "\n",
    "# At first, we collect the parameters of the process from the file name.\n",
    "for file in tqdm(to_process):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "# The DataLoader is initialized with the parameters of the process. \n",
    "    dataloader = DataLoader(n_variables = n_variables,\n",
    "                    maxlags = maxlags)\n",
    "    dataloader.from_pickle(input_folder+file)\n",
    "\n",
    "# The D2C object is initialized with the DataLoader and the parameters of the process.\n",
    "    d2c = D2C(observations=dataloader.get_observations(), \n",
    "            dags=dataloader.get_dags(), \n",
    "            couples_to_consider_per_dag=COUPLES_TO_CONSIDER_PER_DAG, \n",
    "            MB_size=MB_SIZE, \n",
    "            n_variables=n_variables, \n",
    "            maxlags=maxlags,\n",
    "            seed=SEED,\n",
    "            n_jobs=N_JOBS,\n",
    "            full=True,\n",
    "            quantiles=True,\n",
    "            normalize=True,\n",
    "            cmi='original',\n",
    "            mb_estimator= 'original',\n",
    "            top_vars=3)\n",
    "\n",
    "    d2c.initialize() # initializes the D2C object\n",
    "\n",
    "    descriptors_df = d2c.get_descriptors_df()  # computes the descriptors\n",
    "\n",
    "    descriptors_df.insert(0, 'process_id', gen_process_number)\n",
    "    descriptors_df.insert(2, 'n_variables', n_variables)\n",
    "    descriptors_df.insert(3, 'max_neighborhood_size', max_neighborhood_size)\n",
    "    descriptors_df.insert(4, 'noise_std', noise_std)\n",
    "\n",
    "    # The descriptors are saved in the output folder as a pickle file.\n",
    "    descriptors_df.to_pickle(output_folder+f'P{gen_process_number}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std}_MB{MB_SIZE}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "\n",
    "to_dos = []\n",
    "\n",
    "# This loop gets a list of all the files to be processed\n",
    "for testing_file in sorted(os.listdir(data_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "          \n",
    "        if noise_std != 0.01: # if the noise is different we skip the file\n",
    "            continue\n",
    "\n",
    "        if max_neighborhood_size != 2: # if the max_neighborhood_size is different we skip the file\n",
    "            continue\n",
    "\n",
    "        to_dos.append(testing_file) # we add the file to the list (to_dos) to be processed\n",
    "\n",
    "# sort to_dos by number of variables\n",
    "to_dos_5_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 5]\n",
    "# to_dos_10_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 10]\n",
    "# to_dos_25_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 25]\n",
    "\n",
    "# we create a dictionary with the lists of files to be processed\n",
    "todos = {'5': to_dos_5_variables} # , '10': to_dos_10_variables, '25': to_dos_25_variables\n",
    "\n",
    "# we create a dictionary to store the results\n",
    "dfs = []\n",
    "descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/D2C/'\n",
    "\n",
    "# Re-save pickle files with protocol 4\n",
    "for testing_file in sorted(os.listdir(descriptors_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        file_path = os.path.join(descriptors_root, testing_file)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Re-save with protocol 4\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(data, f, protocol=4)\n",
    "\n",
    "# This loop gets the descriptors for the files to be processed\n",
    "for testing_file in sorted(os.listdir(descriptors_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        df = pd.read_pickle(os.path.join(descriptors_root, testing_file))\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            dfs.append(df)\n",
    "\n",
    "# we concatenate the descriptors\n",
    "descriptors_training = pd.concat(dfs, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loop does the following:\n",
    "# 1. Creates some dictionaries to store the results\n",
    "# 2. Loads the training data\n",
    "# 3. Trains the model\n",
    "# 4. Evaluates the model\n",
    "# 5. Stores the results in the dictionaries\n",
    "# 6. Saves the dictionaries in a pickle file\n",
    "\n",
    "for n_vars, todo in todos.items():\n",
    "    d2c_rocs_process = {}\n",
    "    d2c_precision_process = {}\n",
    "    d2c_recall_process = {}\n",
    "    d2c_f1_process = {}\n",
    "    for testing_file in tqdm(todo):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "\n",
    "        # split training and testing data\n",
    "        training_data = descriptors_training.loc[descriptors_training['process_id'] != gen_process_number]\n",
    "        X_train = training_data.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "        y_train = training_data['is_causal']\n",
    "\n",
    "        testing_data = descriptors_training.loc[(descriptors_training['process_id'] == gen_process_number) & (descriptors_training['n_variables'] == n_variables) & (descriptors_training['max_neighborhood_size'] == max_neighborhood_size) & (descriptors_training['noise_std'] == noise_std)]\n",
    "\n",
    "        model = BalancedRandomForestClassifier(n_estimators=100, random_state=0, n_jobs=50, max_depth=None, sampling_strategy='auto', replacement=True, bootstrap=False)\n",
    "        # model = RandomForestClassifier(n_estimators=50, random_state=0, n_jobs=50, max_depth=10)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        rocs = {}\n",
    "        precisions = {}\n",
    "        recalls = {}\n",
    "        f1s = {}\n",
    "        for graph_id in range(40):\n",
    "            #load testing descriptors\n",
    "            test_df = testing_data.loc[testing_data['graph_id'] == graph_id]\n",
    "            test_df = test_df.sort_values(by=['edge_source','edge_dest']).reset_index(drop=True) # sort for coherence\n",
    "\n",
    "            X_test = test_df.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "            y_test = test_df['is_causal']\n",
    "\n",
    "            y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            roc = roc_auc_score(y_test, y_pred_proba)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            \n",
    "            rocs[graph_id] = roc\n",
    "            precisions[graph_id] = precision\n",
    "            recalls[graph_id] = recall\n",
    "            f1s[graph_id] = f1\n",
    "\n",
    "        d2c_rocs_process[gen_process_number] = rocs\n",
    "        d2c_precision_process[gen_process_number] = precisions\n",
    "        d2c_recall_process[gen_process_number] = recalls\n",
    "        d2c_f1_process[gen_process_number] = f1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle everything\n",
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/journals/'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "with open(os.path.join(output_folder, f'journal_results_d2c_R_N5.pkl'), 'wb') as f:\n",
    "    everything = (d2c_rocs_process, d2c_precision_process, d2c_recall_process, d2c_f1_process)\n",
    "    pickle.dump(everything, f)\n",
    "\n",
    "# with open(os.path.join(output_folder, f'journal_results_d2c_R_N10.pkl'), 'wb') as f:\n",
    "#     everything = (d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process)\n",
    "#     pickle.dump(everything, f)\n",
    "\n",
    "# with open(os.path.join(output_folder, f'journal_results_d2c_R_N25.pkl'), 'wb') as f:\n",
    "#     everything = (d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process)\n",
    "#     pickle.dump(everything, f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################### LOAD DATA #####################################################################\n",
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/journals/'\n",
    "\n",
    "with open(os.path.join(input_folder, 'journal_results_d2c_R_N5.pkl'), 'rb') as f:\n",
    "    D2C_rocs_process, D2C_precision_process, D2C_recall_process, D2C_f1_process = pickle.load(f)\n",
    "\n",
    "# with open(os.path.join(input_folder, 'journal_results_d2c_R_N10.pkl'), 'rb') as f:\n",
    "#     d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process = pickle.load(f)\n",
    "\n",
    "# with open(os.path.join(input_folder, 'journal_results_d2c_R_N25.pkl'), 'rb') as f:\n",
    "#     d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process = pickle.load(f)\n",
    "\n",
    "\n",
    "##################################################################### PLOT #########################################################################\n",
    "\n",
    "df1 = pd.DataFrame(D2C_rocs_process)\n",
    "\n",
    "# Combine data for boxplot\n",
    "combined_data = []\n",
    "\n",
    "for col in df1.columns:\n",
    "    combined_data.append(df1[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns:\n",
    "    labels.append(f'{col} D2C_Reg')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title('Boxplot of ROC-AUC scores for D2C method with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('ROC-AUC score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD2C (& TD2C but without contrmporaneous nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptors Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################### SETTING FOR DESCRIPTORS COMPUTATION ######################################################\n",
    "\n",
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "\n",
    "to_process = [] # list of files to process\n",
    "\n",
    "# This loop is used to filter the files to process and obtain the parameters of the process\n",
    "# The resulting list will be used to parallelize the process and will be passed to the DataLoader.\n",
    "# The result is of the form (file, gen_process_number, n_variables, max_neighborhood_size, noise_std)\n",
    "# asnd is saved in the to_process list.\n",
    "for file in sorted(os.listdir(input_folder)): \n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    if noise_std != 0.01:\n",
    "        continue\n",
    "    \n",
    "    if max_neighborhood_size != 2:\n",
    "        continue\n",
    "\n",
    "    # if n_variables != 5:\n",
    "    #     continue\n",
    "\n",
    "    to_process.append(file)\n",
    "\n",
    "\n",
    "############################################################### COMPUTE DESCRIPTORS ################################################################\n",
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C/'  \n",
    "\n",
    "# create output folder if it does not exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# This loop processes the files in the input folder (to_process) and saves the descriptors in the output folder.\n",
    "\n",
    "# At first, we collect the parameters of the process from the file name.\n",
    "for file in tqdm(to_process):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "# The DataLoader is initialized with the parameters of the process. \n",
    "    dataloader = DataLoader(n_variables = n_variables,\n",
    "                    maxlags = maxlags)\n",
    "    dataloader.from_pickle(input_folder+file)\n",
    "\n",
    "# The D2C object is initialized with the DataLoader and the parameters of the process.\n",
    "    d2c = D2C(observations=dataloader.get_observations(), \n",
    "            dags=dataloader.get_dags(), \n",
    "            couples_to_consider_per_dag=COUPLES_TO_CONSIDER_PER_DAG, \n",
    "            MB_size=MB_SIZE, \n",
    "            n_variables=n_variables, \n",
    "            maxlags=maxlags,\n",
    "            seed=SEED,\n",
    "            n_jobs=N_JOBS,\n",
    "            full=True,\n",
    "            quantiles=True,\n",
    "            normalize=True,\n",
    "            cmi='original',\n",
    "            mb_estimator= 'ts',\n",
    "            top_vars=3)\n",
    "\n",
    "    d2c.initialize() # initializes the D2C object\n",
    "\n",
    "    descriptors_df = d2c.get_descriptors_df()  # computes the descriptors\n",
    "\n",
    "    descriptors_df.insert(0, 'process_id', gen_process_number)\n",
    "    descriptors_df.insert(2, 'n_variables', n_variables)\n",
    "    descriptors_df.insert(3, 'max_neighborhood_size', max_neighborhood_size)\n",
    "    descriptors_df.insert(4, 'noise_std', noise_std)\n",
    "\n",
    "    # The descriptors are saved in the output folder as a pickle file.\n",
    "    descriptors_df.to_pickle(output_folder+f'P{gen_process_number}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std}_MB{MB_SIZE}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "\n",
    "to_dos = []\n",
    "\n",
    "# This loop gets a list of all the files to be processed\n",
    "for testing_file in sorted(os.listdir(data_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "          \n",
    "        if noise_std != 0.01: # if the noise is different we skip the file\n",
    "            continue\n",
    "\n",
    "        if max_neighborhood_size != 2: # if the max_neighborhood_size is different we skip the file\n",
    "            continue\n",
    "\n",
    "        to_dos.append(testing_file) # we add the file to the list (to_dos) to be processed\n",
    "\n",
    "# sort to_dos by number of variables\n",
    "to_dos_5_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 5]\n",
    "# to_dos_10_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 10]\n",
    "# to_dos_25_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 25]\n",
    "\n",
    "# we create a dictionary with the lists of files to be processed\n",
    "todos = {'5': to_dos_5_variables} # , '10': to_dos_10_variables, '25': to_dos_25_variables\n",
    "\n",
    "# we create a dictionary to store the results\n",
    "dfs = []\n",
    "descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C/'\n",
    "\n",
    "# Re-save pickle files with protocol 4\n",
    "for testing_file in sorted(os.listdir(descriptors_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        file_path = os.path.join(descriptors_root, testing_file)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Re-save with protocol 4\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(data, f, protocol=4)\n",
    "\n",
    "# This loop gets the descriptors for the files to be processed\n",
    "for testing_file in sorted(os.listdir(descriptors_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        df = pd.read_pickle(os.path.join(descriptors_root, testing_file))\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            dfs.append(df)\n",
    "\n",
    "# we concatenate the descriptors\n",
    "descriptors_training = pd.concat(dfs, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loop does the following:\n",
    "# 1. Creates some dictionaries to store the results\n",
    "# 2. Loads the training data\n",
    "# 3. Trains the model\n",
    "# 4. Evaluates the model\n",
    "# 5. Stores the results in the dictionaries\n",
    "# 6. Saves the dictionaries in a pickle file\n",
    "\n",
    "for n_vars, todo in todos.items():\n",
    "    td2c_rocs_process = {}\n",
    "    td2c_precision_process = {}\n",
    "    td2c_recall_process = {}\n",
    "    td2c_f1_process = {}\n",
    "    for testing_file in tqdm(todo):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "\n",
    "        # split training and testing data\n",
    "        training_data = descriptors_training.loc[descriptors_training['process_id'] != gen_process_number]\n",
    "        X_train = training_data.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "        y_train = training_data['is_causal']\n",
    "\n",
    "        testing_data = descriptors_training.loc[(descriptors_training['process_id'] == gen_process_number) & (descriptors_training['n_variables'] == n_variables) & (descriptors_training['max_neighborhood_size'] == max_neighborhood_size) & (descriptors_training['noise_std'] == noise_std)]\n",
    "\n",
    "        model = BalancedRandomForestClassifier(n_estimators=100, random_state=0, n_jobs=50, max_depth=None, sampling_strategy='auto', replacement=True, bootstrap=False)\n",
    "        # model = RandomForestClassifier(n_estimators=50, random_state=0, n_jobs=50, max_depth=10)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        rocs = {}\n",
    "        precisions = {}\n",
    "        recalls = {}\n",
    "        f1s = {}\n",
    "        for graph_id in range(40):\n",
    "            #load testing descriptors\n",
    "            test_df = testing_data.loc[testing_data['graph_id'] == graph_id]\n",
    "            test_df = test_df.sort_values(by=['edge_source','edge_dest']).reset_index(drop=True) # sort for coherence\n",
    "\n",
    "            X_test = test_df.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "            y_test = test_df['is_causal']\n",
    "\n",
    "            y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            roc = roc_auc_score(y_test, y_pred_proba)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            \n",
    "            rocs[graph_id] = roc\n",
    "            precisions[graph_id] = precision\n",
    "            recalls[graph_id] = recall\n",
    "            f1s[graph_id] = f1\n",
    "\n",
    "        td2c_rocs_process[gen_process_number] = rocs\n",
    "        td2c_precision_process[gen_process_number] = precisions\n",
    "        td2c_recall_process[gen_process_number] = recalls\n",
    "        td2c_f1_process[gen_process_number] = f1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle everything\n",
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/journals/'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "with open(os.path.join(output_folder, f'journal_results_td2c_R_N5.pkl'), 'wb') as f:\n",
    "    everything = (td2c_rocs_process, td2c_precision_process, td2c_recall_process, td2c_f1_process)\n",
    "    pickle.dump(everything, f)\n",
    "\n",
    "# with open(os.path.join(output_folder, f'journal_results_td2c_R_N10.pkl'), 'wb') as f:\n",
    "#     everything = (td2c_R_rocs_process, td2c_R_precision_process, td2c_R_recall_process, td2c_R_f1_process)\n",
    "#     pickle.dump(everything, f)\n",
    "\n",
    "# with open(os.path.join(output_folder, f'journal_results_td2c_R_N25.pkl'), 'wb') as f:\n",
    "#     everything = (td2c_R_rocs_process, td2c_R_precision_process, td2c_R_recall_process, td2c_R_f1_process)\n",
    "#     pickle.dump(everything, f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################### LOAD DATA #####################################################################\n",
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/journals/'\n",
    "\n",
    "with open(os.path.join(input_folder, 'journal_results_td2c_R_N5.pkl'), 'rb') as f:\n",
    "    TD2C_rocs_process, TD2C_precision_process, TD2C_recall_process, TD2C_f1_process = pickle.load(f)\n",
    "\n",
    "# with open(os.path.join(input_folder, 'journal_results_d2c_R_N10.pkl'), 'rb') as f:\n",
    "#     d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process = pickle.load(f)\n",
    "\n",
    "# with open(os.path.join(input_folder, 'journal_results_d2c_R_N25.pkl'), 'rb') as f:\n",
    "#     d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process = pickle.load(f)\n",
    "\n",
    "\n",
    "##################################################################### PLOT #########################################################################\n",
    "\n",
    "df1 = pd.DataFrame(TD2C_rocs_process)\n",
    "\n",
    "# Combine data for boxplot\n",
    "combined_data = []\n",
    "\n",
    "for col in df1.columns:\n",
    "    combined_data.append(df1[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns:\n",
    "    labels.append(f'{col} TD2C_Reg')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title('Boxplot of ROC-AUC scores for TD2C method, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('ROC-AUC score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD2C + Ranking (All methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptors Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################### SETTING FOR DESCRIPTORS COMPUTATION ######################################################\n",
    "\n",
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "\n",
    "to_process = [] # list of files to process\n",
    "\n",
    "# This loop is used to filter the files to process and obtain the parameters of the process\n",
    "# The resulting list will be used to parallelize the process and will be passed to the DataLoader.\n",
    "# The result is of the form (file, gen_process_number, n_variables, max_neighborhood_size, noise_std)\n",
    "# asnd is saved in the to_process list.\n",
    "for file in sorted(os.listdir(input_folder)): \n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    if noise_std != 0.01:\n",
    "        continue\n",
    "    \n",
    "    if max_neighborhood_size != 2:\n",
    "        continue\n",
    "\n",
    "    # if n_variables != 5:\n",
    "    #     continue\n",
    "\n",
    "    to_process.append(file)\n",
    "\n",
    "\n",
    "############################################################### COMPUTE DESCRIPTORS ################################################################\n",
    "\n",
    "# SET FOLDER\n",
    "cartella = 8\n",
    "# 1 = TD2C_+Ranking_1\n",
    "# 2 = TD2C_+Ranking_2\n",
    "# 3 = TD2C_+Ranking_3, \n",
    "# 4 = TD2C_+Ranking_NoCont\n",
    "# 11 = TD2C_+Ranking_1 with two variables from ranking \n",
    "# 111 = TD2C_+Ranking_1 with three variables from ranking\n",
    "# 110 = TD2C_+Ranking_1 with ten variables from ranking\n",
    "# 5 = TD2C_+Ranking_4 with one variable from ranking\n",
    "# 6 = TD2C_+Ranking_5 with one variable from ranking\n",
    "# 7 = TD2C_+Ranking_6 with one variable from ranking\n",
    "# 8 = TD2C_+Ranking_7 with one variable from ranking\n",
    "\n",
    "if cartella == 1:\n",
    "    output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C_+Ranking/TD2C_+Ranking_1/1_Var/' \n",
    "    ts_rank = 'ts_rank'\n",
    "    vars_to_keep = 1\n",
    "elif cartella == 11:\n",
    "    output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C_+Ranking/TD2C_+Ranking_1/2_Var/'\n",
    "    ts_rank = 'ts_rank'\n",
    "    vars_to_keep = 2\n",
    "elif cartella == 111:\n",
    "    output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C_+Ranking/TD2C_+Ranking_1/3_Var/'\n",
    "    ts_rank = 'ts_rank'\n",
    "    vars_to_keep = 3\n",
    "elif cartella == 110:\n",
    "    output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C_+Ranking/TD2C_+Ranking_1/10_Var/'\n",
    "    ts_rank = 'ts_rank'\n",
    "    vars_to_keep = 10\n",
    "elif cartella == 2:\n",
    "    output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C_+Ranking/TD2C_+Ranking_2/'\n",
    "    ts_rank = 'ts_rank_2'\n",
    "    vars_to_keep = 1\n",
    "elif cartella == 3:\n",
    "    output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C_+Ranking/TD2C_+Ranking_3/'\n",
    "    ts_rank = 'ts_rank_3'\n",
    "    vars_to_keep = 1\n",
    "elif cartella == 4:\n",
    "    output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C_+Ranking/TD2C+Ranking_NoCont/'\n",
    "    ts_rank = 'ts_rank_no_cont' \n",
    "    vars_to_keep = 1\n",
    "elif cartella == 5:\n",
    "    output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C_+Ranking/TD2C+Ranking_4/'\n",
    "    ts_rank = 'ts_rank_4' \n",
    "    vars_to_keep = 1\n",
    "elif cartella == 6:\n",
    "    output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C_+Ranking/TD2C+Ranking_5/'\n",
    "    ts_rank = 'ts_rank_5' \n",
    "    vars_to_keep = 1\n",
    "elif cartella == 7:\n",
    "    output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C_+Ranking/TD2C+Ranking_6/'\n",
    "    ts_rank = 'ts_rank_6' \n",
    "    vars_to_keep = 1\n",
    "elif cartella == 8:\n",
    "    output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C_+Ranking/TD2C+Ranking_7/'\n",
    "    ts_rank = 'ts_rank_7' \n",
    "    vars_to_keep = 1\n",
    "\n",
    "# create output folder if it does not exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# This loop processes the files in the input folder (to_process) and saves the descriptors in the output folder.\n",
    "\n",
    "# At first, we collect the parameters of the process from the file name.\n",
    "for file in tqdm(to_process):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "# The DataLoader is initialized with the parameters of the process. \n",
    "    dataloader = DataLoader(n_variables = n_variables,\n",
    "                    maxlags = maxlags)\n",
    "    dataloader.from_pickle(input_folder+file)\n",
    "\n",
    "# The D2C object is initialized with the DataLoader and the parameters of the process.\n",
    "    d2c = D2C(observations=dataloader.get_observations(), \n",
    "            dags=dataloader.get_dags(), \n",
    "            couples_to_consider_per_dag=COUPLES_TO_CONSIDER_PER_DAG, \n",
    "            MB_size=MB_SIZE, \n",
    "            n_variables=n_variables, \n",
    "            maxlags=maxlags,\n",
    "            seed=SEED,\n",
    "            n_jobs=N_JOBS,\n",
    "            full=True,\n",
    "            quantiles=True,\n",
    "            normalize=True,\n",
    "            cmi='original',\n",
    "            mb_estimator= ts_rank,\n",
    "            top_vars = vars_to_keep)\n",
    "\n",
    "    d2c.initialize() # initializes the D2C object\n",
    "\n",
    "    descriptors_df = d2c.get_descriptors_df()  # computes the descriptors\n",
    "\n",
    "    descriptors_df.insert(0, 'process_id', gen_process_number)\n",
    "    descriptors_df.insert(2, 'n_variables', n_variables)\n",
    "    descriptors_df.insert(3, 'max_neighborhood_size', max_neighborhood_size)\n",
    "    descriptors_df.insert(4, 'noise_std', noise_std)\n",
    "\n",
    "    # The descriptors are saved in the output folder as a pickle file.\n",
    "    descriptors_df.to_pickle(output_folder+f'P{gen_process_number}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std}_MB{MB_SIZE}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "\n",
    "to_dos = []\n",
    "\n",
    "# This loop gets a list of all the files to be processed\n",
    "for testing_file in sorted(os.listdir(data_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "          \n",
    "        if noise_std != 0.01: # if the noise is different we skip the file\n",
    "            continue\n",
    "\n",
    "        if max_neighborhood_size != 2: # if the max_neighborhood_size is different we skip the file\n",
    "            continue\n",
    "\n",
    "        to_dos.append(testing_file) # we add the file to the list (to_dos) to be processed\n",
    "\n",
    "# sort to_dos by number of variables\n",
    "to_dos_5_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 5]\n",
    "# to_dos_10_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 10]\n",
    "# to_dos_25_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 25]\n",
    "\n",
    "# we create a dictionary with the lists of files to be processed\n",
    "todos = {'5': to_dos_5_variables} # , '10': to_dos_10_variables, '25': to_dos_25_variables\n",
    "\n",
    "# we create a dictionary to store the results\n",
    "dfs = []\n",
    "\n",
    "# TAKES THE FOLDER SET AT THE STEP BEFORE AND RUN ALL THE FOLLOWING CELLS FOR THIS METHOD\n",
    "# 1 = TD2C_+Ranking_1\n",
    "# 2 = TD2C_+Ranking_2\n",
    "# 3 = TD2C_+Ranking_3\n",
    "# 4 = TD2C_+Ranking_NoCont\n",
    "# 11 = TD2C_+Ranking_1 with two variables from ranking \n",
    "# 111 = TD2C_+Ranking_1 with three variables from ranking\n",
    "# 110 = TD2C_+Ranking_1 with ten variables from ranking\n",
    "# 5 = TD2C_+Ranking_4 with two variables from ranking\n",
    "# 6 = TD2C_+Ranking_5 with three variables from ranking\n",
    "\n",
    "if cartella == 1:\n",
    "    descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C_+Ranking/TD2C_+Ranking_1/1_Var/' \n",
    "    name = 'TD2C_Ranking_1_1_Var'\n",
    "elif cartella == 11:\n",
    "    descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C_+Ranking/TD2C_+Ranking_1/2_Var/'\n",
    "    name = 'TD2C_Ranking_1_2_Var'\n",
    "elif cartella == 111:\n",
    "    descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C_+Ranking/TD2C_+Ranking_1/3_Var/'\n",
    "    name = 'TD2C_Ranking_1_3_Var'\n",
    "elif cartella == 110:\n",
    "    descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C_+Ranking/TD2C_+Ranking_1/10_Var/'\n",
    "    name = 'TD2C_Ranking_1_10_Var'\n",
    "elif cartella == 2:\n",
    "    descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C_+Ranking/TD2C_+Ranking_2/'\n",
    "    name = 'TD2C_Ranking_2'\n",
    "elif cartella == 3:\n",
    "    descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C_+Ranking/TD2C_+Ranking_3/'\n",
    "    name = 'TD2C_Ranking_3'\n",
    "elif cartella == 4:\n",
    "    descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C_+Ranking/TD2C+Ranking_NoCont/'\n",
    "    name = 'TD2C_Ranking_NoCont'\n",
    "elif cartella == 5:\n",
    "    descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C_+Ranking/TD2C+Ranking_4/'\n",
    "    name = 'TD2C_Ranking_4'\n",
    "elif cartella == 6:\n",
    "    descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C_+Ranking/TD2C+Ranking_5/'\n",
    "    name = 'TD2C_Ranking_5'\n",
    "elif cartella == 7:\n",
    "    descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C_+Ranking/TD2C+Ranking_6/'\n",
    "    name = 'TD2C_Ranking_6'\n",
    "elif cartella == 8:\n",
    "    descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C_+Ranking/TD2C+Ranking_7/'\n",
    "    name = 'TD2C_Ranking_7'\n",
    "\n",
    "\n",
    "\n",
    "# Re-save pickle files with protocol 4\n",
    "for testing_file in sorted(os.listdir(descriptors_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        file_path = os.path.join(descriptors_root, testing_file)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Re-save with protocol 4\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(data, f, protocol=4)\n",
    "\n",
    "# This loop gets the descriptors for the files to be processed\n",
    "for testing_file in sorted(os.listdir(descriptors_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        df = pd.read_pickle(os.path.join(descriptors_root, testing_file))\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            dfs.append(df)\n",
    "\n",
    "# we concatenate the descriptors\n",
    "descriptors_training = pd.concat(dfs, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loop does the following:\n",
    "# 1. Creates some dictionaries to store the results\n",
    "# 2. Loads the training data\n",
    "# 3. Trains the model\n",
    "# 4. Evaluates the model\n",
    "# 5. Stores the results in the dictionaries\n",
    "# 6. Saves the dictionaries in a pickle file\n",
    "\n",
    "\n",
    "for n_vars, todo in todos.items():\n",
    "    m1 = f'{name}_rocs_process'\n",
    "    m2 = f'{name}_precision_process'\n",
    "    m3 = f'{name}_recall_process'\n",
    "    m4 = f'{name}_f1_process'\n",
    "\n",
    "    globals()[m1] = {}\n",
    "    globals()[m2] = {}\n",
    "    globals()[m3] = {}\n",
    "    globals()[m4] = {}\n",
    "\n",
    "\n",
    "    for testing_file in tqdm(todo):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "\n",
    "        # split training and testing data\n",
    "        training_data = descriptors_training.loc[descriptors_training['process_id'] != gen_process_number]\n",
    "        X_train = training_data.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "        y_train = training_data['is_causal']\n",
    "\n",
    "        testing_data = descriptors_training.loc[(descriptors_training['process_id'] == gen_process_number) & (descriptors_training['n_variables'] == n_variables) & (descriptors_training['max_neighborhood_size'] == max_neighborhood_size) & (descriptors_training['noise_std'] == noise_std)]\n",
    "\n",
    "        model = BalancedRandomForestClassifier(n_estimators=100, random_state=0, n_jobs=50, max_depth=None, sampling_strategy='auto', replacement=True, bootstrap=False)\n",
    "        # model = RandomForestClassifier(n_estimators=50, random_state=0, n_jobs=50, max_depth=10)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        rocs = {}\n",
    "        precisions = {}\n",
    "        recalls = {}\n",
    "        f1s = {}\n",
    "        for graph_id in range(40):\n",
    "            #load testing descriptors\n",
    "            test_df = testing_data.loc[testing_data['graph_id'] == graph_id]\n",
    "            test_df = test_df.sort_values(by=['edge_source','edge_dest']).reset_index(drop=True) # sort for coherence\n",
    "\n",
    "            X_test = test_df.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "            y_test = test_df['is_causal']\n",
    "\n",
    "            y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            roc = roc_auc_score(y_test, y_pred_proba)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            \n",
    "            rocs[graph_id] = roc\n",
    "            precisions[graph_id] = precision\n",
    "            recalls[graph_id] = recall\n",
    "            f1s[graph_id] = f1\n",
    "\n",
    "        globals()[m1][gen_process_number] = rocs\n",
    "        globals()[m2][gen_process_number] = precisions\n",
    "        globals()[m3][gen_process_number] = recalls\n",
    "        globals()[m4][gen_process_number] = f1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle everything\n",
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/journals/'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "with open(os.path.join(output_folder, f'journal_results_{name}_N5.pkl'), 'wb') as f:\n",
    "    everything = (globals()[m1], globals()[m2], globals()[m3], globals()[m4])\n",
    "    pickle.dump(everything, f)\n",
    "\n",
    "# with open(os.path.join(output_folder, f'journal_results_d2c_R_N10.pkl'), 'wb') as f:\n",
    "#     everything = (d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process)\n",
    "#     pickle.dump(everything, f)\n",
    "\n",
    "# with open(os.path.join(output_folder, f'journal_results_d2c_R_N25.pkl'), 'wb') as f:\n",
    "#     everything = (d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process)\n",
    "#     pickle.dump(everything, f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data for local and global plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### local save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/journals/'\n",
    "\n",
    "# LOCAL\n",
    "with open(os.path.join(input_folder, f'journal_results_{name}_N5.pkl'), 'rb') as f:\n",
    "    globals()[m1], globals()[m2], globals()[m3], globals()[m4] = pickle.load(f)\n",
    "\n",
    "# with open(os.path.join(input_folder, 'journal_results_d2c_R_N10.pkl'), 'rb') as f:\n",
    "#     d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process = pickle.load(f)\n",
    "\n",
    "# with open(os.path.join(input_folder, 'journal_results_d2c_R_N25.pkl'), 'rb') as f:\n",
    "#     d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### global save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/journals/'\n",
    "\n",
    "cartella = 8\n",
    "\n",
    "if cartella == 1:\n",
    "    name = 'TD2C_Ranking_1_1_Var'\n",
    "elif cartella == 11:\n",
    "    name = 'TD2C_Ranking_1_2_Var'\n",
    "elif cartella == 111:\n",
    "    name = 'TD2C_Ranking_1_3_Var'\n",
    "elif cartella == 110:\n",
    "    name = 'TD2C_Ranking_1_10_Var'\n",
    "elif cartella == 2:\n",
    "    name = 'TD2C_Ranking_2'\n",
    "elif cartella == 3:\n",
    "    name = 'TD2C_Ranking_3'\n",
    "elif cartella == 4:\n",
    "    name = 'TD2C_Ranking_NoCont'\n",
    "elif cartella == 5:\n",
    "    name = 'TD2C_Ranking_4'\n",
    "elif cartella == 6:\n",
    "    name = 'TD2C_Ranking_5'\n",
    "elif cartella == 7:\n",
    "    name = 'TD2C_Ranking_6'\n",
    "elif cartella == 8:\n",
    "    name = 'TD2C_Ranking_7'\n",
    "\n",
    "if cartella == 1:\n",
    "    with open(os.path.join(input_folder, f'journal_results_{name}_N5.pkl'), 'rb') as f:\n",
    "        TD2C_Ranking_1_1_Var_rocs_process, TD2C_Ranking_1_1_Var_precision_process, TD2C_Ranking_1_1_Var_recall_process, TD2C_Ranking_1_1_Var_f1_process = pickle.load(f)\n",
    "elif cartella == 11:\n",
    "    with open(os.path.join(input_folder, f'journal_results_{name}_N5.pkl'), 'rb') as f:\n",
    "        TD2C_Ranking_1_2_Var_rocs_process, TD2C_Ranking_1_2_Var_precision_process, TD2C_Ranking_1_2_Var_recall_process, TD2C_Ranking_1_2_Var_f1_process = pickle.load(f)\n",
    "elif cartella == 111:\n",
    "    with open(os.path.join(input_folder, f'journal_results_{name}_N5.pkl'), 'rb') as f:\n",
    "        TD2C_Ranking_1_3_Var_rocs_process, TD2C_Ranking_1_3_Var_precision_process, TD2C_Ranking_1_3_Var_recall_process, TD2C_Ranking_1_3_Var_f1_process = pickle.load(f)\n",
    "elif cartella == 110:\n",
    "    with open(os.path.join(input_folder, f'journal_results_{name}_N5.pkl'), 'rb') as f:\n",
    "        TD2C_Ranking_1_10_Var_rocs_process, TD2C_Ranking_1_10_Var_precision_process, TD2C_Ranking_1_10_Var_recall_process, TD2C_Ranking_1_10_Var_f1_process = pickle.load(f)\n",
    "elif cartella == 2:\n",
    "    with open(os.path.join(input_folder, f'journal_results_{name}_N5.pkl'), 'rb') as f:\n",
    "        TD2C_Ranking_2_rocs_process, TD2C_Ranking_2_precision_process, TD2C_Ranking_2_recall_process, TD2C_Ranking_2_f1_process = pickle.load(f)\n",
    "elif cartella == 3:\n",
    "    with open(os.path.join(input_folder, f'journal_results_{name}_N5.pkl'), 'rb') as f:\n",
    "        TD2C_Ranking_3_rocs_process, TD2C_Ranking_3_precision_process, TD2C_Ranking_3_recall_process, TD2C_Ranking_3_f1_process = pickle.load(f)\n",
    "elif cartella == 4:\n",
    "    with open(os.path.join(input_folder, f'journal_results_{name}_N5.pkl'), 'rb') as f:\n",
    "        TD2C_Ranking_NoCont_rocs_process, TD2C_Ranking_NoCont_precision_process, TD2C_Ranking_NoCont_recall_process, TD2C_Ranking_NoCont_f1_process = pickle.load(f)\n",
    "elif cartella == 5:\n",
    "    with open(os.path.join(input_folder, f'journal_results_{name}_N5.pkl'), 'rb') as f:\n",
    "        TD2C_Ranking_4_rocs_process, TD2C_Ranking_4_precision_process, TD2C_Ranking_4_recall_process, TD2C_Ranking_4_f1_process = pickle.load(f)\n",
    "elif cartella == 6:\n",
    "    with open(os.path.join(input_folder, f'journal_results_{name}_N5.pkl'), 'rb') as f:\n",
    "        TD2C_Ranking_5_rocs_process, TD2C_Ranking_5_precision_process, TD2C_Ranking_5_recall_process, TD2C_Ranking_5_f1_process = pickle.load(f)\n",
    "elif cartella == 7:\n",
    "    with open(os.path.join(input_folder, f'journal_results_{name}_N5.pkl'), 'rb') as f:\n",
    "        TD2C_Ranking_6_rocs_process, TD2C_Ranking_6_precision_process, TD2C_Ranking_6_recall_process, TD2C_Ranking_6_f1_process = pickle.load(f)\n",
    "elif cartella == 8:\n",
    "    with open(os.path.join(input_folder, f'journal_results_{name}_N5.pkl'), 'rb') as f:\n",
    "        TD2C_Ranking_7_rocs_process, TD2C_Ranking_7_precision_process, TD2C_Ranking_7_recall_process, TD2C_Ranking_7_f1_process = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(globals()[m1])\n",
    "df_name = f'{name}_rocs_dataset'\n",
    "globals()[df_name] = df1\n",
    "\n",
    "# Combine data for boxplot\n",
    "combined_data = []\n",
    "\n",
    "for col in df1.columns:\n",
    "    combined_data.append(df1[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns:\n",
    "    labels.append(f'{col} {name}')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title(f'Boxplot of ROC-AUC scores for {name} method, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('ROC-AUC score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD2C in the past-future (& TD2C in the past-future but without contrmporaneous nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptors Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################### SETTING FOR DESCRIPTORS COMPUTATION ######################################################\n",
    "\n",
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "\n",
    "to_process = [] # list of files to process\n",
    "\n",
    "# This loop is used to filter the files to process and obtain the parameters of the process\n",
    "# The resulting list will be used to parallelize the process and will be passed to the DataLoader.\n",
    "# The result is of the form (file, gen_process_number, n_variables, max_neighborhood_size, noise_std)\n",
    "# asnd is saved in the to_process list.\n",
    "for file in sorted(os.listdir(input_folder)): \n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    if noise_std != 0.01:\n",
    "        continue\n",
    "    \n",
    "    if max_neighborhood_size != 2:\n",
    "        continue\n",
    "\n",
    "    # if n_variables != 5:\n",
    "    #     continue\n",
    "\n",
    "    to_process.append(file)\n",
    "\n",
    "\n",
    "############################################################### COMPUTE DESCRIPTORS ################################################################\n",
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C_PastFut/'  \n",
    "\n",
    "# create output folder if it does not exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# This loop processes the files in the input folder (to_process) and saves the descriptors in the output folder.\n",
    "\n",
    "# At first, we collect the parameters of the process from the file name.\n",
    "for file in tqdm(to_process):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "# The DataLoader is initialized with the parameters of the process. \n",
    "    dataloader = DataLoader(n_variables = n_variables,\n",
    "                    maxlags = maxlags)\n",
    "    dataloader.from_pickle(input_folder+file)\n",
    "\n",
    "# The D2C object is initialized with the DataLoader and the parameters of the process.\n",
    "    d2c = D2C(observations=dataloader.get_observations(), \n",
    "            dags=dataloader.get_dags(), \n",
    "            couples_to_consider_per_dag=COUPLES_TO_CONSIDER_PER_DAG, \n",
    "            MB_size=MB_SIZE, \n",
    "            n_variables=n_variables, \n",
    "            maxlags=maxlags,\n",
    "            seed=SEED,\n",
    "            n_jobs=N_JOBS,\n",
    "            full=True,\n",
    "            quantiles=True,\n",
    "            normalize=True,\n",
    "            cmi='original',\n",
    "            mb_estimator= 'ts_past')\n",
    "\n",
    "    d2c.initialize() # initializes the D2C object\n",
    "\n",
    "    descriptors_df = d2c.get_descriptors_df()  # computes the descriptors\n",
    "\n",
    "    descriptors_df.insert(0, 'process_id', gen_process_number)\n",
    "    descriptors_df.insert(2, 'n_variables', n_variables)\n",
    "    descriptors_df.insert(3, 'max_neighborhood_size', max_neighborhood_size)\n",
    "    descriptors_df.insert(4, 'noise_std', noise_std)\n",
    "\n",
    "    # The descriptors are saved in the output folder as a pickle file.\n",
    "    descriptors_df.to_pickle(output_folder+f'P{gen_process_number}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std}_MB{MB_SIZE}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "\n",
    "to_dos = []\n",
    "\n",
    "# This loop gets a list of all the files to be processed\n",
    "for testing_file in sorted(os.listdir(data_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "          \n",
    "        if noise_std != 0.01: # if the noise is different we skip the file\n",
    "            continue\n",
    "\n",
    "        if max_neighborhood_size != 2: # if the max_neighborhood_size is different we skip the file\n",
    "            continue\n",
    "\n",
    "        to_dos.append(testing_file) # we add the file to the list (to_dos) to be processed\n",
    "\n",
    "# sort to_dos by number of variables\n",
    "to_dos_5_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 5]\n",
    "# to_dos_10_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 10]\n",
    "# to_dos_25_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 25]\n",
    "\n",
    "# we create a dictionary with the lists of files to be processed\n",
    "todos = {'5': to_dos_5_variables} # , '10': to_dos_10_variables, '25': to_dos_25_variables\n",
    "\n",
    "# we create a dictionary to store the results\n",
    "dfs = []\n",
    "descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C_PastFut/'\n",
    "\n",
    "# Re-save pickle files with protocol 4\n",
    "for testing_file in sorted(os.listdir(descriptors_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        file_path = os.path.join(descriptors_root, testing_file)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Re-save with protocol 4\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(data, f, protocol=4)\n",
    "\n",
    "# This loop gets the descriptors for the files to be processed\n",
    "for testing_file in sorted(os.listdir(descriptors_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        df = pd.read_pickle(os.path.join(descriptors_root, testing_file))\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            dfs.append(df)\n",
    "\n",
    "# we concatenate the descriptors\n",
    "descriptors_training = pd.concat(dfs, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loop does the following:\n",
    "# 1. Creates some dictionaries to store the results\n",
    "# 2. Loads the training data\n",
    "# 3. Trains the model\n",
    "# 4. Evaluates the model\n",
    "# 5. Stores the results in the dictionaries\n",
    "# 6. Saves the dictionaries in a pickle file\n",
    "\n",
    "for n_vars, todo in todos.items():\n",
    "    td2c_past_rocs_process = {}\n",
    "    td2c_past_precision_process = {}\n",
    "    td2c_past_recall_process = {}\n",
    "    td2c_past_f1_process = {}\n",
    "    for testing_file in tqdm(todo):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "\n",
    "        # split training and testing data\n",
    "        training_data = descriptors_training.loc[descriptors_training['process_id'] != gen_process_number]\n",
    "        X_train = training_data.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "        y_train = training_data['is_causal']\n",
    "\n",
    "        testing_data = descriptors_training.loc[(descriptors_training['process_id'] == gen_process_number) & (descriptors_training['n_variables'] == n_variables) & (descriptors_training['max_neighborhood_size'] == max_neighborhood_size) & (descriptors_training['noise_std'] == noise_std)]\n",
    "\n",
    "        model = BalancedRandomForestClassifier(n_estimators=100, random_state=0, n_jobs=50, max_depth=None, sampling_strategy='auto', replacement=True, bootstrap=False)\n",
    "        # model = RandomForestClassifier(n_estimators=50, random_state=0, n_jobs=50, max_depth=10)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        rocs = {}\n",
    "        precisions = {}\n",
    "        recalls = {}\n",
    "        f1s = {}\n",
    "        for graph_id in range(40):\n",
    "            #load testing descriptors\n",
    "            test_df = testing_data.loc[testing_data['graph_id'] == graph_id]\n",
    "            test_df = test_df.sort_values(by=['edge_source','edge_dest']).reset_index(drop=True) # sort for coherence\n",
    "\n",
    "            X_test = test_df.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "            y_test = test_df['is_causal']\n",
    "\n",
    "            y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            roc = roc_auc_score(y_test, y_pred_proba)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            \n",
    "            rocs[graph_id] = roc\n",
    "            precisions[graph_id] = precision\n",
    "            recalls[graph_id] = recall\n",
    "            f1s[graph_id] = f1\n",
    "\n",
    "        td2c_past_rocs_process[gen_process_number] = rocs\n",
    "        td2c_past_precision_process[gen_process_number] = precisions\n",
    "        td2c_past_recall_process[gen_process_number] = recalls\n",
    "        td2c_past_f1_process[gen_process_number] = f1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle everything\n",
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/journals/'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "with open(os.path.join(output_folder, f'journal_results_td2c_past_R_N5.pkl'), 'wb') as f:\n",
    "    everything = (td2c_past_rocs_process, td2c_past_precision_process, td2c_past_recall_process, td2c_past_f1_process)\n",
    "    pickle.dump(everything, f)\n",
    "\n",
    "# with open(os.path.join(output_folder, f'journal_results_d2c_R_N10.pkl'), 'wb') as f:\n",
    "#     everything = (d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process)\n",
    "#     pickle.dump(everything, f)\n",
    "\n",
    "# with open(os.path.join(output_folder, f'journal_results_d2c_R_N25.pkl'), 'wb') as f:\n",
    "#     everything = (d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process)\n",
    "#     pickle.dump(everything, f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################### LOAD DATA #####################################################################\n",
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/journals/'\n",
    "\n",
    "with open(os.path.join(input_folder, 'journal_results_td2c_past_R_N5.pkl'), 'rb') as f:\n",
    "    TD2C_Ranking_PastFut_rocs_process, TD2C_Ranking_PastFut_precision_process, TD2C_Ranking_PastFut_recall_process, TD2C_Ranking_PastFut_f1_process = pickle.load(f) \n",
    "\n",
    "# with open(os.path.join(input_folder, 'journal_results_d2c_R_N10.pkl'), 'rb') as f:\n",
    "#     d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process = pickle.load(f)\n",
    "\n",
    "# with open(os.path.join(input_folder, 'journal_results_d2c_R_N25.pkl'), 'rb') as f:\n",
    "#     d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process = pickle.load(f)\n",
    "\n",
    "\n",
    "##################################################################### PLOT #########################################################################\n",
    "\n",
    "df1 = pd.DataFrame(TD2C_Ranking_PastFut_rocs_process)\n",
    "\n",
    "# Combine data for boxplot\n",
    "combined_data = []\n",
    "\n",
    "for col in df1.columns:\n",
    "    combined_data.append(df1[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns:\n",
    "    labels.append(f'{col} TD2C_Past_Reg')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title('Boxplot of ROC-AUC scores for TD2C_Past method with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('ROC-AUC score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNNCMI Estimation of MI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D2C (& D2C but without contemporaneous nodes) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptors Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################### SETTING FOR DESCRIPTORS COMPUTATION ######################################################\n",
    "\n",
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "\n",
    "to_process = [] # list of files to process\n",
    "\n",
    "# This loop is used to filter the files to process and obtain the parameters of the process\n",
    "# The resulting list will be used to parallelize the process and will be passed to the DataLoader.\n",
    "# The result is of the form (file, gen_process_number, n_variables, max_neighborhood_size, noise_std)\n",
    "# asnd is saved in the to_process list.\n",
    "for file in sorted(os.listdir(input_folder)): \n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    if noise_std != 0.01:\n",
    "        continue\n",
    "    \n",
    "    if max_neighborhood_size != 2:\n",
    "        continue\n",
    "\n",
    "    # if n_variables != 5:\n",
    "    #     continue\n",
    "\n",
    "    to_process.append(file)\n",
    "\n",
    "\n",
    "############################################################### COMPUTE DESCRIPTORS ################################################################\n",
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/D2C/'  \n",
    "\n",
    "# create output folder if it does not exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# This loop processes the files in the input folder (to_process) and saves the descriptors in the output folder.\n",
    "\n",
    "# At first, we collect the parameters of the process from the file name.\n",
    "for file in tqdm(to_process):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "# The DataLoader is initialized with the parameters of the process. \n",
    "    dataloader = DataLoader(n_variables = n_variables,\n",
    "                    maxlags = maxlags)\n",
    "    dataloader.from_pickle(input_folder+file)\n",
    "\n",
    "# The D2C object is initialized with the DataLoader and the parameters of the process.\n",
    "    d2c = D2C(observations=dataloader.get_observations(), \n",
    "            dags=dataloader.get_dags(), \n",
    "            couples_to_consider_per_dag=COUPLES_TO_CONSIDER_PER_DAG, \n",
    "            MB_size=MB_SIZE, \n",
    "            n_variables=n_variables, \n",
    "            maxlags=maxlags,\n",
    "            seed=SEED,\n",
    "            n_jobs=N_JOBS,\n",
    "            full=True,\n",
    "            quantiles=True,\n",
    "            normalize=True,\n",
    "            cmi='cmiknn_3',\n",
    "            mb_estimator= 'original',\n",
    "            top_vars=3)\n",
    "\n",
    "    d2c.initialize() # initializes the D2C object\n",
    "\n",
    "    descriptors_df = d2c.get_descriptors_df()  # computes the descriptors\n",
    "\n",
    "    descriptors_df.insert(0, 'process_id', gen_process_number)\n",
    "    descriptors_df.insert(2, 'n_variables', n_variables)\n",
    "    descriptors_df.insert(3, 'max_neighborhood_size', max_neighborhood_size)\n",
    "    descriptors_df.insert(4, 'noise_std', noise_std)\n",
    "\n",
    "    # The descriptors are saved in the output folder as a pickle file.\n",
    "    descriptors_df.to_pickle(output_folder+f'P{gen_process_number}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std}_MB{MB_SIZE}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "\n",
    "to_dos = []\n",
    "\n",
    "# This loop gets a list of all the files to be processed\n",
    "for testing_file in sorted(os.listdir(data_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "          \n",
    "        if noise_std != 0.01: # if the noise is different we skip the file\n",
    "            continue\n",
    "\n",
    "        if max_neighborhood_size != 2: # if the max_neighborhood_size is different we skip the file\n",
    "            continue\n",
    "\n",
    "        to_dos.append(testing_file) # we add the file to the list (to_dos) to be processed\n",
    "\n",
    "# sort to_dos by number of variables\n",
    "to_dos_5_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 5]\n",
    "# to_dos_10_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 10]\n",
    "# to_dos_25_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 25]\n",
    "\n",
    "# we create a dictionary with the lists of files to be processed\n",
    "todos = {'5': to_dos_5_variables} # , '10': to_dos_10_variables, '25': to_dos_25_variables\n",
    "\n",
    "# we create a dictionary to store the results\n",
    "dfs = []\n",
    "descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/D2C/'\n",
    "\n",
    "# Re-save pickle files with protocol 4\n",
    "for testing_file in sorted(os.listdir(descriptors_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        file_path = os.path.join(descriptors_root, testing_file)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Re-save with protocol 4\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(data, f, protocol=4)\n",
    "\n",
    "# This loop gets the descriptors for the files to be processed\n",
    "for testing_file in sorted(os.listdir(descriptors_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        df = pd.read_pickle(os.path.join(descriptors_root, testing_file))\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            dfs.append(df)\n",
    "\n",
    "# we concatenate the descriptors\n",
    "descriptors_training = pd.concat(dfs, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loop does the following:\n",
    "# 1. Creates some dictionaries to store the results\n",
    "# 2. Loads the training data\n",
    "# 3. Trains the model\n",
    "# 4. Evaluates the model\n",
    "# 5. Stores the results in the dictionaries\n",
    "# 6. Saves the dictionaries in a pickle file\n",
    "\n",
    "for n_vars, todo in todos.items():\n",
    "    d2c_rocs_process = {}\n",
    "    d2c_precision_process = {}\n",
    "    d2c_recall_process = {}\n",
    "    d2c_f1_process = {}\n",
    "    for testing_file in tqdm(todo):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "\n",
    "        # split training and testing data\n",
    "        training_data = descriptors_training.loc[descriptors_training['process_id'] != gen_process_number]\n",
    "        X_train = training_data.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "        y_train = training_data['is_causal']\n",
    "\n",
    "        testing_data = descriptors_training.loc[(descriptors_training['process_id'] == gen_process_number) & (descriptors_training['n_variables'] == n_variables) & (descriptors_training['max_neighborhood_size'] == max_neighborhood_size) & (descriptors_training['noise_std'] == noise_std)]\n",
    "\n",
    "        model = BalancedRandomForestClassifier(n_estimators=100, random_state=0, n_jobs=50, max_depth=None, sampling_strategy='auto', replacement=True, bootstrap=False)\n",
    "        # model = RandomForestClassifier(n_estimators=50, random_state=0, n_jobs=50, max_depth=10)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        rocs = {}\n",
    "        precisions = {}\n",
    "        recalls = {}\n",
    "        f1s = {}\n",
    "        for graph_id in range(40):\n",
    "            #load testing descriptors\n",
    "            test_df = testing_data.loc[testing_data['graph_id'] == graph_id]\n",
    "            test_df = test_df.sort_values(by=['edge_source','edge_dest']).reset_index(drop=True) # sort for coherence\n",
    "\n",
    "            X_test = test_df.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "            y_test = test_df['is_causal']\n",
    "\n",
    "            y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            roc = roc_auc_score(y_test, y_pred_proba)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            \n",
    "            rocs[graph_id] = roc\n",
    "            precisions[graph_id] = precision\n",
    "            recalls[graph_id] = recall\n",
    "            f1s[graph_id] = f1\n",
    "\n",
    "        d2c_rocs_process[gen_process_number] = rocs\n",
    "        d2c_precision_process[gen_process_number] = precisions\n",
    "        d2c_recall_process[gen_process_number] = recalls\n",
    "        d2c_f1_process[gen_process_number] = f1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle everything\n",
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/KnnCMI/journals/'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "with open(os.path.join(output_folder, f'journal_results_d2c_R_N5.pkl'), 'wb') as f:\n",
    "    everything = (d2c_rocs_process, d2c_precision_process, d2c_recall_process, d2c_f1_process)\n",
    "    pickle.dump(everything, f)\n",
    "\n",
    "# with open(os.path.join(output_folder, f'journal_results_d2c_R_N10.pkl'), 'wb') as f:\n",
    "#     everything = (d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process)\n",
    "#     pickle.dump(everything, f)\n",
    "\n",
    "# with open(os.path.join(output_folder, f'journal_results_d2c_R_N25.pkl'), 'wb') as f:\n",
    "#     everything = (d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process)\n",
    "#     pickle.dump(everything, f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################### LOAD DATA #####################################################################\n",
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/KnnCMI/journals/'\n",
    "\n",
    "with open(os.path.join(input_folder, 'journal_results_d2c_R_N5.pkl'), 'rb') as f:\n",
    "    D2C_rocs_process, D2C_precision_process, D2C_recall_process, D2C_f1_process = pickle.load(f)\n",
    "\n",
    "# with open(os.path.join(input_folder, 'journal_results_d2c_R_N10.pkl'), 'rb') as f:\n",
    "#     d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process = pickle.load(f)\n",
    "\n",
    "# with open(os.path.join(input_folder, 'journal_results_d2c_R_N25.pkl'), 'rb') as f:\n",
    "#     d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process = pickle.load(f)\n",
    "\n",
    "\n",
    "##################################################################### PLOT #########################################################################\n",
    "\n",
    "df1 = pd.DataFrame(D2C_rocs_process)\n",
    "\n",
    "# Combine data for boxplot\n",
    "combined_data = []\n",
    "\n",
    "for col in df1.columns:\n",
    "    combined_data.append(df1[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns:\n",
    "    labels.append(f'{col} D2C_Reg')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title('Boxplot of ROC-AUC scores for D2C method with KnnCMI to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('ROC-AUC score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD2C (& TD2C but without contrmporaneous nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptors Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################### SETTING FOR DESCRIPTORS COMPUTATION ######################################################\n",
    "\n",
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "\n",
    "to_process = [] # list of files to process\n",
    "\n",
    "# This loop is used to filter the files to process and obtain the parameters of the process\n",
    "# The resulting list will be used to parallelize the process and will be passed to the DataLoader.\n",
    "# The result is of the form (file, gen_process_number, n_variables, max_neighborhood_size, noise_std)\n",
    "# asnd is saved in the to_process list.\n",
    "for file in sorted(os.listdir(input_folder)): \n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    if noise_std != 0.01:\n",
    "        continue\n",
    "    \n",
    "    if max_neighborhood_size != 2:\n",
    "        continue\n",
    "\n",
    "    # if n_variables != 5:\n",
    "    #     continue\n",
    "\n",
    "    to_process.append(file)\n",
    "\n",
    "\n",
    "############################################################### COMPUTE DESCRIPTORS ################################################################\n",
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C/'  \n",
    "\n",
    "# create output folder if it does not exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# This loop processes the files in the input folder (to_process) and saves the descriptors in the output folder.\n",
    "\n",
    "# At first, we collect the parameters of the process from the file name.\n",
    "for file in tqdm(to_process):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "# The DataLoader is initialized with the parameters of the process. \n",
    "    dataloader = DataLoader(n_variables = n_variables,\n",
    "                    maxlags = maxlags)\n",
    "    dataloader.from_pickle(input_folder+file)\n",
    "\n",
    "# The D2C object is initialized with the DataLoader and the parameters of the process.\n",
    "    d2c = D2C(observations=dataloader.get_observations(), \n",
    "            dags=dataloader.get_dags(), \n",
    "            couples_to_consider_per_dag=COUPLES_TO_CONSIDER_PER_DAG, \n",
    "            MB_size=MB_SIZE, \n",
    "            n_variables=n_variables, \n",
    "            maxlags=maxlags,\n",
    "            seed=SEED,\n",
    "            n_jobs=N_JOBS,\n",
    "            full=True,\n",
    "            quantiles=True,\n",
    "            normalize=True,\n",
    "            cmi='cmiknn_3',\n",
    "            mb_estimator= 'ts',\n",
    "            top_vars=3)\n",
    "\n",
    "    d2c.initialize() # initializes the D2C object\n",
    "\n",
    "    descriptors_df = d2c.get_descriptors_df()  # computes the descriptors\n",
    "\n",
    "    descriptors_df.insert(0, 'process_id', gen_process_number)\n",
    "    descriptors_df.insert(2, 'n_variables', n_variables)\n",
    "    descriptors_df.insert(3, 'max_neighborhood_size', max_neighborhood_size)\n",
    "    descriptors_df.insert(4, 'noise_std', noise_std)\n",
    "\n",
    "    # The descriptors are saved in the output folder as a pickle file.\n",
    "    descriptors_df.to_pickle(output_folder+f'P{gen_process_number}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std}_MB{MB_SIZE}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "\n",
    "to_dos = []\n",
    "\n",
    "# This loop gets a list of all the files to be processed\n",
    "for testing_file in sorted(os.listdir(data_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "          \n",
    "        if noise_std != 0.01: # if the noise is different we skip the file\n",
    "            continue\n",
    "\n",
    "        if max_neighborhood_size != 2: # if the max_neighborhood_size is different we skip the file\n",
    "            continue\n",
    "\n",
    "        to_dos.append(testing_file) # we add the file to the list (to_dos) to be processed\n",
    "\n",
    "# sort to_dos by number of variables\n",
    "to_dos_5_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 5]\n",
    "# to_dos_10_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 10]\n",
    "# to_dos_25_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 25]\n",
    "\n",
    "# we create a dictionary with the lists of files to be processed\n",
    "todos = {'5': to_dos_5_variables} # , '10': to_dos_10_variables, '25': to_dos_25_variables\n",
    "\n",
    "# we create a dictionary to store the results\n",
    "dfs = []\n",
    "descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C/'\n",
    "\n",
    "# Re-save pickle files with protocol 4\n",
    "for testing_file in sorted(os.listdir(descriptors_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        file_path = os.path.join(descriptors_root, testing_file)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Re-save with protocol 4\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(data, f, protocol=4)\n",
    "\n",
    "# This loop gets the descriptors for the files to be processed\n",
    "for testing_file in sorted(os.listdir(descriptors_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        df = pd.read_pickle(os.path.join(descriptors_root, testing_file))\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            dfs.append(df)\n",
    "\n",
    "# we concatenate the descriptors\n",
    "descriptors_training = pd.concat(dfs, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loop does the following:\n",
    "# 1. Creates some dictionaries to store the results\n",
    "# 2. Loads the training data\n",
    "# 3. Trains the model\n",
    "# 4. Evaluates the model\n",
    "# 5. Stores the results in the dictionaries\n",
    "# 6. Saves the dictionaries in a pickle file\n",
    "\n",
    "for n_vars, todo in todos.items():\n",
    "    td2c_rocs_process = {}\n",
    "    td2c_precision_process = {}\n",
    "    td2c_recall_process = {}\n",
    "    td2c_f1_process = {}\n",
    "    for testing_file in tqdm(todo):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "\n",
    "        # split training and testing data\n",
    "        training_data = descriptors_training.loc[descriptors_training['process_id'] != gen_process_number]\n",
    "        X_train = training_data.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "        y_train = training_data['is_causal']\n",
    "\n",
    "        testing_data = descriptors_training.loc[(descriptors_training['process_id'] == gen_process_number) & (descriptors_training['n_variables'] == n_variables) & (descriptors_training['max_neighborhood_size'] == max_neighborhood_size) & (descriptors_training['noise_std'] == noise_std)]\n",
    "\n",
    "        model = BalancedRandomForestClassifier(n_estimators=100, random_state=0, n_jobs=50, max_depth=None, sampling_strategy='auto', replacement=True, bootstrap=False)\n",
    "        # model = RandomForestClassifier(n_estimators=50, random_state=0, n_jobs=50, max_depth=10)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        rocs = {}\n",
    "        precisions = {}\n",
    "        recalls = {}\n",
    "        f1s = {}\n",
    "        for graph_id in range(40):\n",
    "            #load testing descriptors\n",
    "            test_df = testing_data.loc[testing_data['graph_id'] == graph_id]\n",
    "            test_df = test_df.sort_values(by=['edge_source','edge_dest']).reset_index(drop=True) # sort for coherence\n",
    "\n",
    "            X_test = test_df.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "            y_test = test_df['is_causal']\n",
    "\n",
    "            y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            roc = roc_auc_score(y_test, y_pred_proba)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            \n",
    "            rocs[graph_id] = roc\n",
    "            precisions[graph_id] = precision\n",
    "            recalls[graph_id] = recall\n",
    "            f1s[graph_id] = f1\n",
    "\n",
    "        td2c_rocs_process[gen_process_number] = rocs\n",
    "        td2c_precision_process[gen_process_number] = precisions\n",
    "        td2c_recall_process[gen_process_number] = recalls\n",
    "        td2c_f1_process[gen_process_number] = f1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle everything\n",
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/KnnCMI/journals/'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "with open(os.path.join(output_folder, f'journal_results_td2c_R_N5.pkl'), 'wb') as f:\n",
    "    everything = (td2c_rocs_process, td2c_precision_process, td2c_recall_process, td2c_f1_process)\n",
    "    pickle.dump(everything, f)\n",
    "\n",
    "# with open(os.path.join(output_folder, f'journal_results_td2c_R_N10.pkl'), 'wb') as f:\n",
    "#     everything = (td2c_R_rocs_process, td2c_R_precision_process, td2c_R_recall_process, td2c_R_f1_process)\n",
    "#     pickle.dump(everything, f)\n",
    "\n",
    "# with open(os.path.join(output_folder, f'journal_results_td2c_R_N25.pkl'), 'wb') as f:\n",
    "#     everything = (td2c_R_rocs_process, td2c_R_precision_process, td2c_R_recall_process, td2c_R_f1_process)\n",
    "#     pickle.dump(everything, f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################### LOAD DATA #####################################################################\n",
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/KnnCMI/journals/'\n",
    "\n",
    "with open(os.path.join(input_folder, 'journal_results_td2c_R_N5.pkl'), 'rb') as f:\n",
    "    TD2C_rocs_process, TD2C_precision_process, TD2C_recall_process, TD2C_f1_process = pickle.load(f)\n",
    "\n",
    "# with open(os.path.join(input_folder, 'journal_results_d2c_R_N10.pkl'), 'rb') as f:\n",
    "#     d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process = pickle.load(f)\n",
    "\n",
    "# with open(os.path.join(input_folder, 'journal_results_d2c_R_N25.pkl'), 'rb') as f:\n",
    "#     d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process = pickle.load(f)\n",
    "\n",
    "\n",
    "##################################################################### PLOT #########################################################################\n",
    "\n",
    "df1 = pd.DataFrame(TD2C_rocs_process)\n",
    "\n",
    "# Combine data for boxplot\n",
    "combined_data = []\n",
    "\n",
    "for col in df1.columns:\n",
    "    combined_data.append(df1[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns:\n",
    "    labels.append(f'{col} TD2C_Reg')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title('Boxplot of ROC-AUC scores for TD2C method, with KnnCMI to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('ROC-AUC score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD2C + Ranking (All methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptors Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################### SETTING FOR DESCRIPTORS COMPUTATION ######################################################\n",
    "\n",
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "\n",
    "to_process = [] # list of files to process\n",
    "\n",
    "# This loop is used to filter the files to process and obtain the parameters of the process\n",
    "# The resulting list will be used to parallelize the process and will be passed to the DataLoader.\n",
    "# The result is of the form (file, gen_process_number, n_variables, max_neighborhood_size, noise_std)\n",
    "# asnd is saved in the to_process list.\n",
    "for file in sorted(os.listdir(input_folder)): \n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    if noise_std != 0.01:\n",
    "        continue\n",
    "    \n",
    "    if max_neighborhood_size != 2:\n",
    "        continue\n",
    "\n",
    "    # if n_variables != 5:\n",
    "    #     continue\n",
    "\n",
    "    to_process.append(file)\n",
    "\n",
    "\n",
    "############################################################### COMPUTE DESCRIPTORS ################################################################\n",
    "\n",
    "# SET FOLDER\n",
    "cartella = 8\n",
    "# 1 = TD2C_+Ranking_1\n",
    "# 2 = TD2C_+Ranking_2\n",
    "# 3 = TD2C_+Ranking_3, \n",
    "# 4 = TD2C_+Ranking_NoCont\n",
    "# 11 = TD2C_+Ranking_1 with two variables from ranking \n",
    "# 111 = TD2C_+Ranking_1 with three variables from ranking\n",
    "# 110 = TD2C_+Ranking_1 with ten variables from ranking\n",
    "# 5 = TD2C_+Ranking_4 with one variable from ranking\n",
    "# 6 = TD2C_+Ranking_5 with one variable from ranking\n",
    "# 7 = TD2C_+Ranking_6 with one variable from ranking\n",
    "# 8 = TD2C_+Ranking_7 with one variable from ranking\n",
    "\n",
    "if cartella == 1:\n",
    "    output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C_+Ranking/TD2C_+Ranking_1/1_Var/' \n",
    "    ts_rank = 'ts_rank'\n",
    "    vars_to_keep = 1\n",
    "elif cartella == 11:\n",
    "    output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C_+Ranking/TD2C_+Ranking_1/2_Var/'\n",
    "    ts_rank = 'ts_rank'\n",
    "    vars_to_keep = 2\n",
    "elif cartella == 111:\n",
    "    output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C_+Ranking/TD2C_+Ranking_1/3_Var/'\n",
    "    ts_rank = 'ts_rank'\n",
    "    vars_to_keep = 3\n",
    "elif cartella == 110:\n",
    "    output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C_+Ranking/TD2C_+Ranking_1/10_Var/'\n",
    "    ts_rank = 'ts_rank'\n",
    "    vars_to_keep = 10\n",
    "elif cartella == 2:\n",
    "    output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C_+Ranking/TD2C_+Ranking_2/'\n",
    "    ts_rank = 'ts_rank_2'\n",
    "    vars_to_keep = 1\n",
    "elif cartella == 3:\n",
    "    output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C_+Ranking/TD2C_+Ranking_3/'\n",
    "    ts_rank = 'ts_rank_3'\n",
    "    vars_to_keep = 1\n",
    "elif cartella == 4:\n",
    "    output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C_+Ranking/TD2C+Ranking_NoCont/'\n",
    "    ts_rank = 'ts_rank_no_cont' \n",
    "    vars_to_keep = 1\n",
    "elif cartella == 5:\n",
    "    output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C_+Ranking/TD2C+Ranking_4/'\n",
    "    ts_rank = 'ts_rank_4' \n",
    "    vars_to_keep = 1\n",
    "elif cartella == 6:\n",
    "    output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C_+Ranking/TD2C+Ranking_5/'\n",
    "    ts_rank = 'ts_rank_5' \n",
    "    vars_to_keep = 1\n",
    "elif cartella == 7:\n",
    "    output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C_+Ranking/TD2C+Ranking_6/'\n",
    "    ts_rank = 'ts_rank_6' \n",
    "    vars_to_keep = 1\n",
    "elif cartella == 8:\n",
    "    output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C_+Ranking/TD2C+Ranking_7/'\n",
    "    ts_rank = 'ts_rank_7' \n",
    "    vars_to_keep = 1\n",
    "\n",
    "# create output folder if it does not exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# This loop processes the files in the input folder (to_process) and saves the descriptors in the output folder.\n",
    "\n",
    "# At first, we collect the parameters of the process from the file name.\n",
    "for file in tqdm(to_process):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "# The DataLoader is initialized with the parameters of the process. \n",
    "    dataloader = DataLoader(n_variables = n_variables,\n",
    "                    maxlags = maxlags)\n",
    "    dataloader.from_pickle(input_folder+file)\n",
    "\n",
    "# The D2C object is initialized with the DataLoader and the parameters of the process.\n",
    "    d2c = D2C(observations=dataloader.get_observations(), \n",
    "            dags=dataloader.get_dags(), \n",
    "            couples_to_consider_per_dag=COUPLES_TO_CONSIDER_PER_DAG, \n",
    "            MB_size=MB_SIZE, \n",
    "            n_variables=n_variables, \n",
    "            maxlags=maxlags,\n",
    "            seed=SEED,\n",
    "            n_jobs=N_JOBS,\n",
    "            full=True,\n",
    "            quantiles=True,\n",
    "            normalize=True,\n",
    "            cmi='cmiknn_3',\n",
    "            mb_estimator= ts_rank,\n",
    "            top_vars = vars_to_keep)\n",
    "\n",
    "    d2c.initialize() # initializes the D2C object\n",
    "\n",
    "    descriptors_df = d2c.get_descriptors_df()  # computes the descriptors\n",
    "\n",
    "    descriptors_df.insert(0, 'process_id', gen_process_number)\n",
    "    descriptors_df.insert(2, 'n_variables', n_variables)\n",
    "    descriptors_df.insert(3, 'max_neighborhood_size', max_neighborhood_size)\n",
    "    descriptors_df.insert(4, 'noise_std', noise_std)\n",
    "\n",
    "    # The descriptors are saved in the output folder as a pickle file.\n",
    "    descriptors_df.to_pickle(output_folder+f'P{gen_process_number}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std}_MB{MB_SIZE}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "\n",
    "to_dos = []\n",
    "\n",
    "# This loop gets a list of all the files to be processed\n",
    "for testing_file in sorted(os.listdir(data_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "          \n",
    "        if noise_std != 0.01: # if the noise is different we skip the file\n",
    "            continue\n",
    "\n",
    "        if max_neighborhood_size != 2: # if the max_neighborhood_size is different we skip the file\n",
    "            continue\n",
    "\n",
    "        to_dos.append(testing_file) # we add the file to the list (to_dos) to be processed\n",
    "\n",
    "# sort to_dos by number of variables\n",
    "to_dos_5_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 5]\n",
    "# to_dos_10_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 10]\n",
    "# to_dos_25_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 25]\n",
    "\n",
    "# we create a dictionary with the lists of files to be processed\n",
    "todos = {'5': to_dos_5_variables} # , '10': to_dos_10_variables, '25': to_dos_25_variables\n",
    "\n",
    "# we create a dictionary to store the results\n",
    "dfs = []\n",
    "\n",
    "# TAKES THE FOLDER SET AT THE STEP BEFORE AND RUN ALL THE FOLLOWING CELLS FOR THIS METHOD\n",
    "# 1 = TD2C_+Ranking_1\n",
    "# 2 = TD2C_+Ranking_2\n",
    "# 3 = TD2C_+Ranking_3\n",
    "# 4 = TD2C_+Ranking_NoCont\n",
    "# 11 = TD2C_+Ranking_1 with two variables from ranking \n",
    "# 111 = TD2C_+Ranking_1 with three variables from ranking\n",
    "# 110 = TD2C_+Ranking_1 with ten variables from ranking\n",
    "# 5 = TD2C_+Ranking_4 with two variables from ranking\n",
    "# 6 = TD2C_+Ranking_5 with three variables from ranking\n",
    "\n",
    "if cartella == 1:\n",
    "    descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C_+Ranking/TD2C_+Ranking_1/1_Var/' \n",
    "    name = 'TD2C_Ranking_1_1_Var'\n",
    "elif cartella == 11:\n",
    "    descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C_+Ranking/TD2C_+Ranking_1/2_Var/'\n",
    "    name = 'TD2C_Ranking_1_2_Var'\n",
    "elif cartella == 111:\n",
    "    descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C_+Ranking/TD2C_+Ranking_1/3_Var/'\n",
    "    name = 'TD2C_Ranking_1_3_Var'\n",
    "elif cartella == 110:\n",
    "    descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C_+Ranking/TD2C_+Ranking_1/10_Var/'\n",
    "    name = 'TD2C_Ranking_1_10_Var'\n",
    "elif cartella == 2:\n",
    "    descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C_+Ranking/TD2C_+Ranking_2/'\n",
    "    name = 'TD2C_Ranking_2'\n",
    "elif cartella == 3:\n",
    "    descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C_+Ranking/TD2C_+Ranking_3/'\n",
    "    name = 'TD2C_Ranking_3'\n",
    "elif cartella == 4:\n",
    "    descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C_+Ranking/TD2C+Ranking_NoCont/'\n",
    "    name = 'TD2C_Ranking_NoCont'\n",
    "elif cartella == 5:\n",
    "    descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C_+Ranking/TD2C+Ranking_4/'\n",
    "    name = 'TD2C_Ranking_4'\n",
    "elif cartella == 6:\n",
    "    descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C_+Ranking/TD2C+Ranking_5/'\n",
    "    name = 'TD2C_Ranking_5'\n",
    "elif cartella == 7:\n",
    "    descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C_+Ranking/TD2C+Ranking_6/'\n",
    "    name = 'TD2C_Ranking_6'\n",
    "elif cartella == 8:\n",
    "    descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C_+Ranking/TD2C+Ranking_7/'\n",
    "    name = 'TD2C_Ranking_7'\n",
    "\n",
    "\n",
    "\n",
    "# Re-save pickle files with protocol 4\n",
    "for testing_file in sorted(os.listdir(descriptors_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        file_path = os.path.join(descriptors_root, testing_file)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Re-save with protocol 4\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(data, f, protocol=4)\n",
    "\n",
    "# This loop gets the descriptors for the files to be processed\n",
    "for testing_file in sorted(os.listdir(descriptors_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        df = pd.read_pickle(os.path.join(descriptors_root, testing_file))\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            dfs.append(df)\n",
    "\n",
    "# we concatenate the descriptors\n",
    "descriptors_training = pd.concat(dfs, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loop does the following:\n",
    "# 1. Creates some dictionaries to store the results\n",
    "# 2. Loads the training data\n",
    "# 3. Trains the model\n",
    "# 4. Evaluates the model\n",
    "# 5. Stores the results in the dictionaries\n",
    "# 6. Saves the dictionaries in a pickle file\n",
    "\n",
    "\n",
    "for n_vars, todo in todos.items():\n",
    "    m1 = f'{name}_rocs_process'\n",
    "    m2 = f'{name}_precision_process'\n",
    "    m3 = f'{name}_recall_process'\n",
    "    m4 = f'{name}_f1_process'\n",
    "\n",
    "    globals()[m1] = {}\n",
    "    globals()[m2] = {}\n",
    "    globals()[m3] = {}\n",
    "    globals()[m4] = {}\n",
    "\n",
    "\n",
    "    for testing_file in tqdm(todo):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "\n",
    "        # split training and testing data\n",
    "        training_data = descriptors_training.loc[descriptors_training['process_id'] != gen_process_number]\n",
    "        X_train = training_data.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "        y_train = training_data['is_causal']\n",
    "\n",
    "        testing_data = descriptors_training.loc[(descriptors_training['process_id'] == gen_process_number) & (descriptors_training['n_variables'] == n_variables) & (descriptors_training['max_neighborhood_size'] == max_neighborhood_size) & (descriptors_training['noise_std'] == noise_std)]\n",
    "\n",
    "        model = BalancedRandomForestClassifier(n_estimators=100, random_state=0, n_jobs=50, max_depth=None, sampling_strategy='auto', replacement=True, bootstrap=False)\n",
    "        # model = RandomForestClassifier(n_estimators=50, random_state=0, n_jobs=50, max_depth=10)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        rocs = {}\n",
    "        precisions = {}\n",
    "        recalls = {}\n",
    "        f1s = {}\n",
    "        for graph_id in range(40):\n",
    "            #load testing descriptors\n",
    "            test_df = testing_data.loc[testing_data['graph_id'] == graph_id]\n",
    "            test_df = test_df.sort_values(by=['edge_source','edge_dest']).reset_index(drop=True) # sort for coherence\n",
    "\n",
    "            X_test = test_df.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "            y_test = test_df['is_causal']\n",
    "\n",
    "            y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            roc = roc_auc_score(y_test, y_pred_proba)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            \n",
    "            rocs[graph_id] = roc\n",
    "            precisions[graph_id] = precision\n",
    "            recalls[graph_id] = recall\n",
    "            f1s[graph_id] = f1\n",
    "\n",
    "        globals()[m1][gen_process_number] = rocs\n",
    "        globals()[m2][gen_process_number] = precisions\n",
    "        globals()[m3][gen_process_number] = recalls\n",
    "        globals()[m4][gen_process_number] = f1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle everything\n",
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/KnnCMI/journals/'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "with open(os.path.join(output_folder, f'journal_results_{name}_N5.pkl'), 'wb') as f:\n",
    "    everything = (globals()[m1], globals()[m2], globals()[m3], globals()[m4])\n",
    "    pickle.dump(everything, f)\n",
    "\n",
    "# with open(os.path.join(output_folder, f'journal_results_d2c_R_N10.pkl'), 'wb') as f:\n",
    "#     everything = (d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process)\n",
    "#     pickle.dump(everything, f)\n",
    "\n",
    "# with open(os.path.join(output_folder, f'journal_results_d2c_R_N25.pkl'), 'wb') as f:\n",
    "#     everything = (d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process)\n",
    "#     pickle.dump(everything, f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data for local and global plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### local save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/KnnCMI/journals/'\n",
    "\n",
    "# LOCAL\n",
    "with open(os.path.join(input_folder, f'journal_results_{name}_N5.pkl'), 'rb') as f:\n",
    "    globals()[m1], globals()[m2], globals()[m3], globals()[m4] = pickle.load(f)\n",
    "\n",
    "# with open(os.path.join(input_folder, 'journal_results_d2c_R_N10.pkl'), 'rb') as f:\n",
    "#     d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process = pickle.load(f)\n",
    "\n",
    "# with open(os.path.join(input_folder, 'journal_results_d2c_R_N25.pkl'), 'rb') as f:\n",
    "#     d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### global save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/KnnCMI/journals/'\n",
    "\n",
    "cartella = 8\n",
    "\n",
    "if cartella == 1:\n",
    "    name = 'TD2C_Ranking_1_1_Var'\n",
    "elif cartella == 11:\n",
    "    name = 'TD2C_Ranking_1_2_Var'\n",
    "elif cartella == 111:\n",
    "    name = 'TD2C_Ranking_1_3_Var'\n",
    "elif cartella == 110:\n",
    "    name = 'TD2C_Ranking_1_10_Var'\n",
    "elif cartella == 2:\n",
    "    name = 'TD2C_Ranking_2'\n",
    "elif cartella == 3:\n",
    "    name = 'TD2C_Ranking_3'\n",
    "elif cartella == 4:\n",
    "    name = 'TD2C_Ranking_NoCont'\n",
    "elif cartella == 5:\n",
    "    name = 'TD2C_Ranking_4'\n",
    "elif cartella == 6:\n",
    "    name = 'TD2C_Ranking_5'\n",
    "elif cartella == 7:\n",
    "    name = 'TD2C_Ranking_6'\n",
    "elif cartella == 8:\n",
    "    name = 'TD2C_Ranking_7'\n",
    "\n",
    "if cartella == 1:\n",
    "    with open(os.path.join(input_folder, f'journal_results_{name}_N5.pkl'), 'rb') as f:\n",
    "        TD2C_Ranking_1_1_Var_rocs_process, TD2C_Ranking_1_1_Var_precision_process, TD2C_Ranking_1_1_Var_recall_process, TD2C_Ranking_1_1_Var_f1_process = pickle.load(f)\n",
    "elif cartella == 11:\n",
    "    with open(os.path.join(input_folder, f'journal_results_{name}_N5.pkl'), 'rb') as f:\n",
    "        TD2C_Ranking_1_2_Var_rocs_process, TD2C_Ranking_1_2_Var_precision_process, TD2C_Ranking_1_2_Var_recall_process, TD2C_Ranking_1_2_Var_f1_process = pickle.load(f)\n",
    "elif cartella == 111:\n",
    "    with open(os.path.join(input_folder, f'journal_results_{name}_N5.pkl'), 'rb') as f:\n",
    "        TD2C_Ranking_1_3_Var_rocs_process, TD2C_Ranking_1_3_Var_precision_process, TD2C_Ranking_1_3_Var_recall_process, TD2C_Ranking_1_3_Var_f1_process = pickle.load(f)\n",
    "elif cartella == 110:\n",
    "    with open(os.path.join(input_folder, f'journal_results_{name}_N5.pkl'), 'rb') as f:\n",
    "        TD2C_Ranking_1_10_Var_rocs_process, TD2C_Ranking_1_10_Var_precision_process, TD2C_Ranking_1_10_Var_recall_process, TD2C_Ranking_1_10_Var_f1_process = pickle.load(f)\n",
    "elif cartella == 2:\n",
    "    with open(os.path.join(input_folder, f'journal_results_{name}_N5.pkl'), 'rb') as f:\n",
    "        TD2C_Ranking_2_rocs_process, TD2C_Ranking_2_precision_process, TD2C_Ranking_2_recall_process, TD2C_Ranking_2_f1_process = pickle.load(f)\n",
    "elif cartella == 3:\n",
    "    with open(os.path.join(input_folder, f'journal_results_{name}_N5.pkl'), 'rb') as f:\n",
    "        TD2C_Ranking_3_rocs_process, TD2C_Ranking_3_precision_process, TD2C_Ranking_3_recall_process, TD2C_Ranking_3_f1_process = pickle.load(f)\n",
    "elif cartella == 4:\n",
    "    with open(os.path.join(input_folder, f'journal_results_{name}_N5.pkl'), 'rb') as f:\n",
    "        TD2C_Ranking_NoCont_rocs_process, TD2C_Ranking_NoCont_precision_process, TD2C_Ranking_NoCont_recall_process, TD2C_Ranking_NoCont_f1_process = pickle.load(f)\n",
    "elif cartella == 5:\n",
    "    with open(os.path.join(input_folder, f'journal_results_{name}_N5.pkl'), 'rb') as f:\n",
    "        TD2C_Ranking_4_rocs_process, TD2C_Ranking_4_precision_process, TD2C_Ranking_4_recall_process, TD2C_Ranking_4_f1_process = pickle.load(f)\n",
    "elif cartella == 6:\n",
    "    with open(os.path.join(input_folder, f'journal_results_{name}_N5.pkl'), 'rb') as f:\n",
    "        TD2C_Ranking_5_rocs_process, TD2C_Ranking_5_precision_process, TD2C_Ranking_5_recall_process, TD2C_Ranking_5_f1_process = pickle.load(f)\n",
    "elif cartella == 7:\n",
    "    with open(os.path.join(input_folder, f'journal_results_{name}_N5.pkl'), 'rb') as f:\n",
    "        TD2C_Ranking_6_rocs_process, TD2C_Ranking_6_precision_process, TD2C_Ranking_6_recall_process, TD2C_Ranking_6_f1_process = pickle.load(f)\n",
    "elif cartella == 8:\n",
    "    with open(os.path.join(input_folder, f'journal_results_{name}_N5.pkl'), 'rb') as f:\n",
    "        TD2C_Ranking_7_rocs_process, TD2C_Ranking_7_precision_process, TD2C_Ranking_7_recall_process, TD2C_Ranking_7_f1_process = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(globals()[m1])\n",
    "df_name = f'{name}_rocs_dataset'\n",
    "globals()[df_name] = df1\n",
    "\n",
    "# Combine data for boxplot\n",
    "combined_data = []\n",
    "\n",
    "for col in df1.columns:\n",
    "    combined_data.append(df1[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns:\n",
    "    labels.append(f'{col} {name}')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title(f'Boxplot of ROC-AUC scores for {name} method, with KnnCMI to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('ROC-AUC score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD2C in the past-future (& TD2C in the past-future but without contrmporaneous nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptors Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################### SETTING FOR DESCRIPTORS COMPUTATION ######################################################\n",
    "\n",
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "\n",
    "to_process = [] # list of files to process\n",
    "\n",
    "# This loop is used to filter the files to process and obtain the parameters of the process\n",
    "# The resulting list will be used to parallelize the process and will be passed to the DataLoader.\n",
    "# The result is of the form (file, gen_process_number, n_variables, max_neighborhood_size, noise_std)\n",
    "# asnd is saved in the to_process list.\n",
    "for file in sorted(os.listdir(input_folder)): \n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    if noise_std != 0.01:\n",
    "        continue\n",
    "    \n",
    "    if max_neighborhood_size != 2:\n",
    "        continue\n",
    "\n",
    "    # if n_variables != 5:\n",
    "    #     continue\n",
    "\n",
    "    to_process.append(file)\n",
    "\n",
    "\n",
    "############################################################### COMPUTE DESCRIPTORS ################################################################\n",
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C_PastFut/'  \n",
    "\n",
    "# create output folder if it does not exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# This loop processes the files in the input folder (to_process) and saves the descriptors in the output folder.\n",
    "\n",
    "# At first, we collect the parameters of the process from the file name.\n",
    "for file in tqdm(to_process):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "# The DataLoader is initialized with the parameters of the process. \n",
    "    dataloader = DataLoader(n_variables = n_variables,\n",
    "                    maxlags = maxlags)\n",
    "    dataloader.from_pickle(input_folder+file)\n",
    "\n",
    "# The D2C object is initialized with the DataLoader and the parameters of the process.\n",
    "    d2c = D2C(observations=dataloader.get_observations(), \n",
    "            dags=dataloader.get_dags(), \n",
    "            couples_to_consider_per_dag=COUPLES_TO_CONSIDER_PER_DAG, \n",
    "            MB_size=MB_SIZE, \n",
    "            n_variables=n_variables, \n",
    "            maxlags=maxlags,\n",
    "            seed=SEED,\n",
    "            n_jobs=N_JOBS,\n",
    "            full=True,\n",
    "            quantiles=True,\n",
    "            normalize=True,\n",
    "            cmi='cmiknn_3',\n",
    "            mb_estimator= 'ts_past')\n",
    "\n",
    "    d2c.initialize() # initializes the D2C object\n",
    "\n",
    "    descriptors_df = d2c.get_descriptors_df()  # computes the descriptors\n",
    "\n",
    "    descriptors_df.insert(0, 'process_id', gen_process_number)\n",
    "    descriptors_df.insert(2, 'n_variables', n_variables)\n",
    "    descriptors_df.insert(3, 'max_neighborhood_size', max_neighborhood_size)\n",
    "    descriptors_df.insert(4, 'noise_std', noise_std)\n",
    "\n",
    "    # The descriptors are saved in the output folder as a pickle file.\n",
    "    descriptors_df.to_pickle(output_folder+f'P{gen_process_number}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std}_MB{MB_SIZE}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "\n",
    "to_dos = []\n",
    "\n",
    "# This loop gets a list of all the files to be processed\n",
    "for testing_file in sorted(os.listdir(data_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "          \n",
    "        if noise_std != 0.01: # if the noise is different we skip the file\n",
    "            continue\n",
    "\n",
    "        if max_neighborhood_size != 2: # if the max_neighborhood_size is different we skip the file\n",
    "            continue\n",
    "\n",
    "        to_dos.append(testing_file) # we add the file to the list (to_dos) to be processed\n",
    "\n",
    "# sort to_dos by number of variables\n",
    "to_dos_5_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 5]\n",
    "# to_dos_10_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 10]\n",
    "# to_dos_25_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 25]\n",
    "\n",
    "# we create a dictionary with the lists of files to be processed\n",
    "todos = {'5': to_dos_5_variables} # , '10': to_dos_10_variables, '25': to_dos_25_variables\n",
    "\n",
    "# we create a dictionary to store the results\n",
    "dfs = []\n",
    "descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/KnnCMI/TD2C_PastFut/'\n",
    "\n",
    "# Re-save pickle files with protocol 4\n",
    "for testing_file in sorted(os.listdir(descriptors_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        file_path = os.path.join(descriptors_root, testing_file)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Re-save with protocol 4\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(data, f, protocol=4)\n",
    "\n",
    "# This loop gets the descriptors for the files to be processed\n",
    "for testing_file in sorted(os.listdir(descriptors_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        df = pd.read_pickle(os.path.join(descriptors_root, testing_file))\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            dfs.append(df)\n",
    "\n",
    "# we concatenate the descriptors\n",
    "descriptors_training = pd.concat(dfs, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loop does the following:\n",
    "# 1. Creates some dictionaries to store the results\n",
    "# 2. Loads the training data\n",
    "# 3. Trains the model\n",
    "# 4. Evaluates the model\n",
    "# 5. Stores the results in the dictionaries\n",
    "# 6. Saves the dictionaries in a pickle file\n",
    "\n",
    "for n_vars, todo in todos.items():\n",
    "    td2c_past_rocs_process = {}\n",
    "    td2c_past_precision_process = {}\n",
    "    td2c_past_recall_process = {}\n",
    "    td2c_past_f1_process = {}\n",
    "    for testing_file in tqdm(todo):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "\n",
    "        # split training and testing data\n",
    "        training_data = descriptors_training.loc[descriptors_training['process_id'] != gen_process_number]\n",
    "        X_train = training_data.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "        y_train = training_data['is_causal']\n",
    "\n",
    "        testing_data = descriptors_training.loc[(descriptors_training['process_id'] == gen_process_number) & (descriptors_training['n_variables'] == n_variables) & (descriptors_training['max_neighborhood_size'] == max_neighborhood_size) & (descriptors_training['noise_std'] == noise_std)]\n",
    "\n",
    "        model = BalancedRandomForestClassifier(n_estimators=100, random_state=0, n_jobs=50, max_depth=None, sampling_strategy='auto', replacement=True, bootstrap=False)\n",
    "        # model = RandomForestClassifier(n_estimators=50, random_state=0, n_jobs=50, max_depth=10)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        rocs = {}\n",
    "        precisions = {}\n",
    "        recalls = {}\n",
    "        f1s = {}\n",
    "        for graph_id in range(40):\n",
    "            #load testing descriptors\n",
    "            test_df = testing_data.loc[testing_data['graph_id'] == graph_id]\n",
    "            test_df = test_df.sort_values(by=['edge_source','edge_dest']).reset_index(drop=True) # sort for coherence\n",
    "\n",
    "            X_test = test_df.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "            y_test = test_df['is_causal']\n",
    "\n",
    "            y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            roc = roc_auc_score(y_test, y_pred_proba)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            \n",
    "            rocs[graph_id] = roc\n",
    "            precisions[graph_id] = precision\n",
    "            recalls[graph_id] = recall\n",
    "            f1s[graph_id] = f1\n",
    "\n",
    "        td2c_past_rocs_process[gen_process_number] = rocs\n",
    "        td2c_past_precision_process[gen_process_number] = precisions\n",
    "        td2c_past_recall_process[gen_process_number] = recalls\n",
    "        td2c_past_f1_process[gen_process_number] = f1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle everything\n",
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/KnnCMI/journals/'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "with open(os.path.join(output_folder, f'journal_results_td2c_past_R_N5.pkl'), 'wb') as f:\n",
    "    everything = (td2c_past_rocs_process, td2c_past_precision_process, td2c_past_recall_process, td2c_past_f1_process)\n",
    "    pickle.dump(everything, f)\n",
    "\n",
    "# with open(os.path.join(output_folder, f'journal_results_d2c_R_N10.pkl'), 'wb') as f:\n",
    "#     everything = (d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process)\n",
    "#     pickle.dump(everything, f)\n",
    "\n",
    "# with open(os.path.join(output_folder, f'journal_results_d2c_R_N25.pkl'), 'wb') as f:\n",
    "#     everything = (d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process)\n",
    "#     pickle.dump(everything, f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################### LOAD DATA #####################################################################\n",
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/KnnCMI/journals/'\n",
    "\n",
    "with open(os.path.join(input_folder, 'journal_results_td2c_past_R_N5.pkl'), 'rb') as f:\n",
    "    TD2C_Ranking_PastFut_rocs_process, TD2C_Ranking_PastFut_precision_process, TD2C_Ranking_PastFut_recall_process, TD2C_Ranking_PastFut_f1_process = pickle.load(f) \n",
    "\n",
    "# with open(os.path.join(input_folder, 'journal_results_d2c_R_N10.pkl'), 'rb') as f:\n",
    "#     d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process = pickle.load(f)\n",
    "\n",
    "# with open(os.path.join(input_folder, 'journal_results_d2c_R_N25.pkl'), 'rb') as f:\n",
    "#     d2c_R_rocs_process, d2c_R_precision_process, d2c_R_recall_process, d2c_R_f1_process = pickle.load(f)\n",
    "\n",
    "\n",
    "##################################################################### PLOT #########################################################################\n",
    "\n",
    "df1 = pd.DataFrame(TD2C_Ranking_PastFut_rocs_process)\n",
    "\n",
    "# Combine data for boxplot\n",
    "combined_data = []\n",
    "\n",
    "for col in df1.columns:\n",
    "    combined_data.append(df1[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns:\n",
    "    labels.append(f'{col} TD2C_Past_Reg')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title('Boxplot of ROC-AUC scores for TD2C_Past method with KnnCMI to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('ROC-AUC score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative TD2C implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first try (failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the causal paths from the descriptors files for each process\n",
    "\n",
    "proc = [1,2,3,4,6,7,8,9,10,11,12,13,14,15,16,18,19,20]\n",
    "td2c_descriptors = {}\n",
    "for i in proc:\n",
    "    td2c_desc = pd.read_pickle(f'/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C/P{i}_N5_Nj2_n0.01_MB2.pkl')\n",
    "    td2c_causal_paths = td2c_desc.loc[td2c_desc['is_causal'] == 1]\n",
    "    td2c_causal_paths = td2c_causal_paths.sort_values(by=['edge_source','edge_dest']).reset_index(drop=True)\n",
    "    td2c_causal_paths = td2c_causal_paths[['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size', 'noise_std', 'edge_source', 'edge_dest']]\n",
    "    # make unique the edge_source and edge_dest combinations\n",
    "    td2c_causal_paths = td2c_causal_paths.drop_duplicates(subset=['edge_source', 'edge_dest'])\n",
    "    td2c_descriptors[i] = td2c_causal_paths\n",
    "\n",
    "td2c_descriptors[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the graph for each process\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "# create a graph for each process\n",
    "for i in proc:\n",
    "    # get the descriptors for the process\n",
    "    td2c_causal_paths = td2c_descriptors[i]\n",
    "\n",
    "    # create a graph\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from(td2c_causal_paths[['edge_source', 'edge_dest']].values)\n",
    "\n",
    "# plot the graph\n",
    "plt.figure(figsize=(10,10))\n",
    "nx.draw(G, with_labels=True, node_size=1000, node_color='skyblue', font_size=10, font_weight='bold', font_color='black', edge_color='gray', pos=nx.spring_layout(G))\n",
    "plt.title(f'Graph for process {i}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a graph for each process\n",
    "\n",
    "# Define the list of processes to handle\n",
    "proc = [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20]\n",
    "td2c_descriptors = {}\n",
    "\n",
    "# Iterate through each process ID and process the corresponding pickle file\n",
    "for i in proc:\n",
    "    # Load the pickle file containing the data\n",
    "    td2c_desc = pd.read_pickle(f'/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C/P{i}_N5_Nj2_n0.01_MB2.pkl')\n",
    "    \n",
    "    # Filter rows where 'is_causal' is 1, indicating a causal relationship\n",
    "    td2c_causal_paths = td2c_desc.loc[td2c_desc['is_causal'] == 1]\n",
    "    \n",
    "    # Sort by 'edge_source' and 'edge_dest' to organize the causal paths\n",
    "    td2c_causal_paths = td2c_causal_paths.sort_values(by=['edge_source', 'edge_dest']).reset_index(drop=True)\n",
    "    \n",
    "    # Select relevant columns\n",
    "    td2c_causal_paths = td2c_causal_paths[['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size', 'noise_std', 'edge_source', 'edge_dest']]\n",
    "    \n",
    "    # Remove duplicate causal paths based on 'edge_source' and 'edge_dest' combinations\n",
    "    td2c_causal_paths = td2c_causal_paths.drop_duplicates(subset=['edge_source', 'edge_dest'])\n",
    "    \n",
    "    # Store the processed DataFrame in a dictionary keyed by the process ID\n",
    "    td2c_descriptors[i] = td2c_causal_paths\n",
    "\n",
    "# Example to view the causal paths for process 1\n",
    "# print(td2c_descriptors[1])\n",
    "\n",
    "# Initialize a dictionary to store the DAGs for each process\n",
    "dags = {}\n",
    "\n",
    "for process_id, df in td2c_descriptors.items():\n",
    "    dags[process_id] = {}\n",
    "    unique_graph_ids = df['graph_id'].unique()\n",
    "    \n",
    "    for graph_id in unique_graph_ids:\n",
    "        # Filter the DataFrame for the current graph_id\n",
    "        df_graph = df[df['graph_id'] == graph_id]\n",
    "        \n",
    "        # Initialize an empty directed graph\n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        # Add nodes\n",
    "        for j in range(df_graph['n_variables'].iloc[0]):\n",
    "            G.add_node(j)\n",
    "        \n",
    "        # Add edges based on causal relationships\n",
    "        for _, row in df_graph.iterrows():\n",
    "            G.add_edge(row['edge_source'], row['edge_dest'])\n",
    "        \n",
    "        # Store the graph in the dictionary\n",
    "        dags[process_id][graph_id] = G\n",
    "\n",
    "# Example to access and view the nodes and edges of the graph for process_id 1, graph_id 0\n",
    "dags[1][0].nodes, dags[1][0].edges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### second try (simply using new dags for second estimation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptors Generation (first estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C/iterative/initial/'\n",
    "DAGs_2 = {}\n",
    "\n",
    "# List of files to process\n",
    "to_process = []\n",
    "\n",
    "# Filtering the files to process\n",
    "for file in sorted(os.listdir(input_folder)):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    if noise_std != noise_std_filter or max_neighborhood_size != max_neighborhood_size_filter:\n",
    "        continue\n",
    "\n",
    "    to_process.append(file)\n",
    "\n",
    "# Create output folder if it does not exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Process each file and create new DAGs based on causal paths\n",
    "for file in tqdm(to_process):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    dataloader = DataLoader(n_variables=n_variables, maxlags=maxlags)\n",
    "    dataloader.from_pickle(input_folder + file)\n",
    "\n",
    "    d2c = D2C(\n",
    "        observations=dataloader.get_observations(),\n",
    "        dags=dataloader.get_dags(),\n",
    "        couples_to_consider_per_dag=COUPLES_TO_CONSIDER_PER_DAG,\n",
    "        MB_size=MB_SIZE,\n",
    "        n_variables=n_variables,\n",
    "        maxlags=maxlags,\n",
    "        seed=SEED,\n",
    "        n_jobs=N_JOBS,\n",
    "        full=True,\n",
    "        quantiles=True,\n",
    "        normalize=True,\n",
    "        cmi='original',\n",
    "        mb_estimator='ts',\n",
    "        top_vars=3\n",
    "    )\n",
    "\n",
    "    d2c.initialize()  # Initializes the D2C object\n",
    "    descriptors_df = d2c.get_descriptors_df()  # Computes the descriptors\n",
    "\n",
    "    # Extract causal paths to create new DAGs\n",
    "    new_dags = []\n",
    "    for dag in dataloader.get_dags():\n",
    "        new_dag = nx.DiGraph()  # Create a new directed graph\n",
    "        for index, row in descriptors_df.iterrows():\n",
    "            if row['is_causal'] == 1:\n",
    "                source = row['edge_source']\n",
    "                effect = row['edge_dest']\n",
    "                new_dag.add_edge(source, effect)  # Add causal relationships\n",
    "        new_dags.append(new_dag)\n",
    "\n",
    "    # Replace the original DAGs with new DAGs\n",
    "    # This assumes you want to use the new DAGs for further processing\n",
    "    # d2c.dags = new_dags  # Update DAGs in D2C object\n",
    "\n",
    "    # Save the new DAGs in the dictionary\n",
    "    DAGs_2[gen_process_number] = new_dags\n",
    "\n",
    "    # Save the descriptors along with new DAGs if needed\n",
    "    descriptors_df.insert(0, 'process_id', gen_process_number)\n",
    "    descriptors_df.insert(2, 'n_variables', n_variables)\n",
    "    descriptors_df.insert(3, 'max_neighborhood_size', max_neighborhood_size)\n",
    "    descriptors_df.insert(4, 'noise_std', noise_std)\n",
    "\n",
    "    descriptors_df.to_pickle(output_folder + f'P{gen_process_number}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std}_MB{MB_SIZE}.pkl')\n",
    "\n",
    "    # Run further estimation processes using the new DAGs as needed\n",
    "    # Example: d2c.run_estimation() # Call the estimation method if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_dags = dataloader.get_dags()\n",
    "old_dags[0].nodes, old_dags[0].edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptors Generation (second estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "output_folder_2 = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C/iterative/second_estimate/'\n",
    "\n",
    "# replace values in d2c.dags with the new DAGs_2\n",
    "for file in tqdm(to_process):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    dataloader = DataLoader(n_variables=n_variables, maxlags=maxlags)\n",
    "    dataloader.from_pickle(input_folder + file)\n",
    "\n",
    "    d2c_2 = D2C(\n",
    "        observations=dataloader.get_observations(),\n",
    "        dags=DAGs_2[gen_process_number],\n",
    "        couples_to_consider_per_dag=COUPLES_TO_CONSIDER_PER_DAG,\n",
    "        MB_size=MB_SIZE,\n",
    "        n_variables=n_variables,\n",
    "        maxlags=maxlags,\n",
    "        seed=SEED,\n",
    "        n_jobs=N_JOBS,\n",
    "        full=True,\n",
    "        quantiles=True,\n",
    "        normalize=True,\n",
    "        cmi='original',\n",
    "        mb_estimator='ts',\n",
    "        top_vars=3\n",
    "        )\n",
    "    \n",
    "    d2c_2.initialize() # initializes the D2C object\n",
    "\n",
    "    descriptors_df_2 = d2c_2.get_descriptors_df()  # computes the descriptors\n",
    "\n",
    "    descriptors_df_2.insert(0, 'process_id', gen_process_number)\n",
    "    descriptors_df_2.insert(2, 'n_variables', n_variables)\n",
    "    descriptors_df_2.insert(3, 'max_neighborhood_size', max_neighborhood_size)\n",
    "    descriptors_df_2.insert(4, 'noise_std', noise_std)\n",
    "\n",
    "    # The descriptors are saved in the output folder as a pickle file.\n",
    "    descriptors_df_2.to_pickle(output_folder_2+f'P{gen_process_number}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std}_MB{MB_SIZE}.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Classifier (initial estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "\n",
    "to_dos = []\n",
    "\n",
    "# This loop gets a list of all the files to be processed\n",
    "for testing_file in sorted(os.listdir(data_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "          \n",
    "        if noise_std != 0.01: # if the noise is different we skip the file\n",
    "            continue\n",
    "\n",
    "        if max_neighborhood_size != 2: # if the max_neighborhood_size is different we skip the file\n",
    "            continue\n",
    "\n",
    "        to_dos.append(testing_file) # we add the file to the list (to_dos) to be processed\n",
    "\n",
    "# sort to_dos by number of variables\n",
    "to_dos_5_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 5]\n",
    "# to_dos_10_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 10]\n",
    "# to_dos_25_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 25]\n",
    "\n",
    "# we create a dictionary with the lists of files to be processed\n",
    "todos = {'5': to_dos_5_variables} # , '10': to_dos_10_variables, '25': to_dos_25_variables\n",
    "\n",
    "# we create a dictionary to store the results\n",
    "dfs = []\n",
    "descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C/iterative/initial/'\n",
    "\n",
    "# Re-save pickle files with protocol 4\n",
    "for testing_file in sorted(os.listdir(descriptors_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        file_path = os.path.join(descriptors_root, testing_file)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Re-save with protocol 4\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(data, f, protocol=4)\n",
    "\n",
    "# This loop gets the descriptors for the files to be processed\n",
    "for testing_file in sorted(os.listdir(descriptors_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        df = pd.read_pickle(os.path.join(descriptors_root, testing_file))\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            dfs.append(df)\n",
    "\n",
    "# we concatenate the descriptors\n",
    "descriptors_training = pd.concat(dfs, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Classifier (second estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "\n",
    "to_dos_2 = []\n",
    "\n",
    "# This loop gets a list of all the files to be processed\n",
    "for testing_file in sorted(os.listdir(data_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "          \n",
    "        if noise_std != 0.01: # if the noise is different we skip the file\n",
    "            continue\n",
    "\n",
    "        if max_neighborhood_size != 2: # if the max_neighborhood_size is different we skip the file\n",
    "            continue\n",
    "\n",
    "        to_dos_2.append(testing_file) # we add the file to the list (to_dos) to be processed\n",
    "\n",
    "# sort to_dos by number of variables\n",
    "to_dos_5_variables_2 = [file for file in to_dos_2 if int(file.split('_')[1][1:]) == 5]\n",
    "# to_dos_10_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 10]\n",
    "# to_dos_25_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 25]\n",
    "\n",
    "# we create a dictionary with the lists of files to be processed\n",
    "todos_2 = {'5': to_dos_5_variables_2} # , '10': to_dos_10_variables, '25': to_dos_25_variables\n",
    "\n",
    "# we create a dictionary to store the results\n",
    "dfs_2 = []\n",
    "descriptors_root_2 = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C/iterative/second_estimate/'\n",
    "\n",
    "# Re-save pickle files with protocol 4\n",
    "for testing_file in sorted(os.listdir(descriptors_root_2)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        file_path = os.path.join(descriptors_root_2, testing_file)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Re-save with protocol 4\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(data, f, protocol=4)\n",
    "\n",
    "# This loop gets the descriptors for the files to be processed\n",
    "for testing_file in sorted(os.listdir(descriptors_root_2)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        df = pd.read_pickle(os.path.join(descriptors_root_2, testing_file))\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            dfs_2.append(df)\n",
    "\n",
    "# we concatenate the descriptors\n",
    "descriptors_training_2 = pd.concat(dfs_2, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics (initial estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loop does the following:\n",
    "# 1. Creates some dictionaries to store the results\n",
    "# 2. Loads the training data\n",
    "# 3. Trains the model\n",
    "# 4. Evaluates the model\n",
    "# 5. Stores the results in the dictionaries\n",
    "# 6. Saves the dictionaries in a pickle file\n",
    "\n",
    "for n_vars, todo in todos.items():\n",
    "    td2c_rocs_process = {}\n",
    "    td2c_precision_process = {}\n",
    "    td2c_recall_process = {}\n",
    "    td2c_f1_process = {}\n",
    "    for testing_file in tqdm(todo):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "\n",
    "        # split training and testing data\n",
    "        training_data = descriptors_training.loc[descriptors_training['process_id'] != gen_process_number]\n",
    "        X_train = training_data.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "        y_train = training_data['is_causal']\n",
    "\n",
    "        testing_data = descriptors_training.loc[(descriptors_training['process_id'] == gen_process_number) & (descriptors_training['n_variables'] == n_variables) & (descriptors_training['max_neighborhood_size'] == max_neighborhood_size) & (descriptors_training['noise_std'] == noise_std)]\n",
    "\n",
    "        model = BalancedRandomForestClassifier(n_estimators=100, random_state=0, n_jobs=50, max_depth=None, sampling_strategy='auto', replacement=True, bootstrap=False)\n",
    "        # model = RandomForestClassifier(n_estimators=50, random_state=0, n_jobs=50, max_depth=10)\n",
    "\n",
    "        model = model.fit(X_train, y_train)\n",
    "\n",
    "        rocs = {}\n",
    "        precisions = {}\n",
    "        recalls = {}\n",
    "        f1s = {}\n",
    "        for graph_id in range(40):\n",
    "            #load testing descriptors\n",
    "            test_df = testing_data.loc[testing_data['graph_id'] == graph_id]\n",
    "            test_df = test_df.sort_values(by=['edge_source','edge_dest']).reset_index(drop=True) # sort for coherence\n",
    "\n",
    "            X_test = test_df.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "            y_test = test_df['is_causal']\n",
    "\n",
    "            y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            roc = roc_auc_score(y_test, y_pred_proba)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            \n",
    "            rocs[graph_id] = roc\n",
    "            precisions[graph_id] = precision\n",
    "            recalls[graph_id] = recall\n",
    "            f1s[graph_id] = f1\n",
    "\n",
    "        td2c_rocs_process[gen_process_number] = rocs\n",
    "        td2c_precision_process[gen_process_number] = precisions\n",
    "        td2c_recall_process[gen_process_number] = recalls\n",
    "        td2c_f1_process[gen_process_number] = f1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics (second estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'todos_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# This loop does the following:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 1. Creates some dictionaries to store the results\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 2. Loads the training data\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 5. Stores the results in the dictionaries\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 6. Saves the dictionaries in a pickle file\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_vars, todo \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtodos_2\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     10\u001b[0m     td2c_rocs_process_2 \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     11\u001b[0m     td2c_precision_process_2 \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'todos_2' is not defined"
     ]
    }
   ],
   "source": [
    "# This loop does the following:\n",
    "# 1. Creates some dictionaries to store the results\n",
    "# 2. Loads the training data\n",
    "# 3. Trains the model\n",
    "# 4. Evaluates the model\n",
    "# 5. Stores the results in the dictionaries\n",
    "# 6. Saves the dictionaries in a pickle file\n",
    "\n",
    "for n_vars, todo in todos_2.items():\n",
    "    td2c_rocs_process_2 = {}\n",
    "    td2c_precision_process_2 = {}\n",
    "    td2c_recall_process_2 = {}\n",
    "    td2c_f1_process_2 = {}\n",
    "    causal_df = {}\n",
    "    for testing_file in tqdm(todo):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "\n",
    "        # split training and testing data\n",
    "        training_data = descriptors_training_2.loc[descriptors_training_2['process_id'] != gen_process_number]\n",
    "        X_train = training_data.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "        y_train = training_data['is_causal']\n",
    "\n",
    "        testing_data = descriptors_training_2.loc[(descriptors_training_2['process_id'] == gen_process_number) & (descriptors_training_2['n_variables'] == n_variables) & (descriptors_training_2['max_neighborhood_size'] == max_neighborhood_size) & (descriptors_training_2['noise_std'] == noise_std)]\n",
    "\n",
    "        model_2 = BalancedRandomForestClassifier(n_estimators=100, random_state=0, n_jobs=50, max_depth=None, sampling_strategy='auto', replacement=True, bootstrap=False)\n",
    "        # model = RandomForestClassifier(n_estimators=50, random_state=0, n_jobs=50, max_depth=10)\n",
    "\n",
    "        model_2.fit(X_train, y_train)\n",
    "\n",
    "        rocs = {}\n",
    "        precisions = {}\n",
    "        recalls = {}\n",
    "        f1s = {}\n",
    "        for graph_id in range(40):\n",
    "            #load testing descriptors\n",
    "            test_df = testing_data.loc[testing_data['graph_id'] == graph_id]\n",
    "            test_df = test_df.sort_values(by=['edge_source','edge_dest']).reset_index(drop=True) # sort for coherence\n",
    "\n",
    "            X_test = test_df.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "            y_test = test_df['is_causal']\n",
    "\n",
    "            y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            roc = roc_auc_score(y_test, y_pred_proba)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            \n",
    "            rocs[graph_id] = roc\n",
    "            precisions[graph_id] = precision\n",
    "            recalls[graph_id] = recall\n",
    "            f1s[graph_id] = f1\n",
    "\n",
    "        td2c_rocs_process_2[gen_process_number] = rocs\n",
    "        td2c_precision_process_2[gen_process_number] = precisions\n",
    "        td2c_recall_process_2[gen_process_number] = recalls\n",
    "        td2c_f1_process_2[gen_process_number] = f1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pickle everything initial estimation\n",
    "# output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/journals/iterative/initial/'\n",
    "\n",
    "# # Create the folder if it doesn't exist\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.makedirs(output_folder)\n",
    "\n",
    "# with open(os.path.join(output_folder, f'journal_results_td2c_R_N5.pkl'), 'wb') as f:\n",
    "#     everything = (td2c_rocs_process, td2c_precision_process, td2c_recall_process, td2c_f1_process)\n",
    "#     pickle.dump(everything, f)\n",
    "\n",
    "\n",
    "# pickle everything second estimation\n",
    "output_folder_2 = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/journals/iterative/second_estimation/'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(output_folder_2):\n",
    "    os.makedirs(output_folder_2)\n",
    "\n",
    "with open(os.path.join(output_folder_2, f'journal_results_td2c_R_N5_2.pkl'), 'wb') as f:\n",
    "    everything_2 = (td2c_rocs_process_2, td2c_precision_process_2, td2c_recall_process_2, td2c_f1_process_2)\n",
    "    pickle.dump(everything_2, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################### LOAD DATA #####################################################################\n",
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/journals/iterative/initial/'\n",
    "input_folder_2 = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/journals/iterative/second_estimation/'\n",
    "\n",
    "\n",
    "with open(os.path.join(input_folder, 'journal_results_td2c_R_N5.pkl'), 'rb') as f:\n",
    "    TD2C_rocs_process, TD2C_precision_process, TD2C_recall_process, TD2C_f1_process = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(input_folder_2, 'journal_results_td2c_R_N5_2.pkl'), 'rb') as f:\n",
    "    TD2C_rocs_process_2, TD2C_precision_process_2, TD2C_recall_process_2, TD2C_f1_process_2 = pickle.load(f)\n",
    "\n",
    "\n",
    "##################################################################### PLOT #########################################################################\n",
    "\n",
    "df1 = pd.DataFrame(TD2C_rocs_process)\n",
    "\n",
    "df2 = pd.DataFrame(TD2C_rocs_process_2)\n",
    "\n",
    "# Combine data for boxplot\n",
    "combined_data = []\n",
    "\n",
    "for col in df1.columns:\n",
    "    combined_data.append(df1[col])\n",
    "    combined_data.append(df2[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns:\n",
    "    labels.append(f'{col} TD2C_Fist_Estimation')\n",
    "    labels.append(f'{col} TD2C_Second_Estimation')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title('Boxplot of ROC-AUC scores for TD2C method with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('ROC-AUC score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.mean().mean(), df2.mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot th two means\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot([df1.mean().values, df2.mean().values], patch_artist=True)\n",
    "plt.xticks([1, 2], ['TD2C First Estimation', 'TD2C Second Estimation'])\n",
    "plt.title('Boxplot of the means of the ROC-AUC scores for TD2C method with Regression to estimate MI (5 variables processes)')\n",
    "plt.ylabel('ROC-AUC score')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### third try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptors Generation (first estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C/iterative/initial/'\n",
    "DAGs_2 = {}\n",
    "\n",
    "# List of files to process\n",
    "to_process = []\n",
    "\n",
    "# Filtering the files to process\n",
    "for file in sorted(os.listdir(input_folder)):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    if noise_std != noise_std_filter or max_neighborhood_size != max_neighborhood_size_filter:\n",
    "        continue\n",
    "\n",
    "    to_process.append(file)\n",
    "\n",
    "# Create output folder if it does not exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Process each file and create new DAGs based on causal paths\n",
    "for file in tqdm(to_process):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    dataloader = DataLoader(n_variables=n_variables, maxlags=maxlags)\n",
    "    dataloader.from_pickle(input_folder + file)\n",
    "\n",
    "    d2c = D2C(\n",
    "        observations=dataloader.get_observations(),\n",
    "        dags=dataloader.get_dags(),\n",
    "        couples_to_consider_per_dag=COUPLES_TO_CONSIDER_PER_DAG,\n",
    "        MB_size=MB_SIZE,\n",
    "        n_variables=n_variables,\n",
    "        maxlags=maxlags,\n",
    "        seed=SEED,\n",
    "        n_jobs=N_JOBS,\n",
    "        full=True,\n",
    "        quantiles=True,\n",
    "        normalize=True,\n",
    "        cmi='original',\n",
    "        mb_estimator='original',\n",
    "        top_vars=3\n",
    "    )\n",
    "\n",
    "    d2c.initialize()  # Initializes the D2C object\n",
    "    descriptors_df = d2c.get_descriptors_df()  # Computes the descriptors\n",
    "\n",
    "    # Extract causal paths to create new DAGs\n",
    "    new_dags = []\n",
    "    for dag in dataloader.get_dags():\n",
    "        new_dag = nx.DiGraph()  # Create a new directed graph\n",
    "        for index, row in descriptors_df.iterrows():\n",
    "            if row['is_causal'] == 1:\n",
    "                source = row['edge_source']\n",
    "                effect = row['edge_dest']\n",
    "                new_dag.add_edge(source, effect)  # Add causal relationships\n",
    "        new_dags.append(new_dag)\n",
    "\n",
    "    # Replace the original DAGs with new DAGs\n",
    "    # This assumes you want to use the new DAGs for further processing\n",
    "    # d2c.dags = new_dags  # Update DAGs in D2C object\n",
    "\n",
    "    # Save the new DAGs in the dictionary\n",
    "    DAGs_2[gen_process_number] = new_dags\n",
    "\n",
    "    # Save the descriptors along with new DAGs if needed\n",
    "    descriptors_df.insert(0, 'process_id', gen_process_number)\n",
    "    descriptors_df.insert(2, 'n_variables', n_variables)\n",
    "    descriptors_df.insert(3, 'max_neighborhood_size', max_neighborhood_size)\n",
    "    descriptors_df.insert(4, 'noise_std', noise_std)\n",
    "\n",
    "    descriptors_df.to_pickle(output_folder + f'P{gen_process_number}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std}_MB{MB_SIZE}.pkl')\n",
    "\n",
    "    # Run further estimation processes using the new DAGs as needed\n",
    "    # Example: d2c.run_estimation() # Call the estimation method if available\n",
    "    \n",
    "# save the new DAGs in a pickle file\n",
    "with open(os.path.join(output_folder, 'DAGs_2.pkl'), 'wb') as f:\n",
    "    pickle.dump(DAGs_2, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DAG modifying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### enlarge extracted dag using Meek rules and other rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT OLD DAGs\n",
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C/iterative/initial/'\n",
    "\n",
    "\n",
    "# print original dags from data\n",
    "dataloader = DataLoader(n_variables=5, maxlags=5)\n",
    "dataloader.from_pickle('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/P1_N5_Nj2_n0.01.pkl')\n",
    "old_dags = dataloader.get_dags()\n",
    "old_dags[0].nodes, old_dags[0].edges\n",
    "\n",
    "# EXTRACT NEW DAGs\n",
    "\n",
    "# load the new DAGs\n",
    "with open(os.path.join(output_folder, 'DAGs_2.pkl'), 'rb') as f:\n",
    "    DAGs_2 = pickle.load(f)\n",
    "\n",
    "# create a dictionary to store the DAGS_2\n",
    "dags_2 = {}\n",
    "for process_id, dags in DAGs_2.items():\n",
    "    dags_2[process_id] = {}\n",
    "    for i, dag in enumerate(dags):\n",
    "        dags_2[process_id][i] = dag\n",
    "\n",
    "# print old DAGs\n",
    "print(f'old nodes: {old_dags[0].nodes}')\n",
    "print(f'old edges: {old_dags[0].edges}')\n",
    "# print new DAGs\n",
    "print(f'new nodes: {dags_2[1][0].nodes}')\n",
    "print(f'new edges: {dags_2[1][0].edges}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of variables and the total number of nodes\n",
    "n_variables = 5\n",
    "n_nodes = 30\n",
    "\n",
    "# Create a mapping for nodes\n",
    "node_mapping = {}\n",
    "\n",
    "# Loop over the nodes and assign names\n",
    "for node in range(n_nodes):\n",
    "    time_step = node // n_variables  # Determine the time step\n",
    "    var_index = node % n_variables  # Determine the variable index\n",
    "    if (time_step + (n_nodes // n_variables) - 6) != 0:\n",
    "        node_name = f\"X_{var_index}_(t-{time_step + (n_nodes // n_variables) - 6})\"  # Adjusting for a reference time step\n",
    "    else:\n",
    "        node_name = f\"X_{var_index}_(t)\"  # Adjusting for a reference time step\n",
    "    node_mapping[node] = node_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the nodes in the old_dags with the new names\n",
    "old_dags_renamed = []\n",
    "for old_dag in old_dags:\n",
    "    new_dag = nx.relabel_nodes(old_dag, node_mapping)\n",
    "    old_dags_renamed.append(new_dag)\n",
    "\n",
    "# print the nodes and edges of the first DAG\n",
    "print(f'old nodes: {old_dags_renamed[0].nodes}')\n",
    "\n",
    "# now modify the edges of the old_dags_renamed\n",
    "for old_dag in old_dags_renamed:\n",
    "    for edge in old_dag.edges:\n",
    "        old_dag.edges[edge]['weight'] = 1\n",
    "\n",
    "# print the edges of the first DAG\n",
    "print(f'old edges: {old_dags_renamed[0].edges}')\n",
    "\n",
    "\n",
    "# create a mapping that goes to the original names of the old_dags nodes to the new names\n",
    "node_mapping_reverse = {v: k for k, v in node_mapping.items()}\n",
    "\n",
    "# rename the nodes in the DAGs_2 with the new names\n",
    "dags_2_renamed = {}\n",
    "for process_id, dags in dags_2.items():\n",
    "    dags_2_renamed[process_id] = {}\n",
    "    for i, dag in dags.items():\n",
    "        new_dag = nx.relabel_nodes(dag, node_mapping)\n",
    "        dags_2_renamed[process_id][i] = new_dag\n",
    "\n",
    "# print the nodes and edges of the first DAG\n",
    "print(f'new nodes: {dags_2_renamed[1][0].nodes}')\n",
    "\n",
    "# rename the edges of the dags_2_renamed\n",
    "for process_id, dags in dags_2_renamed.items():\n",
    "    for i, dag in dags.items():\n",
    "        for edge in dag.edges:\n",
    "            dag.edges[edge]['weight'] = 1\n",
    "\n",
    "# print the edges of the first DAG\n",
    "print(f'new edges: {dags_2_renamed[1][0].edges}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and axis\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Define node positions manually\n",
    "pos = {\n",
    "    'X_0_(t-5)': (0, 5), 'X_1_(t-5)': (1, 5), 'X_2_(t-5)': (2, 5), 'X_3_(t-5)': (3, 5), 'X_4_(t-5)': (4, 5),\n",
    "    'X_0_(t-4)': (0, 4), 'X_1_(t-4)': (1, 4), 'X_2_(t-4)': (2, 4), 'X_3_(t-4)': (3, 4), 'X_4_(t-4)': (4, 4),\n",
    "    'X_0_(t-3)': (0, 3), 'X_1_(t-3)': (1, 3), 'X_2_(t-3)': (2, 3), 'X_3_(t-3)': (3, 3), 'X_4_(t-3)': (4, 3),\n",
    "    'X_0_(t-2)': (0, 2), 'X_1_(t-2)': (1, 2), 'X_2_(t-2)': (2, 2), 'X_3_(t-2)': (3, 2), 'X_4_(t-2)': (4, 2),\n",
    "    'X_0_(t-1)': (0, 1), 'X_1_(t-1)': (1, 1), 'X_2_(t-1)': (2, 1), 'X_3_(t-1)': (3, 1), 'X_4_(t-1)': (4, 1),\n",
    "    'X_0_(t)': (0, 0), 'X_1_(t)': (1, 0), 'X_2_(t)': (2, 0), 'X_3_(t)': (3, 0), 'X_4_(t)': (4, 0)\n",
    "}\n",
    "\n",
    "# Draw the graph with the manually set positions\n",
    "nx.draw(old_dags_renamed[0], pos, with_labels=True, node_size=1000, \n",
    "        node_color='skyblue', font_size=10, font_weight='bold', \n",
    "        font_color='black', edge_color='gray')\n",
    "\n",
    "# Set title\n",
    "plt.title('original edges')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# save the plot as a pdf\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/iterative/original_edges.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the dag dropping nodes at istants t-5 and t-4\n",
    "old_dags_reduced = []\n",
    "\n",
    "for old_dag in old_dags_renamed:\n",
    "    new_dag = old_dag.copy()\n",
    "    nodes_to_remove = ['X_0_(t-5)', 'X_1_(t-5)', 'X_2_(t-5)', 'X_3_(t-5)', 'X_4_(t-5)', 'X_0_(t-4)', 'X_1_(t-4)', 'X_2_(t-4)', 'X_3_(t-4)', 'X_4_(t-4)', 'X_0_(t-3)', 'X_1_(t-3)', 'X_2_(t-3)', 'X_3_(t-3)', 'X_4_(t-3)']\n",
    "    new_dag.remove_nodes_from(nodes_to_remove)\n",
    "    old_dags_reduced.append(new_dag)\n",
    "\n",
    "# print the nodes and edges of the first DAG\n",
    "print(f'old nodes: {old_dags_reduced[0].nodes}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the reduced dag\n",
    "# Create figure and axis\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Draw the graph with the manually set positions\n",
    "nx.draw(old_dags_reduced[0], pos, with_labels=True, node_size=1000, \n",
    "        node_color='skyblue', font_size=10, font_weight='bold', \n",
    "        font_color='black', edge_color='gray')\n",
    "\n",
    "# Set title\n",
    "plt.title('original edges reduced')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING RULES TO ENLARGE THE OLD DAGs\n",
    "\n",
    "# count how many edges strart from each node in one old_dag\n",
    "edges_count = {}\n",
    "for edge in old_dags_renamed[0].edges:\n",
    "    if edge[0] in edges_count:\n",
    "        edges_count[edge[0]] += 1\n",
    "    else:\n",
    "        edges_count[edge[0]] = 1\n",
    "\n",
    "# sort the edges_count\n",
    "edges_count = dict(sorted(edges_count.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# print the edges_count\n",
    "edges_count\n",
    "\n",
    "# do th esame fo all the nodes\n",
    "edges_dest_all = {}\n",
    "for node in old_dags_renamed[0].nodes:\n",
    "    edges_dest = []\n",
    "    for edge in old_dags_renamed[0].edges:\n",
    "        if edge[0] == node:\n",
    "            edges_dest.append(edge[1])\n",
    "    edges_dest_all[node] = edges_dest\n",
    "\n",
    "# print the edges_dest_all\n",
    "edges_dest_all\n",
    "\n",
    "# merge the two dictionaries\n",
    "nodes_edges_1 = {}\n",
    "for node in edges_count.keys():\n",
    "    nodes_edges_1[node] = (edges_count[node], edges_dest_all[node])\n",
    "\n",
    "# print the nodes_edges\n",
    "nodes_edges_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure and axis\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# draw the graph for the new DAG\n",
    "nx.draw(dags_2_renamed[1][0], pos, with_labels=True, node_size=1000, \n",
    "        node_color='green', font_size=10, font_weight='bold', \n",
    "        font_color='black', edge_color='gray')\n",
    "\n",
    "# set title\n",
    "plt.title('new edges')\n",
    "plt.show()\n",
    "\n",
    "# save the plot as a pdf\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/iterative/new_edges.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING RULES TO ENLARGE THE NEW DAGs\n",
    "\n",
    "# count how many edges strart from each node in one old_dag\n",
    "edges_count = {}\n",
    "for edge in dags_2_renamed[1][0].edges:\n",
    "    if edge[0] in edges_count:\n",
    "        edges_count[edge[0]] += 1\n",
    "    else:\n",
    "        edges_count[edge[0]] = 1\n",
    "    \n",
    "# sort the edges_count\n",
    "edges_count = dict(sorted(edges_count.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# do th esame fo all the nodes\n",
    "edges_dest_all = {}\n",
    "for node in dags_2_renamed[1][0].nodes:\n",
    "    edges_dest = []\n",
    "    for edge in dags_2_renamed[1][0].edges:\n",
    "        if edge[0] == node:\n",
    "            edges_dest.append(edge[1])\n",
    "    edges_dest_all[node] = edges_dest\n",
    "\n",
    "# merge the two dictionaries\n",
    "nodes_edges = {}\n",
    "for node in edges_count.keys():\n",
    "    nodes_edges[node] = (edges_count[node], edges_dest_all[node])\n",
    "\n",
    "# print the nodes_edges\n",
    "nodes_edges_2 = dict(sorted(nodes_edges.items(), key=lambda item: item[1][0], reverse=True))\n",
    "nodes_edges_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count common elemnts in old_dags_renamed[0].edges and dags_2_renamed[1][0].edges\n",
    "common_edges = set(old_dags_renamed[0].edges).intersection(dags_2_renamed[1][0].edges)\n",
    "len(common_edges)\n",
    "\n",
    "# print the common edges\n",
    "common_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure and axis\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# draw the graph for the common edges\n",
    "nx.draw(nx.DiGraph(common_edges), pos, with_labels=True, node_size=1000, \n",
    "        node_color='lightgreen', font_size=10, font_weight='bold', \n",
    "        font_color='black', edge_color='gray')\n",
    "\n",
    "# set title\n",
    "plt.title('common edges for original and new dags')\n",
    "plt.show()\n",
    "\n",
    "# save the plot as a pdf\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/iterative/common_edges.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix between the old_dags_reduced[0].edges and the new dags_2_renamed[1][0].edges\n",
    "confusion_matrix = np.zeros((2, 2))\n",
    "\n",
    "for edge in old_dags_reduced[0].edges:\n",
    "    if edge in dags_2_renamed[1][0].edges:\n",
    "        confusion_matrix[0, 0] += 1\n",
    "    else:\n",
    "        confusion_matrix[0, 1] += 1\n",
    "\n",
    "for edge in dags_2_renamed[1][0].edges:\n",
    "    if edge not in old_dags_reduced[0].edges:\n",
    "        confusion_matrix[1, 0] += 1\n",
    "\n",
    "confusion_matrix[1, 1] = len(dags_2_renamed[1][0].edges) - confusion_matrix[1, 0]\n",
    "\n",
    "# print the confusion matrix\n",
    "confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the elements in new_dags that are not in common_edges\n",
    "new_edges = set(dags_2_renamed[1][0].edges).difference(common_edges)\n",
    "len(new_edges)\n",
    "\n",
    "# print the new_edges\n",
    "new_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure and axis\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# draw the graph for the new edges\n",
    "nx.draw(nx.DiGraph(new_edges), pos, with_labels=True, node_size=1000, \n",
    "        node_color='lightcoral', font_size=10, font_weight='bold', \n",
    "        font_color='black', edge_color='gray')\n",
    "\n",
    "# set title\n",
    "plt.title('edges in new dags that are not in original dags')\n",
    "plt.show()\n",
    "\n",
    "# save the plot as a file\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/iterative/new_edges_not_in_original.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count edges per each node in the new_edges\n",
    "edges_count = {}\n",
    "for edge in new_edges:\n",
    "    if edge[0] in edges_count:\n",
    "        edges_count[edge[0]] += 1\n",
    "    else:\n",
    "        edges_count[edge[0]] = 1\n",
    "\n",
    "# sort the edges_count\n",
    "edges_count = dict(sorted(edges_count.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# print the edges_count\n",
    "edges_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print confusion matrix between old_dags_renamed[0].edges and dags_2_renamed[1][0].edges\n",
    "confusion_matrix = np.zeros((2, 2))\n",
    "for edge in old_dags_renamed[0].edges:\n",
    "    if edge in dags_2_renamed[1][0].edges:\n",
    "        confusion_matrix[0, 0] += 1\n",
    "    else:\n",
    "        confusion_matrix[0, 1] += 1\n",
    "\n",
    "for edge in dags_2_renamed[1][0].edges:\n",
    "    if edge not in old_dags_renamed[0].edges:\n",
    "        confusion_matrix[1, 0] += 1\n",
    "\n",
    "confusion_matrix[1, 1] = len(dags_2_renamed[1][0].edges) - confusion_matrix[1, 0]\n",
    "\n",
    "# print precision\n",
    "precision = confusion_matrix[0, 0] / (confusion_matrix[0, 0] + confusion_matrix[0, 1])\n",
    "# print recall\n",
    "recall = confusion_matrix[0, 0] / (confusion_matrix[0, 0] + confusion_matrix[1, 0])\n",
    "# print f1\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "precision, recall,f1,confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(common_edges))\n",
    "print(len(old_dags_reduced[0].edges))\n",
    "print(len(dags_2_renamed[1][0].edges))\n",
    "print(len(new_edges))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C/iterative/initial/'\n",
    "DAGs_2 = {}\n",
    "\n",
    "# List of files to process\n",
    "to_process = []\n",
    "\n",
    "# Filtering the files to process\n",
    "for file in sorted(os.listdir(input_folder)):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    if noise_std != noise_std_filter or max_neighborhood_size != max_neighborhood_size_filter:\n",
    "        continue\n",
    "\n",
    "    to_process.append(file)\n",
    "\n",
    "# Create output folder if it does not exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Process each file and create new DAGs based on causal paths\n",
    "for file in tqdm(to_process):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    dataloader = DataLoader(n_variables=n_variables, maxlags=maxlags)\n",
    "    dataloader.from_pickle(input_folder + file)\n",
    "\n",
    "    d2c = D2C(\n",
    "        observations=dataloader.get_observations(),\n",
    "        dags=dataloader.get_dags(),\n",
    "        couples_to_consider_per_dag=COUPLES_TO_CONSIDER_PER_DAG,\n",
    "        MB_size=MB_SIZE,\n",
    "        n_variables=n_variables,\n",
    "        maxlags=maxlags,\n",
    "        seed=SEED,\n",
    "        n_jobs=N_JOBS,\n",
    "        full=True,\n",
    "        quantiles=True,\n",
    "        normalize=True,\n",
    "        cmi='original',\n",
    "        mb_estimator='original',\n",
    "        top_vars=3\n",
    "    )\n",
    "\n",
    "    d2c.initialize()  # Initializes the D2C object\n",
    "    descriptors_df = d2c.get_descriptors_df()  # Computes the descriptors\n",
    "\n",
    "    # Extract causal paths to create new DAGs based on the causal paths including only elemetns in the common_edges\n",
    "    new_dags = []\n",
    "    for dag in dataloader.get_dags():\n",
    "        new_dag = nx.DiGraph()  # Create a new directed graph\n",
    "        for index, row in descriptors_df.iterrows():\n",
    "            if row['is_causal'] == 1:\n",
    "                source = row['edge_source']\n",
    "                effect = row['edge_dest']\n",
    "                if (source, effect) in common_edges:\n",
    "                    new_dag.add_edge(source, effect)  # Add causal relationships\n",
    "        new_dags.append(new_dag)\n",
    "\n",
    "    # Replace the original DAGs with new DAGs\n",
    "    # This assumes you want to use the new DAGs for further processing\n",
    "    # d2c.dags = new_dags  # Update DAGs in D2C object\n",
    "\n",
    "    # Save the new DAGs in the dictionary\n",
    "    DAGs_2[gen_process_number] = new_dags\n",
    "\n",
    "    # Save the descriptors along with new DAGs if needed\n",
    "    descriptors_df.insert(0, 'process_id', gen_process_number)\n",
    "    descriptors_df.insert(2, 'n_variables', n_variables)\n",
    "    descriptors_df.insert(3, 'max_neighborhood_size', max_neighborhood_size)\n",
    "    descriptors_df.insert(4, 'noise_std', noise_std)\n",
    "\n",
    "    descriptors_df.to_pickle(output_folder + f'P{gen_process_number}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std}_MB{MB_SIZE}.pkl')\n",
    "\n",
    "    # Run further estimation processes using the new DAGs as needed\n",
    "    # Example: d2c.run_estimation() # Call the estimation method if available\n",
    "    \n",
    "# save the new DAGs in a pickle file\n",
    "with open(os.path.join(output_folder, 'DAGs_2.pkl'), 'wb') as f:\n",
    "    pickle.dump(DAGs_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C/iterative/initial/'\n",
    "\n",
    "# create a DAGs_com file of the same type of DAGs_2 using the common_edges\n",
    "DAGs_com = {}\n",
    "DAGs_com[1] = {}\n",
    "DAGs_com[1][0] = nx.DiGraph(common_edges)\n",
    "\n",
    "DAGs_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show keys of the DAGs_com\n",
    "DAGs_2.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second estimation using the common_dag\n",
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C/iterative/second estimate/third_try/common/'\n",
    "dag_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C/iterative/initial/'\n",
    "# load the com dags\n",
    "with open(os.path.join(dag_folder, 'DAGs_com.pkl'), 'rb') as f:\n",
    "    dags_2_com = pickle.load(f)\n",
    "\n",
    "DAGs_common_3 = {}\n",
    "\n",
    "# List of files to process\n",
    "to_process = []\n",
    "\n",
    "# Filtering the files to process\n",
    "for file in sorted(os.listdir(input_folder)):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    if noise_std != noise_std_filter or max_neighborhood_size != max_neighborhood_size_filter:\n",
    "        continue\n",
    "\n",
    "    to_process.append(file)\n",
    "\n",
    "# Create output folder if it does not exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Process each file and create new DAGs based on causal paths\n",
    "for file in tqdm(to_process):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    dataloader = DataLoader(n_variables=n_variables, maxlags=maxlags)\n",
    "    dataloader.from_pickle(input_folder + file)\n",
    "\n",
    "    d2c = D2C(\n",
    "        observations=dataloader.get_observations(),\n",
    "        dags=dags_2_com[gen_process_number],\n",
    "        couples_to_consider_per_dag=COUPLES_TO_CONSIDER_PER_DAG,\n",
    "        MB_size=MB_SIZE,\n",
    "        n_variables=n_variables,\n",
    "        maxlags=maxlags,\n",
    "        seed=SEED,\n",
    "        n_jobs=N_JOBS,\n",
    "        full=True,\n",
    "        quantiles=True,\n",
    "        normalize=True,\n",
    "        cmi='original',\n",
    "        mb_estimator='original',\n",
    "        top_vars=3\n",
    "    )\n",
    "\n",
    "    d2c.initialize()  # Initializes the D2C object\n",
    "    descriptors_df = d2c.get_descriptors_df()  # Computes the descriptors\n",
    "\n",
    "    # Extract causal paths to create new DAGs\n",
    "    new_dags = []\n",
    "    for dag in dags_2_com:\n",
    "        new_dag = nx.DiGraph()  # Create a new directed graph\n",
    "        for index, row in descriptors_df.iterrows():\n",
    "            if row['is_causal'] == 1:\n",
    "                source = row['edge_source']\n",
    "                effect = row['edge_dest']\n",
    "                new_dag.add_edge(source, effect)  # Add causal relationships\n",
    "        new_dags.append(new_dag)\n",
    "\n",
    "    # Replace the original DAGs with new DAGs\n",
    "    # This assumes you want to use the new DAGs for further processing\n",
    "    # d2c.dags = new_dags  # Update DAGs in D2C object\n",
    "\n",
    "    # Save the new DAGs in the dictionary\n",
    "    DAGs_common_3[gen_process_number] = new_dags\n",
    "\n",
    "    # Save the descriptors along with new DAGs if needed\n",
    "    descriptors_df.insert(0, 'process_id', gen_process_number)\n",
    "    descriptors_df.insert(2, 'n_variables', n_variables)\n",
    "    descriptors_df.insert(3, 'max_neighborhood_size', max_neighborhood_size)\n",
    "    descriptors_df.insert(4, 'noise_std', noise_std)\n",
    "\n",
    "    descriptors_df.to_pickle(output_folder + f'P{gen_process_number}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std}_MB{MB_SIZE}.pkl')\n",
    "\n",
    "\n",
    "# save the new DAGs in a pickle file\n",
    "with open(os.path.join(output_folder, 'DAGs_common_3.pkl'), 'wb') as f:\n",
    "    pickle.dump(DAGs_common_3, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second estimation using the new_dag\n",
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C/iterative/second estimate/third_try/new/'\n",
    "dag_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C/iterative/initial/'\n",
    "# load the new dags\n",
    "with open(os.path.join(dag_folder, 'DAGs_2_new.pkl'), 'rb') as f:\n",
    "    dags_2_new = pickle.load(f)\n",
    "\n",
    "DAGs_new_3 = {}\n",
    "\n",
    "# List of files to process\n",
    "to_process = []\n",
    "\n",
    "# Filtering the files to process\n",
    "for file in sorted(os.listdir(input_folder)):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    if noise_std != noise_std_filter or max_neighborhood_size != max_neighborhood_size_filter:\n",
    "        continue\n",
    "\n",
    "    to_process.append(file)\n",
    "\n",
    "# Create output folder if it does not exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Process each file and create new DAGs based on causal paths\n",
    "for file in tqdm(to_process):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    dataloader = DataLoader(n_variables=n_variables, maxlags=maxlags)\n",
    "    dataloader.from_pickle(input_folder + file)\n",
    "\n",
    "    d2c = D2C(\n",
    "        observations=dataloader.get_observations(),\n",
    "        dags=dags_2_new[gen_process_number],\n",
    "        couples_to_consider_per_dag=COUPLES_TO_CONSIDER_PER_DAG,\n",
    "        MB_size=MB_SIZE,\n",
    "        n_variables=n_variables,\n",
    "        maxlags=maxlags,\n",
    "        seed=SEED,\n",
    "        n_jobs=N_JOBS,\n",
    "        full=True,\n",
    "        quantiles=True,\n",
    "        normalize=True,\n",
    "        cmi='original',\n",
    "        mb_estimator='original',\n",
    "        top_vars=3\n",
    "    )\n",
    "\n",
    "    d2c.initialize()  # Initializes the D2C object\n",
    "    descriptors_df = d2c.get_descriptors_df()  # Computes the descriptors\n",
    "\n",
    "    # Extract causal paths to create new DAGs\n",
    "    new_dags = []\n",
    "    for dag in dataloader.get_dags():\n",
    "        new_dag = nx.DiGraph()  # Create a new directed graph\n",
    "        for index, row in descriptors_df.iterrows():\n",
    "            if row['is_causal'] == 1:\n",
    "                source = row['edge_source']\n",
    "                effect = row['edge_dest']\n",
    "                new_dag.add_edge(source, effect)  # Add causal relationships\n",
    "        new_dags.append(new_dag)\n",
    "\n",
    "    # Replace the original DAGs with new DAGs\n",
    "    # This assumes you want to use the new DAGs for further processing\n",
    "    # d2c.dags = new_dags  # Update DAGs in D2C object\n",
    "\n",
    "    # Save the new DAGs in the dictionary\n",
    "    DAGs_new_3[gen_process_number] = new_dags\n",
    "\n",
    "    # Save the descriptors along with new DAGs if needed\n",
    "    descriptors_df.insert(0, 'process_id', gen_process_number)\n",
    "    descriptors_df.insert(2, 'n_variables', n_variables)\n",
    "    descriptors_df.insert(3, 'max_neighborhood_size', max_neighborhood_size)\n",
    "    descriptors_df.insert(4, 'noise_std', noise_std)\n",
    "\n",
    "    descriptors_df.to_pickle(output_folder + f'P{gen_process_number}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std}_MB{MB_SIZE}.pkl')\n",
    "\n",
    "# save the new DAGs in a pickle file\n",
    "with open(os.path.join(output_folder, 'DAGs_common_3.pkl'), 'wb') as f:\n",
    "    pickle.dump(DAGs_common_3, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second estimation using the estimated_dag\n",
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C/iterative/second estimate/third_try/estim/'\n",
    "dag_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C/iterative/initial/'\n",
    "# load DAGs_2\n",
    "with open(os.path.join(dag_folder, 'DAGs_2.pkl'), 'rb') as f:\n",
    "    dags_2 = pickle.load(f)\n",
    "\n",
    "DAGs_estimated_3 = {}\n",
    "\n",
    "# List of files to process\n",
    "to_process = []\n",
    "\n",
    "# Filtering the files to process\n",
    "for file in sorted(os.listdir(input_folder)):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    if noise_std != noise_std_filter or max_neighborhood_size != max_neighborhood_size_filter:\n",
    "        continue\n",
    "\n",
    "    to_process.append(file)\n",
    "\n",
    "# Create output folder if it does not exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Process each file and create new DAGs based on causal paths\n",
    "for file in tqdm(to_process):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    dataloader = DataLoader(n_variables=n_variables, maxlags=maxlags)\n",
    "    dataloader.from_pickle(input_folder + file)\n",
    "\n",
    "    d2c = D2C(\n",
    "        observations=dataloader.get_observations(),\n",
    "        dags=dags_2[gen_process_number],\n",
    "        couples_to_consider_per_dag=COUPLES_TO_CONSIDER_PER_DAG,\n",
    "        MB_size=MB_SIZE,\n",
    "        n_variables=n_variables,\n",
    "        maxlags=maxlags,\n",
    "        seed=SEED,\n",
    "        n_jobs=N_JOBS,\n",
    "        full=True,\n",
    "        quantiles=True,\n",
    "        normalize=True,\n",
    "        cmi='original',\n",
    "        mb_estimator='original',\n",
    "        top_vars=3\n",
    "    )\n",
    "\n",
    "    d2c.initialize()  # Initializes the D2C object\n",
    "    descriptors_df = d2c.get_descriptors_df()  # Computes the descriptors\n",
    "\n",
    "    # Extract causal paths to create new DAGs\n",
    "    new_dags = []\n",
    "    for dag in dataloader.get_dags():\n",
    "        new_dag = nx.DiGraph()  # Create a new directed graph\n",
    "        for index, row in descriptors_df.iterrows():\n",
    "            if row['is_causal'] == 1:\n",
    "                source = row['edge_source']\n",
    "                effect = row['edge_dest']\n",
    "                new_dag.add_edge(source, effect)  # Add causal relationships\n",
    "        new_dags.append(new_dag)\n",
    "\n",
    "    # Replace the original DAGs with new DAGs\n",
    "    # This assumes you want to use the new DAGs for further processing\n",
    "    # d2c.dags = new_dags  # Update DAGs in D2C object\n",
    "\n",
    "    # Save the new DAGs in the dictionary\n",
    "    DAGs_estimated_3[gen_process_number] = new_dags\n",
    "\n",
    "    # Save the descriptors along with new DAGs if needed\n",
    "    descriptors_df.insert(0, 'process_id', gen_process_number)\n",
    "    descriptors_df.insert(2, 'n_variables', n_variables)\n",
    "    descriptors_df.insert(3, 'max_neighborhood_size', max_neighborhood_size)\n",
    "    descriptors_df.insert(4, 'noise_std', noise_std)\n",
    "\n",
    "    descriptors_df.to_pickle(output_folder + f'P{gen_process_number}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std}_MB{MB_SIZE}.pkl')\n",
    "\n",
    "# save the new DAGs in a pickle file\n",
    "with open(os.path.join(output_folder, 'DAGs_estimated_3.pkl'), 'wb') as f:\n",
    "    pickle.dump(DAGs_estimated_3, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### merge with original dag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptors Generation (second estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "output_folder_2 = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C/iterative/second_estimate/'\n",
    "\n",
    "# replace values in d2c.dags with the new DAGs_2\n",
    "for file in tqdm(to_process):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    dataloader = DataLoader(n_variables=n_variables, maxlags=maxlags)\n",
    "    dataloader.from_pickle(input_folder + file)\n",
    "\n",
    "    d2c_2 = D2C(\n",
    "        observations=dataloader.get_observations(),\n",
    "        dags=DAGs_2[gen_process_number],\n",
    "        couples_to_consider_per_dag=COUPLES_TO_CONSIDER_PER_DAG,\n",
    "        MB_size=MB_SIZE,\n",
    "        n_variables=n_variables,\n",
    "        maxlags=maxlags,\n",
    "        seed=SEED,\n",
    "        n_jobs=N_JOBS,\n",
    "        full=True,\n",
    "        quantiles=True,\n",
    "        normalize=True,\n",
    "        cmi='original',\n",
    "        mb_estimator='ts',\n",
    "        top_vars=3\n",
    "        )\n",
    "    \n",
    "    d2c_2.initialize() # initializes the D2C object\n",
    "\n",
    "    descriptors_df_2 = d2c_2.get_descriptors_df()  # computes the descriptors\n",
    "\n",
    "    descriptors_df_2.insert(0, 'process_id', gen_process_number)\n",
    "    descriptors_df_2.insert(2, 'n_variables', n_variables)\n",
    "    descriptors_df_2.insert(3, 'max_neighborhood_size', max_neighborhood_size)\n",
    "    descriptors_df_2.insert(4, 'noise_std', noise_std)\n",
    "\n",
    "    # The descriptors are saved in the output folder as a pickle file.\n",
    "    descriptors_df_2.to_pickle(output_folder_2+f'P{gen_process_number}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std}_MB{MB_SIZE}.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Classifier (initial estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "\n",
    "to_dos = []\n",
    "\n",
    "# This loop gets a list of all the files to be processed\n",
    "for testing_file in sorted(os.listdir(data_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "          \n",
    "        if noise_std != 0.01: # if the noise is different we skip the file\n",
    "            continue\n",
    "\n",
    "        if max_neighborhood_size != 2: # if the max_neighborhood_size is different we skip the file\n",
    "            continue\n",
    "\n",
    "        to_dos.append(testing_file) # we add the file to the list (to_dos) to be processed\n",
    "\n",
    "# sort to_dos by number of variables\n",
    "to_dos_5_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 5]\n",
    "# to_dos_10_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 10]\n",
    "# to_dos_25_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 25]\n",
    "\n",
    "# we create a dictionary with the lists of files to be processed\n",
    "todos = {'5': to_dos_5_variables} # , '10': to_dos_10_variables, '25': to_dos_25_variables\n",
    "\n",
    "# we create a dictionary to store the results\n",
    "dfs = []\n",
    "descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C/iterative/initial/'\n",
    "\n",
    "# Re-save pickle files with protocol 4\n",
    "for testing_file in sorted(os.listdir(descriptors_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        file_path = os.path.join(descriptors_root, testing_file)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Re-save with protocol 4\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(data, f, protocol=4)\n",
    "\n",
    "# This loop gets the descriptors for the files to be processed\n",
    "for testing_file in sorted(os.listdir(descriptors_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        df = pd.read_pickle(os.path.join(descriptors_root, testing_file))\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            dfs.append(df)\n",
    "\n",
    "# we concatenate the descriptors\n",
    "descriptors_training = pd.concat(dfs, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Classifier (second estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "\n",
    "to_dos_2 = []\n",
    "\n",
    "# This loop gets a list of all the files to be processed\n",
    "for testing_file in sorted(os.listdir(data_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "          \n",
    "        if noise_std != 0.01: # if the noise is different we skip the file\n",
    "            continue\n",
    "\n",
    "        if max_neighborhood_size != 2: # if the max_neighborhood_size is different we skip the file\n",
    "            continue\n",
    "\n",
    "        to_dos_2.append(testing_file) # we add the file to the list (to_dos) to be processed\n",
    "\n",
    "# sort to_dos by number of variables\n",
    "to_dos_5_variables_2 = [file for file in to_dos_2 if int(file.split('_')[1][1:]) == 5]\n",
    "# to_dos_10_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 10]\n",
    "# to_dos_25_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 25]\n",
    "\n",
    "# we create a dictionary with the lists of files to be processed\n",
    "todos_2 = {'5': to_dos_5_variables_2} # , '10': to_dos_10_variables, '25': to_dos_25_variables\n",
    "\n",
    "# we create a dictionary to store the results\n",
    "dfs_2 = []\n",
    "descriptors_root_2 = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C/iterative/second_estimate/third_try/estim/'\n",
    "\n",
    "# Re-save pickle files with protocol 4\n",
    "for testing_file in sorted(os.listdir(descriptors_root_2)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        file_path = os.path.join(descriptors_root_2, testing_file)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Re-save with protocol 4\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(data, f, protocol=4)\n",
    "\n",
    "# This loop gets the descriptors for the files to be processed\n",
    "for testing_file in sorted(os.listdir(descriptors_root_2)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        df = pd.read_pickle(os.path.join(descriptors_root_2, testing_file))\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            dfs_2.append(df)\n",
    "\n",
    "# we concatenate the descriptors\n",
    "descriptors_training_2 = pd.concat(dfs_2, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics (initial estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loop does the following:\n",
    "# 1. Creates some dictionaries to store the results\n",
    "# 2. Loads the training data\n",
    "# 3. Trains the model\n",
    "# 4. Evaluates the model\n",
    "# 5. Stores the results in the dictionaries\n",
    "# 6. Saves the dictionaries in a pickle file\n",
    "\n",
    "for n_vars, todo in todos.items():\n",
    "    td2c_rocs_process = {}\n",
    "    td2c_precision_process = {}\n",
    "    td2c_recall_process = {}\n",
    "    td2c_f1_process = {}\n",
    "    for testing_file in tqdm(todo):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "\n",
    "        # split training and testing data\n",
    "        training_data = descriptors_training.loc[descriptors_training['process_id'] != gen_process_number]\n",
    "        X_train = training_data.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "        y_train = training_data['is_causal']\n",
    "\n",
    "        testing_data = descriptors_training.loc[(descriptors_training['process_id'] == gen_process_number) & (descriptors_training['n_variables'] == n_variables) & (descriptors_training['max_neighborhood_size'] == max_neighborhood_size) & (descriptors_training['noise_std'] == noise_std)]\n",
    "\n",
    "        model = BalancedRandomForestClassifier(n_estimators=100, random_state=0, n_jobs=50, max_depth=None, sampling_strategy='auto', replacement=True, bootstrap=False)\n",
    "        # model = RandomForestClassifier(n_estimators=50, random_state=0, n_jobs=50, max_depth=10)\n",
    "\n",
    "        model = model.fit(X_train, y_train)\n",
    "\n",
    "        rocs = {}\n",
    "        precisions = {}\n",
    "        recalls = {}\n",
    "        f1s = {}\n",
    "        for graph_id in range(40):\n",
    "            #load testing descriptors\n",
    "            test_df = testing_data.loc[testing_data['graph_id'] == graph_id]\n",
    "            test_df = test_df.sort_values(by=['edge_source','edge_dest']).reset_index(drop=True) # sort for coherence\n",
    "\n",
    "            X_test = test_df.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "            y_test = test_df['is_causal']\n",
    "\n",
    "            y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            roc = roc_auc_score(y_test, y_pred_proba)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            \n",
    "            rocs[graph_id] = roc\n",
    "            precisions[graph_id] = precision\n",
    "            recalls[graph_id] = recall\n",
    "            f1s[graph_id] = f1\n",
    "\n",
    "        td2c_rocs_process[gen_process_number] = rocs\n",
    "        td2c_precision_process[gen_process_number] = precisions\n",
    "        td2c_recall_process[gen_process_number] = recalls\n",
    "        td2c_f1_process[gen_process_number] = f1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics (second estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loop does the following:\n",
    "# 1. Creates some dictionaries to store the results\n",
    "# 2. Loads the training data\n",
    "# 3. Trains the model\n",
    "# 4. Evaluates the model\n",
    "# 5. Stores the results in the dictionaries\n",
    "# 6. Saves the dictionaries in a pickle file\n",
    "\n",
    "for n_vars, todo in todos_2.items():\n",
    "    td2c_rocs_process_2 = {}\n",
    "    td2c_precision_process_2 = {}\n",
    "    td2c_recall_process_2 = {}\n",
    "    td2c_f1_process_2 = {}\n",
    "    for testing_file in tqdm(todo):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "\n",
    "        # split training and testing data\n",
    "        training_data = descriptors_training_2.loc[descriptors_training_2['process_id'] != gen_process_number]\n",
    "        X_train = training_data.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "        y_train = training_data['is_causal']\n",
    "\n",
    "        testing_data = descriptors_training_2.loc[(descriptors_training_2['process_id'] == gen_process_number) & (descriptors_training_2['n_variables'] == n_variables) & (descriptors_training_2['max_neighborhood_size'] == max_neighborhood_size) & (descriptors_training_2['noise_std'] == noise_std)]\n",
    "\n",
    "        model_2 = BalancedRandomForestClassifier(n_estimators=100, random_state=0, n_jobs=50, max_depth=None, sampling_strategy='auto', replacement=True, bootstrap=False)\n",
    "        # model = RandomForestClassifier(n_estimators=50, random_state=0, n_jobs=50, max_depth=10)\n",
    "\n",
    "        model_2.fit(X_train, y_train)\n",
    "\n",
    "        rocs = {}\n",
    "        precisions = {}\n",
    "        recalls = {}\n",
    "        f1s = {}\n",
    "        for graph_id in range(40):\n",
    "            #load testing descriptors\n",
    "            test_df = testing_data.loc[testing_data['graph_id'] == graph_id]\n",
    "            test_df = test_df.sort_values(by=['edge_source','edge_dest']).reset_index(drop=True) # sort for coherence\n",
    "\n",
    "            X_test = test_df.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "            y_test = test_df['is_causal']\n",
    "\n",
    "            y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            roc = roc_auc_score(y_test, y_pred_proba)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            \n",
    "            rocs[graph_id] = roc\n",
    "            precisions[graph_id] = precision\n",
    "            recalls[graph_id] = recall\n",
    "            f1s[graph_id] = f1\n",
    "\n",
    "        td2c_rocs_process_2[gen_process_number] = rocs\n",
    "        td2c_precision_process_2[gen_process_number] = precisions\n",
    "        td2c_recall_process_2[gen_process_number] = recalls\n",
    "        td2c_f1_process_2[gen_process_number] = f1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pickle everything initial estimation\n",
    "# output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/journals/iterative/initial/'\n",
    "\n",
    "# # Create the folder if it doesn't exist\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.makedirs(output_folder)\n",
    "\n",
    "# with open(os.path.join(output_folder, f'journal_results_td2c_R_N5.pkl'), 'wb') as f:\n",
    "#     everything = (td2c_rocs_process, td2c_precision_process, td2c_recall_process, td2c_f1_process)\n",
    "#     pickle.dump(everything, f)\n",
    "\n",
    "\n",
    "# pickle everything second estimation\n",
    "output_folder_2 = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/journals/iterative/second_estimation/'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(output_folder_2):\n",
    "    os.makedirs(output_folder_2)\n",
    "\n",
    "with open(os.path.join(output_folder_2, f'journal_results_td2c_R_N5_2.pkl'), 'wb') as f:\n",
    "    everything_2 = (td2c_rocs_process_2, td2c_precision_process_2, td2c_recall_process_2, td2c_f1_process_2)\n",
    "    pickle.dump(everything_2, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################### LOAD DATA #####################################################################\n",
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/journals/iterative/initial/'\n",
    "input_folder_2 = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/journals/iterative/second_estimation/'\n",
    "\n",
    "\n",
    "with open(os.path.join(input_folder, 'journal_results_td2c_R_N5.pkl'), 'rb') as f:\n",
    "    TD2C_rocs_process, TD2C_precision_process, TD2C_recall_process, TD2C_f1_process = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(input_folder_2, 'journal_results_td2c_R_N5_2.pkl'), 'rb') as f:\n",
    "    TD2C_rocs_process_2, TD2C_precision_process_2, TD2C_recall_process_2, TD2C_f1_process_2 = pickle.load(f)\n",
    "\n",
    "\n",
    "##################################################################### PLOT #########################################################################\n",
    "\n",
    "df1 = pd.DataFrame(TD2C_rocs_process)\n",
    "\n",
    "df2 = pd.DataFrame(TD2C_rocs_process_2)\n",
    "\n",
    "# Combine data for boxplot\n",
    "combined_data = []\n",
    "\n",
    "for col in df1.columns:\n",
    "    combined_data.append(df1[col])\n",
    "    combined_data.append(df2[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns:\n",
    "    labels.append(f'{col} TD2C_Fist_Estimation')\n",
    "    labels.append(f'{col} TD2C_Second_Estimation')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title('Boxplot of ROC-AUC scores for TD2C method with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('ROC-AUC score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.mean().mean(), df2.mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot th two means\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot([df1.mean().values, df2.mean().values], patch_artist=True)\n",
    "plt.xticks([1, 2], ['TD2C First Estimation', 'TD2C Second Estimation'])\n",
    "plt.title('Boxplot of the means of the ROC-AUC scores for TD2C method with Regression to estimate MI (5 variables processes)')\n",
    "plt.ylabel('ROC-AUC score')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fourth try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First estimate\n",
    "2. top k (5) causally connected couples\n",
    "3. function that integrates nodes in these top k couples where necessary (when the MB for the destination node is computed)\n",
    "4. 2nd estimate (in theory better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptors Generation (first estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C/iterative/initial/'\n",
    "DAGs_2 = {}\n",
    "\n",
    "# List of files to process\n",
    "to_process = []\n",
    "\n",
    "# Filtering the files to process\n",
    "for file in sorted(os.listdir(input_folder)):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    if noise_std != noise_std_filter or max_neighborhood_size != max_neighborhood_size_filter:\n",
    "        continue\n",
    "\n",
    "    to_process.append(file)\n",
    "\n",
    "# Create output folder if it does not exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Process each file and create new DAGs based on causal paths\n",
    "for file in tqdm(to_process):\n",
    "    gen_process_number = int(file.split('_')[0][1:])\n",
    "    n_variables = int(file.split('_')[1][1:])\n",
    "    max_neighborhood_size = int(file.split('_')[2][2:])\n",
    "    noise_std = float(file.split('_')[3][1:-4])\n",
    "\n",
    "    dataloader = DataLoader(n_variables=n_variables, maxlags=maxlags)\n",
    "    dataloader.from_pickle(input_folder + file)\n",
    "\n",
    "    d2c = D2C(\n",
    "        observations=dataloader.get_observations(),\n",
    "        dags=dataloader.get_dags(),\n",
    "        couples_to_consider_per_dag=COUPLES_TO_CONSIDER_PER_DAG,\n",
    "        MB_size=MB_SIZE,\n",
    "        n_variables=n_variables,\n",
    "        maxlags=maxlags,\n",
    "        seed=SEED,\n",
    "        n_jobs=N_JOBS,\n",
    "        full=True,\n",
    "        quantiles=True,\n",
    "        normalize=True,\n",
    "        cmi='original',\n",
    "        mb_estimator='original',\n",
    "        top_vars=3\n",
    "    )\n",
    "\n",
    "    d2c.initialize()  # Initializes the D2C object\n",
    "    descriptors_df = d2c.get_descriptors_df()  # Computes the descriptors\n",
    "\n",
    "    # Save the descriptors along with new DAGs if needed\n",
    "    descriptors_df.insert(0, 'process_id', gen_process_number)\n",
    "    descriptors_df.insert(2, 'n_variables', n_variables)\n",
    "    descriptors_df.insert(3, 'max_neighborhood_size', max_neighborhood_size)\n",
    "    descriptors_df.insert(4, 'noise_std', noise_std)\n",
    "\n",
    "    descriptors_df.to_pickle(output_folder + f'P{gen_process_number}_N{n_variables}_Nj{max_neighborhood_size}_n{noise_std}_MB{MB_SIZE}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/data/to_use/'\n",
    "\n",
    "to_dos = []\n",
    "\n",
    "# This loop gets a list of all the files to be processed\n",
    "for testing_file in sorted(os.listdir(data_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "          \n",
    "        if noise_std != 0.01: # if the noise is different we skip the file\n",
    "            continue\n",
    "\n",
    "        if max_neighborhood_size != 2: # if the max_neighborhood_size is different we skip the file\n",
    "            continue\n",
    "\n",
    "        to_dos.append(testing_file) # we add the file to the list (to_dos) to be processed\n",
    "\n",
    "# sort to_dos by number of variables\n",
    "to_dos_5_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 5]\n",
    "# to_dos_10_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 10]\n",
    "# to_dos_25_variables = [file for file in to_dos if int(file.split('_')[1][1:]) == 25]\n",
    "\n",
    "# we create a dictionary with the lists of files to be processed\n",
    "todos = {'5': to_dos_5_variables} # , '10': to_dos_10_variables, '25': to_dos_25_variables\n",
    "\n",
    "# we create a dictionary to store the results\n",
    "dfs = []\n",
    "descriptors_root = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/descriptors/Regression/TD2C/iterative/initial/'\n",
    "\n",
    "# Re-save pickle files with protocol 4\n",
    "for testing_file in sorted(os.listdir(descriptors_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        file_path = os.path.join(descriptors_root, testing_file)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Re-save with protocol 4\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(data, f, protocol=4)\n",
    "\n",
    "# This loop gets the descriptors for the files to be processed\n",
    "for testing_file in sorted(os.listdir(descriptors_root)):\n",
    "    if testing_file.endswith('.pkl'):\n",
    "        df = pd.read_pickle(os.path.join(descriptors_root, testing_file))\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            dfs.append(df)\n",
    "\n",
    "# we concatenate the descriptors\n",
    "descriptors_training = pd.concat(dfs, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 67%|██████▋   | 12/18 [01:22<00:41,  6.99s/it]/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 78%|███████▊  | 14/18 [01:35<00:27,  6.86s/it]/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 83%|████████▎ | 15/18 [01:42<00:20,  6.82s/it]/home/jpalombarini/td2c/myenv3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 18/18 [02:03<00:00,  6.86s/it]\n"
     ]
    }
   ],
   "source": [
    "# This loop does the following:\n",
    "# 1. Creates some dictionaries to store the results\n",
    "# 2. Loads the training data\n",
    "# 3. Trains the model\n",
    "# 4. Evaluates the model\n",
    "# 5. Stores the results in the dictionaries\n",
    "# 6. Saves the dictionaries in a pickle file\n",
    "\n",
    "for n_vars, todo in todos.items():\n",
    "    td2c_rocs_process = {}\n",
    "    td2c_precision_process = {}\n",
    "    td2c_recall_process = {}\n",
    "    td2c_f1_process = {}\n",
    "    causal_df = {}\n",
    "    for testing_file in tqdm(todo):\n",
    "        gen_process_number = int(testing_file.split('_')[0][1:])\n",
    "        n_variables = int(testing_file.split('_')[1][1:])\n",
    "        max_neighborhood_size = int(testing_file.split('_')[2][2:])\n",
    "        noise_std = float(testing_file.split('_')[3][1:-4])\n",
    "\n",
    "        # split training and testing data\n",
    "        training_data = descriptors_training.loc[descriptors_training['process_id'] != gen_process_number]\n",
    "        X_train = training_data.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "        y_train = training_data['is_causal']\n",
    "\n",
    "        testing_data = descriptors_training.loc[(descriptors_training['process_id'] == gen_process_number) & (descriptors_training['n_variables'] == n_variables) & (descriptors_training['max_neighborhood_size'] == max_neighborhood_size) & (descriptors_training['noise_std'] == noise_std)]\n",
    "\n",
    "        model = BalancedRandomForestClassifier(n_estimators=100, random_state=0, n_jobs=50, max_depth=None, sampling_strategy='auto', replacement=True, bootstrap=False)\n",
    "        # model = RandomForestClassifier(n_estimators=50, random_state=0, n_jobs=50, max_depth=10)\n",
    "\n",
    "        model = model.fit(X_train, y_train)\n",
    "\n",
    "        rocs = {}\n",
    "        precisions = {}\n",
    "        recalls = {}\n",
    "        f1s = {}\n",
    "        causal_dfs = {}\n",
    "        for graph_id in range(40):\n",
    "            #load testing descriptors\n",
    "            test_df = testing_data.loc[testing_data['graph_id'] == graph_id]\n",
    "            test_df = test_df.sort_values(by=['edge_source','edge_dest']).reset_index(drop=True) # sort for coherence\n",
    "\n",
    "            X_test = test_df.drop(columns=['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size','noise_std', 'edge_source', 'edge_dest', 'is_causal',])\n",
    "            y_test = test_df['is_causal']\n",
    "\n",
    "            y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            roc = roc_auc_score(y_test, y_pred_proba)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            \n",
    "            rocs[graph_id] = roc\n",
    "            precisions[graph_id] = precision\n",
    "            recalls[graph_id] = recall\n",
    "            f1s[graph_id] = f1\n",
    "            \n",
    "            # add to causal_df test_df, y_pred_proba and y_pred\n",
    "            causal_dfs[graph_id] = test_df\n",
    "            causal_dfs[graph_id]['y_pred_proba'] = y_pred_proba\n",
    "            causal_dfs[graph_id]['y_pred'] = y_pred\n",
    "\n",
    "        causal_df[gen_process_number] = causal_dfs\n",
    "        td2c_rocs_process[gen_process_number] = rocs\n",
    "        td2c_precision_process[gen_process_number] = precisions\n",
    "        td2c_recall_process[gen_process_number] = recalls\n",
    "        td2c_f1_process[gen_process_number] = f1s\n",
    "\n",
    "# pickle everything\n",
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/journals/iterative/initial/'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "with open(os.path.join(output_folder, f'journal_results_td2c_R_N5.pkl'), 'wb') as f:\n",
    "    everything = (td2c_rocs_process, td2c_precision_process, td2c_recall_process, td2c_f1_process, causal_df)\n",
    "    pickle.dump(everything, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import causal_df \n",
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/journals/iterative/initial/'\n",
    "\n",
    "with open(os.path.join(input_folder, 'journal_results_td2c_R_N5.pkl'), 'rb') as f:\n",
    "    causal_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "\n",
    "# keep only rows for top k y_pred_proba\n",
    "for process_id, process_data in causal_df[4].items():\n",
    "    for graph_id, graph_data in process_data.items():\n",
    "        graph_data = graph_data.sort_values(by='y_pred_proba', ascending=False).head(k)\n",
    "        causal_df[4][process_id][graph_id] = graph_data\n",
    "\n",
    "# keep only columns process_id, graph_id, n_variables, max_neighborhood_size, noise_std, edge_source, edge_dest, is_causal and y_pred_probaraph_id', 'n_variables', 'max_neighborhood_size', 'noise_std', 'edge_source', 'edge_dest', 'is_causal' and 'y_pred_proba'\n",
    "for process_id, process_data in causal_df[4].items():\n",
    "    for graph_id, graph_data in process_data.items():\n",
    "        causal_df[4][process_id][graph_id] = graph_data[['process_id', 'graph_id', 'n_variables', 'max_neighborhood_size', 'noise_std', 'edge_source', 'edge_dest', 'is_causal', 'y_pred_proba']]\n",
    "\n",
    "# save the causal_df as a pkl file alone\n",
    "output_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/journals/iterative/initial/'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "with open(os.path.join(output_folder, f'causal_df_top_{k}_td2c_R_N5.pkl'), 'wb') as f:\n",
    "    pickle.dump(causal_df, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>process_id</th>\n",
       "      <th>graph_id</th>\n",
       "      <th>edge_source</th>\n",
       "      <th>edge_dest</th>\n",
       "      <th>y_pred_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    process_id  graph_id  edge_source  edge_dest  y_pred_proba\n",
       "21           4         0            7          2          0.91\n",
       "16           4         0            5          0          0.90\n",
       "18           4         0            6          1          0.83\n",
       "22           4         0            8          3          0.75\n",
       "20           4         0            7          0          0.64\n",
       "17           4         0            5          2          0.60\n",
       "24           4         0            9          4          0.55\n",
       "31           4         0           12          3          0.54\n",
       "26           4         0           10          2          0.54\n",
       "30           4         0           12          2          0.53"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load causal_df\n",
    "input_folder = '/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/journals/iterative/initial/'\n",
    "\n",
    "with open(os.path.join(input_folder, f'causal_df_top_{k}_td2c_R_N5.pkl'), 'rb') as f:\n",
    "    causal_df = pickle.load(f)\n",
    "\n",
    "# for each causal_df keep only process_id, graph_id, edge_source, edge_dest and y_pred_proba\n",
    "for process_id, process_data in causal_df[4].items():\n",
    "    for graph_id, graph_data in process_data.items():\n",
    "        causal_df[4][process_id][graph_id] = graph_data[['process_id', 'graph_id', 'edge_source', 'edge_dest', 'y_pred_proba']]\n",
    "\n",
    "causal_df[4][4][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot all Results - Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression for MI estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMENT OUT THE ONES YOU DIDN'T RUN\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_rocs_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_rocs_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_rocs_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_rocs_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_rocs_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_rocs_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_rocs_process)\n",
    "df8 = pd.DataFrame(TD2C_rocs_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_rocs_process)\n",
    "df10 = pd.DataFrame(D2C_rocs_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_rocs_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_rocs_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_rocs_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_rocs_process)\n",
    "\n",
    "# Processes 1-9\n",
    "\n",
    "# Combine data for boxplot\n",
    "combined_data = []\n",
    "\n",
    "# Use the first 9 columns (processes)\n",
    "for col in df5.columns[:10]:\n",
    "    combined_data.append(df1[col])\n",
    "    combined_data.append(df2[col])\n",
    "    # combined_data.append(df3[col])\n",
    "    # combined_data.append(df4[col])\n",
    "    combined_data.append(df5[col])\n",
    "    combined_data.append(df6[col])\n",
    "    combined_data.append(df11[col])\n",
    "    combined_data.append(df7[col])\n",
    "    combined_data.append(df8[col])\n",
    "    combined_data.append(df9[col])\n",
    "    combined_data.append(df10[col])\n",
    "    combined_data.append(df12[col])\n",
    "    combined_data.append(df13[col])\n",
    "    combined_data.append(df14[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns[:10]:\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_1_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_2_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_3_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_10_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_2')\n",
    "    labels.append(f'{col}  TD2C_Ranking_3')\n",
    "    labels.append(f'{col}  TD2C_Ranking_4')\n",
    "    labels.append(f'{col}  TD2C_Ranking_5')\n",
    "    labels.append(f'{col}  TD2C_Ranking_6')\n",
    "    labels.append(f'{col}  TD2C_Ranking_7')\n",
    "    labels.append(f'{col}  TD2C_Ranking_NoCont')\n",
    "    labels.append(f'{col}  TD2C_R')\n",
    "    labels.append(f'{col}  TD2C_Ranking_PastFut')\n",
    "    labels.append(f'{col}  D2C_R')\n",
    "\n",
    "# Plotting Boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral'] #, 'lightyellow']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title('Boxplots ROC-AUC scores per process for TD2C methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('Values')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a vertical line every 6 boxes\n",
    "for i in range(12, len(labels), 12):\n",
    "    plt.axvline(x=i + 0.5, color='black', linewidth=0.5)\n",
    "\n",
    "# Save the plot as a pdf in folder (optional)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/rocauc_boxplot_TD2C_Ranking_1:9.pdf')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Processes 10-20\n",
    "\n",
    "combined_data = []\n",
    "\n",
    "# Use the next 9 columns (processes)\n",
    "for col in df5.columns[10:18]:\n",
    "    combined_data.append(df1[col])\n",
    "    combined_data.append(df2[col])\n",
    "    # combined_data.append(df3[col])\n",
    "    # combined_data.append(df4[col])\n",
    "    combined_data.append(df5[col])\n",
    "    combined_data.append(df6[col])\n",
    "    combined_data.append(df11[col])\n",
    "    combined_data.append(df7[col])\n",
    "    combined_data.append(df8[col])\n",
    "    combined_data.append(df9[col])\n",
    "    combined_data.append(df10[col])\n",
    "    combined_data.append(df12[col])\n",
    "    combined_data.append(df13[col])\n",
    "    combined_data.append(df14[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns[10:18]:\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_1_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_2_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_3_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_10_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_2')\n",
    "    labels.append(f'{col}  TD2C_Ranking_3')\n",
    "    labels.append(f'{col}  TD2C_Ranking_4')\n",
    "    labels.append(f'{col}  TD2C_Ranking_5')\n",
    "    labels.append(f'{col}  TD2C_Ranking_6')\n",
    "    labels.append(f'{col}  TD2C_Ranking_7')\n",
    "    labels.append(f'{col}  TD2C_Ranking_NoCont')\n",
    "    labels.append(f'{col}  TD2C_R')\n",
    "    labels.append(f'{col}  TD2C_Ranking_PastFut')\n",
    "    labels.append(f'{col}  D2C_R')\n",
    "\n",
    "# Plotting Boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral'] #, 'lightyellow']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title('Boxplots ROC-AUC scores per process for TD2C methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('Values')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a vertical line every 6 boxes\n",
    "for i in range(12, len(labels), 12):\n",
    "    plt.axvline(x=i + 0.5, color='black', linewidth=0.5)\n",
    "\n",
    "# Save the plot as a pdf in folder (optional)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/rocauc_boxplot_TD2C_Ranking_10:20.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOTHER VISUALIZATION OF THE SAME PLOT\n",
    "\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_rocs_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_rocs_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_rocs_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_rocs_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_rocs_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_rocs_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_rocs_process)\n",
    "df8 = pd.DataFrame(TD2C_rocs_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_rocs_process)\n",
    "df10 = pd.DataFrame(D2C_rocs_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_rocs_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_rocs_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_rocs_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_rocs_process)\n",
    "\n",
    "# Colors to match the provided image more closely\n",
    "colors = ['lightgreen', 'lightblue', 'orange', 'mediumpurple', 'lightpink', 'lightcoral', 'lightyellow', 'lightgrey', 'lightgreen', 'lightblue', 'orange', 'mediumpurple', 'lightpink', 'lightcoral']\n",
    "\n",
    "# Determine the number of processes (columns)\n",
    "num_columns = len(df5.columns)\n",
    "\n",
    "# Calculate the number of rows and columns for subplots\n",
    "num_rows = 2  # 3 rows\n",
    "num_cols = 9  # 6 plots per row\n",
    "\n",
    "# Plotting Boxplot for Processes\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(24, 12))  # Adjust figsize as needed\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate over the columns in sequential order\n",
    "for i, col in enumerate(df5.columns):\n",
    "    data = [\n",
    "        df1[col], df2[col], df5[col], df6[col], df11[col], df7[col], df8[col], df9[col], df10[col], df12[col], df13[col], df14[col]\n",
    "    ]\n",
    "    \n",
    "    box = axes[i].boxplot(data, patch_artist=True)\n",
    "    \n",
    "    # Set colors for each box\n",
    "    for patch, color in zip(box['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    axes[i].set_title(f'Process {col}')\n",
    "    axes[i].set_xticklabels([\n",
    "        'TD2C_Ranking_1_1_Var', 'TD2C_Ranking_1_2_Var', 'TD2C_Ranking_2', 'TD2C_Ranking_3', 'TD2C_Ranking_4', 'TD2C_Ranking_5', 'TD2C_Ranking_6', 'TD2C_Ranking_7', 'TD2C_Ranking_NoCont', 'TD2C_R', 'TD2C_Ranking_PastFut', 'D2C_R'\n",
    "    ], rotation=-90)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/rocouc_boxplot_TD2C_Ranking_best_vs_TD2C.pdf')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DataFrames\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_rocs_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_rocs_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_rocs_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_rocs_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_rocs_process)\n",
    "df8 = pd.DataFrame(TD2C_rocs_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_rocs_process)\n",
    "df10 = pd.DataFrame(D2C_rocs_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_rocs_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_rocs_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_rocs_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_rocs_process)\n",
    "\n",
    "# Calculate the means\n",
    "means = [\n",
    "    df1.mean().mean(),\n",
    "    df2.mean().mean(),\n",
    "    df5.mean().mean(),\n",
    "    df6.mean().mean(),\n",
    "    df7.mean().mean(),\n",
    "    df8.mean().mean(),\n",
    "    df9.mean().mean(),\n",
    "    df10.mean().mean(),\n",
    "    df11.mean().mean(),\n",
    "    df12.mean().mean(),\n",
    "    df13.mean().mean(),\n",
    "    df14.mean().mean()\n",
    "]\n",
    "\n",
    "# Define the labels\n",
    "labels = [\n",
    "    'TD2C_Ranking_1_1_Var',\n",
    "    'TD2C_Ranking_1_2_Var',\n",
    "    'TD2C_Ranking_2',\n",
    "    'TD2C_Ranking_3',\n",
    "    'TD2C_Ranking_NoCont',\n",
    "    'TD2C_R',\n",
    "    'TD2C_Ranking_PastFut',\n",
    "    'D2C_R',\n",
    "    'TD2C_Ranking_4',\n",
    "    'TD2C_Ranking_5',\n",
    "    'TD2C_Ranking_6',\n",
    "    'TD2C_Ranking_7'\n",
    "]\n",
    "\n",
    "# Define the colors\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen', 'mediumpurple', 'orange', 'lightblue', 'lightgreen', 'lightcoral', 'mediumpurple', 'orange', 'skyblue', 'lightcoral']\n",
    "\n",
    "# Barplot the mean of the ROC-AUC scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(labels, means, color=colors)\n",
    "plt.xticks(rotation=-90)\n",
    "plt.title('Mean ROC-AUC scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('Mean ROC-AUC score')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a pdf in folder (optional)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/rocauc_barplot_TD2C_Ranking_best_vs_TD2C.pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW SHOW THE ROUC-AUC RESULTS IN A DATAFRAME DOING THE AVERAGES FOR EACH PROCESS FOR EACH METHOD\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_rocs_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_rocs_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_rocs_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_rocs_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_rocs_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_rocs_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_rocs_process)\n",
    "df8 = pd.DataFrame(TD2C_rocs_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_rocs_process)\n",
    "df10 = pd.DataFrame(D2C_rocs_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_rocs_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_rocs_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_rocs_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_rocs_process)\n",
    "\n",
    "df1 = df1.T\n",
    "df2 = df2.T\n",
    "# df3 = df3.T\n",
    "# df4 = df4.T\n",
    "df5 = df5.T\n",
    "df6 = df6.T\n",
    "df7 = df7.T\n",
    "df8 = df8.T\n",
    "df9 = df9.T\n",
    "df10 = df10.T\n",
    "df11 = df11.T\n",
    "df12 = df12.T\n",
    "df13 = df13.T\n",
    "df14 = df14.T\n",
    "\n",
    "df1['method'] = 'TD2C_Ranking_1_1_Var'\n",
    "df2['method'] = 'TD2C_Ranking_1_2_Var'\n",
    "# df3['method'] = 'TD2C_Ranking_1_3_Var'\n",
    "# df4['method'] = 'TD2C_Ranking_1_10_Var'\n",
    "df5['method'] = 'TD2C_Ranking_2'\n",
    "df6['method'] = 'TD2C_Ranking_3'\n",
    "df11['method'] = 'TD2C_Ranking_4'\n",
    "df12['method'] = 'TD2C_Ranking_5'\n",
    "df13['method'] = 'TD2C_Ranking_6'\n",
    "df14['method'] = 'TD2C_Ranking_7'\n",
    "df7['method'] = 'TD2C_Ranking_NoCont'\n",
    "df8['method'] = 'TD2C_R'\n",
    "df9['method'] = 'TD2C_Ranking_PastFut'\n",
    "df10['method'] = 'D2C_R'\n",
    "\n",
    "df = pd.concat([df1, df2, df5, df6, df11, df7, df12, df13, df14, df8, df9, df10]) # , df3, df4\n",
    "\n",
    "df = df.reset_index()\n",
    "df = df.rename(columns={'index': 'process_id'})\n",
    "\n",
    "df = df.melt(id_vars=['process_id', 'method'], var_name='graph_id', value_name='roc_auc')\n",
    "\n",
    "df['roc_auc'] = df['roc_auc'].astype(float)\n",
    "\n",
    "df = df.groupby(['process_id', 'method']).mean().reset_index()\n",
    "\n",
    "df = df.pivot(index='process_id', columns='method', values='roc_auc')\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.rename(columns={'process_id': 'Process ID', \n",
    "                        'TD2C_+Ranking_1_1_Var_rocs_process': 'TD2C_+Ranking_1_1_Var_rocs_process', \n",
    "                        'TD2C_+Ranking_1_2_Var_rocs_process': 'TD2C_+Ranking_1_2_Var_rocs_process', \n",
    "                        # 'TD2C_+Ranking_1_3_Var_rocs_process': 'TD2C_+Ranking_1_3_Var_rocs_process',\n",
    "                        # 'TD2C_+Ranking_1_10_Var_rocs_process': 'TD2C_+Ranking_1_10_Var_rocs_process', \n",
    "                        'TD2C_+Ranking_2_rocs_process': 'TD2C_+Ranking_2_rocs_process', \n",
    "                        'TD2C_+Ranking_3_rocs_process': 'TD2C_+Ranking_3_rocs_process',\n",
    "                        'TD2C_+Ranking_4_rocs_process': 'TD2C_+Ranking_4_rocs_process', \n",
    "                        'TD2C_+Ranking_NoCont_rocs_process': 'TD2C_+Ranking_NoCont_rocs_process',\n",
    "                        'TD2C_R_rocs_process': 'TD2C_R_rocs_process',\n",
    "                        'TD2C_+Ranking_PastFut_rocs_process': 'TD2C_+Ranking_PastFut_rocs_process',\n",
    "                        'D2C_R_rocs_process': 'D2C_R_rocs_process'})\n",
    "\n",
    "# eliminate the column method and make the process_id the index of the dataframe\n",
    "\n",
    "\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/roc_auc_td2c_ranking.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# load the dataframe from the csv file\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/roc_auc_td2c_ranking.csv')\n",
    "\n",
    "# Plot the dataframe as a heatmap\n",
    "df = df.set_index('Process ID')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df, cmap='coolwarm', annot=True, fmt=\".2f\")\n",
    "plt.title('ROC-AUC scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Methods')\n",
    "plt.ylabel('Process ID')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the plot as a pdf in folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/rocauc_heatmap_TD2C_Ranking.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now average each row of the dataframe\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/roc_auc_td2c_ranking.csv')\n",
    "\n",
    "df = df.set_index('Process ID')\n",
    "\n",
    "df = df.mean(axis=1)\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.rename(columns={0: 'roc_auc'})\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/roc_auc_td2c_ranking_mean_proc.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrame\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/roc_auc_td2c_ranking.csv')\n",
    "\n",
    "# Strip any leading/trailing spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Plot the DataFrame as a barplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['Process ID'], df['TD2C_R'], color=colors)\n",
    "plt.title('Mean ROC-AUC scores for TD2C_Ranking processes, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Process ID')\n",
    "plt.ylabel('Mean ROC-AUC')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PDF in the folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/rocauc_barplot_TD2C_Ranking_mean_proc.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/roc_auc_td2c_ranking.csv')\n",
    "\n",
    "# now average the results for each process\n",
    "df = df.mean()\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.rename(columns={'index': 'method', 0: 'roc_auc'})\n",
    "\n",
    "df = df.sort_values(by='roc_auc', ascending=False)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# drop Process ID 0 row\n",
    "df = df.drop(0)\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/rocauc_td2c_ranking_avg.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframe from the csv file\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/roc_auc_td2c_ranking_avg.csv')\n",
    "\n",
    "# Plotting Barplot for methods for indexes 1 to 6\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['method'], df['roc_auc'], color=colors)\n",
    "plt.xticks(rotation=-90)\n",
    "plt.title('Mean ROC-AUC scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Methods')\n",
    "plt.ylabel('Mean ROC-AUC')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the plot as a pdf in folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/rocauc_barplot_TD2C_Ranking_avg.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMENT OUT THE ONES YOU DIDN'T RUN\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_precision_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_precision_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_precision_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_precision_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_precision_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_precision_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_precision_process)\n",
    "df8 = pd.DataFrame(TD2C_precision_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_precision_process)\n",
    "df10 = pd.DataFrame(D2C_precision_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_precision_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_precision_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_precision_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_precision_process)\n",
    "\n",
    "# Processes 1-9\n",
    "\n",
    "# Combine data for boxplot\n",
    "combined_data = []\n",
    "\n",
    "# Use the first 9 columns (processes)\n",
    "for col in df5.columns[:10]:\n",
    "    combined_data.append(df1[col])\n",
    "    combined_data.append(df2[col])\n",
    "    # combined_data.append(df3[col])\n",
    "    # combined_data.append(df4[col])\n",
    "    combined_data.append(df5[col])\n",
    "    combined_data.append(df6[col])\n",
    "    combined_data.append(df11[col])\n",
    "    combined_data.append(df7[col])\n",
    "    combined_data.append(df8[col])\n",
    "    combined_data.append(df9[col])\n",
    "    combined_data.append(df10[col])\n",
    "    combined_data.append(df12[col])\n",
    "    combined_data.append(df13[col])\n",
    "    combined_data.append(df14[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns[:10]:\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_1_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_2_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_3_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_10_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_2')\n",
    "    labels.append(f'{col}  TD2C_Ranking_3')\n",
    "    labels.append(f'{col}  TD2C_Ranking_4')\n",
    "    labels.append(f'{col}  TD2C_Ranking_5')\n",
    "    labels.append(f'{col}  TD2C_Ranking_6')\n",
    "    labels.append(f'{col}  TD2C_Ranking_7')\n",
    "    labels.append(f'{col}  TD2C_Ranking_NoCont')\n",
    "    labels.append(f'{col}  TD2C_R')\n",
    "    labels.append(f'{col}  TD2C_Ranking_PastFut')\n",
    "    labels.append(f'{col}  D2C_R')\n",
    "\n",
    "# Plotting Boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral'] #, 'lightyellow']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title('Side-by-Side Boxplots Precision scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('Values')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a vertical line every 6 boxes\n",
    "for i in range(12, len(labels), 12):\n",
    "    plt.axvline(x=i + 0.5, color='black', linewidth=0.5)\n",
    "\n",
    "# Save the plot as a pdf in folder (optional)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/precision_boxplot_TD2C_Ranking_1:9.pdf')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Processes 10-20\n",
    "\n",
    "combined_data = []\n",
    "\n",
    "# Use the next 9 columns (processes)\n",
    "for col in df5.columns[10:18]:\n",
    "    combined_data.append(df1[col])\n",
    "    combined_data.append(df2[col])\n",
    "    # combined_data.append(df3[col])\n",
    "    # combined_data.append(df4[col])\n",
    "    combined_data.append(df5[col])\n",
    "    combined_data.append(df6[col])\n",
    "    combined_data.append(df11[col])\n",
    "    combined_data.append(df7[col])\n",
    "    combined_data.append(df8[col])\n",
    "    combined_data.append(df9[col])\n",
    "    combined_data.append(df10[col])\n",
    "    combined_data.append(df12[col])\n",
    "    combined_data.append(df13[col])\n",
    "    combined_data.append(df14[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns[10:18]:\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_1_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_2_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_3_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_10_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_2')\n",
    "    labels.append(f'{col}  TD2C_Ranking_3')\n",
    "    labels.append(f'{col}  TD2C_Ranking_4')\n",
    "    labels.append(f'{col}  TD2C_Ranking_5')\n",
    "    labels.append(f'{col}  TD2C_Ranking_6')\n",
    "    labels.append(f'{col}  TD2C_Ranking_7')\n",
    "    labels.append(f'{col}  TD2C_Ranking_NoCont')\n",
    "    labels.append(f'{col}  TD2C_R')\n",
    "    labels.append(f'{col}  TD2C_Ranking_PastFut')\n",
    "    labels.append(f'{col}  D2C_R')\n",
    "\n",
    "# Plotting Boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral'] #, 'lightyellow']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title('Side-by-Side Boxplots Precision scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('Values')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a vertical line every 6 boxes\n",
    "for i in range(12, len(labels), 12):\n",
    "    plt.axvline(x=i + 0.5, color='black', linewidth=0.5)\n",
    "\n",
    "# Save the plot as a pdf in folder (optional)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/precision_boxplot_TD2C_Ranking_10:20.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOTHER VISUALIZATION OF THE SAME PLOT\n",
    "\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_precision_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_precision_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_precision_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_precision_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_precision_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_precision_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_precision_process)\n",
    "df8 = pd.DataFrame(TD2C_precision_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_precision_process)\n",
    "df10 = pd.DataFrame(D2C_precision_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_precision_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_precision_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_precision_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_precision_process)\n",
    "\n",
    "# Colors to match the provided image more closely\n",
    "colors = ['lightgreen', 'lightblue', 'orange', 'mediumpurple', 'lightpink', 'lightcoral', 'lightyellow', 'lightgrey', 'lightgreen', 'lightblue', 'orange', 'mediumpurple', 'lightpink', 'lightcoral']\n",
    "\n",
    "# Determine the number of processes (columns)\n",
    "num_columns = len(df5.columns)\n",
    "\n",
    "# Calculate the number of rows and columns for subplots\n",
    "num_rows = 2  # 3 rows\n",
    "num_cols = 9  # 6 plots per row\n",
    "\n",
    "# Plotting Boxplot for Processes\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(24, 12))  # Adjust figsize as needed\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate over the columns in sequential order\n",
    "for i, col in enumerate(df5.columns):\n",
    "    data = [\n",
    "        df1[col], df2[col], df5[col], df6[col], df11[col], df7[col], df8[col], df9[col], df10[col], df12[col], df13[col], df14[col]\n",
    "    ]\n",
    "    \n",
    "    box = axes[i].boxplot(data, patch_artist=True)\n",
    "    \n",
    "    # Set colors for each box\n",
    "    for patch, color in zip(box['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    axes[i].set_title(f'Process {col}')\n",
    "    axes[i].set_xticklabels([\n",
    "        'TD2C_Ranking_1_1_Var', 'TD2C_Ranking_1_2_Var', 'TD2C_Ranking_2', 'TD2C_Ranking_3', 'TD2C_Ranking_4', 'TD2C_Ranking_5', 'TD2C_Ranking_6', 'TD2C_Ranking_7', 'TD2C_Ranking_NoCont', 'TD2C_R', 'TD2C_Ranking_PastFut', 'D2C_R'\n",
    "    ], rotation=-90)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/precision_boxplot_TD2C_Ranking_best_vs_TD2C.pdf')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DataFrames\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_precision_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_precision_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_precision_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_precision_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_precision_process)\n",
    "df8 = pd.DataFrame(TD2C_precision_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_precision_process)\n",
    "df10 = pd.DataFrame(D2C_precision_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_precision_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_precision_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_precision_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_precision_process)\n",
    "\n",
    "\n",
    "# Calculate the means\n",
    "means = [\n",
    "    df1.mean().mean(),\n",
    "    df2.mean().mean(),\n",
    "    df5.mean().mean(),\n",
    "    df6.mean().mean(),\n",
    "    df7.mean().mean(),\n",
    "    df8.mean().mean(),\n",
    "    df9.mean().mean(),\n",
    "    df10.mean().mean(),\n",
    "    df11.mean().mean(),\n",
    "    df12.mean().mean(),\n",
    "    df13.mean().mean(),\n",
    "    df14.mean().mean()\n",
    "]\n",
    "\n",
    "# Define the labels\n",
    "labels = [\n",
    "    'TD2C_Ranking_1_1_Var',\n",
    "    'TD2C_Ranking_1_2_Var',\n",
    "    'TD2C_Ranking_2',\n",
    "    'TD2C_Ranking_3',\n",
    "    'TD2C_Ranking_NoCont',\n",
    "    'TD2C_R',\n",
    "    'TD2C_Ranking_PastFut',\n",
    "    'D2C_R',\n",
    "    'TD2C_Ranking_4',\n",
    "    'TD2C_Ranking_5',\n",
    "    'TD2C_Ranking_6',\n",
    "    'TD2C_Ranking_7'\n",
    "]\n",
    "\n",
    "# Define the colors\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen', 'mediumpurple', 'orange', 'lightblue', 'lightgreen', 'lightcoral', 'mediumpurple', 'orange', 'skyblue', 'lightcoral']\n",
    "\n",
    "# Barplot the mean of the ROC-AUC scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(labels, means, color=colors)\n",
    "plt.xticks(rotation=-90)\n",
    "plt.title('Mean Precision scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('Mean Precision score')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a pdf in folder (optional)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/precision_barplot_TD2C_Ranking_best_vs_TD2C.pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW SHOW THE ROUC-AUC RESULTS IN A DATAFRAME DOING THE AVERAGES FOR EACH PROCESS FOR EACH METHOD\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_precision_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_precision_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_precision_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_precision_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_precision_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_precision_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_precision_process)\n",
    "df8 = pd.DataFrame(TD2C_precision_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_precision_process)\n",
    "df10 = pd.DataFrame(D2C_precision_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_precision_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_precision_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_precision_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_precision_process)\n",
    "\n",
    "df1 = df1.T\n",
    "df2 = df2.T\n",
    "# df3 = df3.T\n",
    "# df4 = df4.T\n",
    "df5 = df5.T\n",
    "df6 = df6.T\n",
    "df7 = df7.T\n",
    "df8 = df8.T\n",
    "df9 = df9.T\n",
    "df10 = df10.T\n",
    "df11 = df11.T\n",
    "df12 = df12.T\n",
    "df13 = df13.T\n",
    "df14 = df14.T\n",
    "\n",
    "df1['method'] = 'TD2C_Ranking_1_1_Var'\n",
    "df2['method'] = 'TD2C_Ranking_1_2_Var'\n",
    "# df3['method'] = 'TD2C_Ranking_1_3_Var'\n",
    "# df4['method'] = 'TD2C_Ranking_1_10_Var'\n",
    "df5['method'] = 'TD2C_Ranking_2'\n",
    "df6['method'] = 'TD2C_Ranking_3'\n",
    "df11['method'] = 'TD2C_Ranking_4'\n",
    "df12['method'] = 'TD2C_Ranking_5'\n",
    "df13['method'] = 'TD2C_Ranking_6'\n",
    "df14['method'] = 'TD2C_Ranking_7'\n",
    "df7['method'] = 'TD2C_Ranking_NoCont'\n",
    "df8['method'] = 'TD2C_R'\n",
    "df9['method'] = 'TD2C_Ranking_PastFut'\n",
    "df10['method'] = 'D2C_R'\n",
    "\n",
    "df = pd.concat([df1, df2, df5, df6, df11, df7, df12, df13, df14, df8, df9, df10]) # , df3, df4\n",
    "\n",
    "df = df.reset_index()\n",
    "df = df.rename(columns={'index': 'process_id'})\n",
    "\n",
    "df = df.melt(id_vars=['process_id', 'method'], var_name='graph_id', value_name='Precision')\n",
    "\n",
    "df['Precision'] = df['Precision'].astype(float)\n",
    "\n",
    "df = df.groupby(['process_id', 'method']).mean().reset_index()\n",
    "\n",
    "df = df.pivot(index='process_id', columns='method', values='Precision')\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.rename(columns={'process_id': 'Process ID', \n",
    "                        'TD2C_+Ranking_1_1_Var_precision_process': 'TD2C_+Ranking_1_1_Var_precision_process',\n",
    "                        'TD2C_+Ranking_1_2_Var_precision_process': 'TD2C_+Ranking_1_2_Var_precision_process',\n",
    "                        # 'TD2C_+Ranking_1_3_Var_precision_process': 'TD2C_+Ranking_1_3_Var_precision_process',\n",
    "                        # 'TD2C_+Ranking_1_10_Var_precision_process': 'TD2C_+Ranking_1_10_Var_precision_process',\n",
    "                        'TD2C_+Ranking_2_precision_process': 'TD2C_+Ranking_2_precision_process',\n",
    "                        'TD2C_+Ranking_3_precision_process': 'TD2C_+Ranking_3_precision_process',\n",
    "                        'TD2C_+Ranking_4_precision_process': 'TD2C_+Ranking_4_precision_process',\n",
    "                        'TD2C_+Ranking_NoCont_precision_process': 'TD2C_+Ranking_NoCont_precision_process',\n",
    "                        'TD2C_R_precision_process': 'TD2C_R_precision_process',\n",
    "                        'TD2C_+Ranking_PastFut_precision_process': 'TD2C_+Ranking_PastFut_precision_process',\n",
    "                        'D2C_R_precision_process': 'D2C_R_precision_process'})\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# load the dataframe from the csv file\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking.csv')\n",
    "\n",
    "# Plot the dataframe as a heatmap\n",
    "df = df.set_index('Process ID')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df, cmap='coolwarm', annot=True, fmt=\".2f\")\n",
    "plt.title('Precision scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Methods')\n",
    "plt.ylabel('Process ID')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the plot as a pdf in folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/precision_heatmap_TD2C_Ranking.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now average each row of the dataframe\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking.csv')\n",
    "\n",
    "df = df.set_index('Process ID')\n",
    "\n",
    "df = df.mean(axis=1)\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.rename(columns={0: 'Precision'})\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking_mean_proc.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrame\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking.csv')\n",
    "\n",
    "# Strip any leading/trailing spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Plot the DataFrame as a barplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['Process ID'], df['TD2C_R'], color=colors)\n",
    "plt.title('Mean Precision scores for TD2C_Ranking processes, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Process ID')\n",
    "plt.ylabel('Mean Precision')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PDF in the folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/precision_barplot_TD2C_Ranking_mean_proc.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking.csv')\n",
    "\n",
    "# now average the results for each process\n",
    "df = df.mean()\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.rename(columns={'index': 'method', 0: 'precision'})\n",
    "\n",
    "df = df.sort_values(by='precision', ascending=False)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# drop Process ID 0 row\n",
    "df = df.drop(0)\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking_avg.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframe from the csv file\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking_avg.csv')\n",
    "\n",
    "# Plotting Barplot for methods for indexes 1 to 6\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['method'], df['precision'], color=colors)\n",
    "plt.xticks(rotation=-90)\n",
    "plt.title('Mean Precision scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Methods')\n",
    "plt.ylabel('Mean Precision')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the plot as a pdf in folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/precision_barplot_TD2C_Ranking_avg.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMENT OUT THE ONES YOU DIDN'T RUN\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_recall_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_recall_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_recall_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_recall_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_recall_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_recall_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_recall_process)\n",
    "df8 = pd.DataFrame(TD2C_recall_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_recall_process)\n",
    "df10 = pd.DataFrame(D2C_recall_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_recall_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_recall_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_recall_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_recall_process)\n",
    "\n",
    "\n",
    "# Processes 1-9\n",
    "\n",
    "# Combine data for boxplot\n",
    "combined_data = []\n",
    "\n",
    "# Use the first 9 columns (processes)\n",
    "for col in df5.columns[:10]:\n",
    "    combined_data.append(df1[col])\n",
    "    combined_data.append(df2[col])\n",
    "    # combined_data.append(df3[col])\n",
    "    # combined_data.append(df4[col])\n",
    "    combined_data.append(df5[col])\n",
    "    combined_data.append(df6[col])\n",
    "    combined_data.append(df11[col])\n",
    "    combined_data.append(df7[col])\n",
    "    combined_data.append(df8[col])\n",
    "    combined_data.append(df9[col])\n",
    "    combined_data.append(df10[col])\n",
    "    combined_data.append(df12[col])\n",
    "    combined_data.append(df13[col])\n",
    "    combined_data.append(df14[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns[:10]:\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_1_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_2_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_3_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_10_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_2')\n",
    "    labels.append(f'{col}  TD2C_Ranking_3')\n",
    "    labels.append(f'{col}  TD2C_Ranking_4')\n",
    "    labels.append(f'{col}  TD2C_Ranking_5')\n",
    "    labels.append(f'{col}  TD2C_Ranking_6')\n",
    "    labels.append(f'{col}  TD2C_Ranking_7')\n",
    "    labels.append(f'{col}  TD2C_Ranking_NoCont')\n",
    "    labels.append(f'{col}  TD2C_R')\n",
    "    labels.append(f'{col}  TD2C_Ranking_PastFut')\n",
    "    labels.append(f'{col}  D2C_R')\n",
    "\n",
    "# Plotting Boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral'] #, 'lightyellow']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title('Side-by-Side Boxplots Recall scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('Values')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a vertical line every 6 boxes\n",
    "for i in range(12, len(labels), 12):\n",
    "    plt.axvline(x=i + 0.5, color='black', linewidth=0.5)\n",
    "\n",
    "# Save the plot as a pdf in folder (optional)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/recall_boxplot_TD2C_Ranking_1:9.pdf')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Processes 10-20\n",
    "\n",
    "combined_data = []\n",
    "\n",
    "# Use the next 9 columns (processes)\n",
    "for col in df5.columns[10:18]:\n",
    "    combined_data.append(df1[col])\n",
    "    combined_data.append(df2[col])\n",
    "    # combined_data.append(df3[col])\n",
    "    # combined_data.append(df4[col])\n",
    "    combined_data.append(df5[col])\n",
    "    combined_data.append(df6[col])\n",
    "    combined_data.append(df11[col])\n",
    "    combined_data.append(df7[col])\n",
    "    combined_data.append(df8[col])\n",
    "    combined_data.append(df9[col])\n",
    "    combined_data.append(df10[col])\n",
    "    combined_data.append(df12[col])\n",
    "    combined_data.append(df13[col])\n",
    "    combined_data.append(df14[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns[10:18]:\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_1_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_2_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_3_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_10_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_2')\n",
    "    labels.append(f'{col}  TD2C_Ranking_3')\n",
    "    labels.append(f'{col}  TD2C_Ranking_4')\n",
    "    labels.append(f'{col}  TD2C_Ranking_5')\n",
    "    labels.append(f'{col}  TD2C_Ranking_6')\n",
    "    labels.append(f'{col}  TD2C_Ranking_7')\n",
    "    labels.append(f'{col}  TD2C_Ranking_NoCont')\n",
    "    labels.append(f'{col}  TD2C_R')\n",
    "    labels.append(f'{col}  TD2C_Ranking_PastFut')\n",
    "    labels.append(f'{col}  D2C_R')\n",
    "\n",
    "# Plotting Boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral'] #, 'lightyellow']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title('Side-by-Side Boxplots Recall scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('Values')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a vertical line every 6 boxes\n",
    "for i in range(12, len(labels), 12):\n",
    "    plt.axvline(x=i + 0.5, color='black', linewidth=0.5)\n",
    "\n",
    "# Save the plot as a pdf in folder (optional)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/recall_boxplot_TD2C_Ranking_10:20.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOTHER VISUALIZATION OF THE SAME PLOT\n",
    "\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_recall_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_recall_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_recall_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_recall_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_recall_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_recall_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_recall_process)\n",
    "df8 = pd.DataFrame(TD2C_recall_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_recall_process)\n",
    "df10 = pd.DataFrame(D2C_recall_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_recall_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_recall_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_recall_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_recall_process)\n",
    "\n",
    "# Colors to match the provided image more closely\n",
    "colors = ['lightgreen', 'lightblue', 'orange', 'mediumpurple', 'lightpink', 'lightcoral', 'lightyellow', 'lightgrey', 'lightgreen', 'lightblue', 'orange', 'mediumpurple', 'lightpink', 'lightcoral']\n",
    "\n",
    "# Determine the number of processes (columns)\n",
    "num_columns = len(df5.columns)\n",
    "\n",
    "# Calculate the number of rows and columns for subplots\n",
    "num_rows = 2  # 3 rows\n",
    "num_cols = 9  # 6 plots per row\n",
    "\n",
    "# Plotting Boxplot for Processes\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(24, 12))  # Adjust figsize as needed\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate over the columns in sequential order\n",
    "for i, col in enumerate(df5.columns):\n",
    "    data = [\n",
    "        df1[col], df2[col], df5[col], df6[col], df11[col], df7[col], df8[col], df9[col], df10[col], df12[col], df13[col], df14[col]\n",
    "    ]\n",
    "    \n",
    "    box = axes[i].boxplot(data, patch_artist=True)\n",
    "    \n",
    "    # Set colors for each box\n",
    "    for patch, color in zip(box['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    axes[i].set_title(f'Process {col}')\n",
    "    axes[i].set_xticklabels([\n",
    "        'TD2C_Ranking_1_1_Var', 'TD2C_Ranking_1_2_Var', 'TD2C_Ranking_2', 'TD2C_Ranking_3', 'TD2C_Ranking_4', 'TD2C_Ranking_5', 'TD2C_Ranking_6', 'TD2C_Ranking_7', 'TD2C_Ranking_NoCont', 'TD2C_R', 'TD2C_Ranking_PastFut', 'D2C_R'\n",
    "    ], rotation=-90)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/recall_boxplot_TD2C_Ranking_best_vs_TD2C.pdf')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DataFrames\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_recall_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_recall_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_recall_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_recall_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_recall_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_recall_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_recall_process)\n",
    "df8 = pd.DataFrame(TD2C_recall_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_recall_process)\n",
    "df10 = pd.DataFrame(D2C_recall_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_recall_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_recall_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_recall_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_recall_process)\n",
    "\n",
    "\n",
    "# Calculate the means\n",
    "means = [\n",
    "    df1.mean().mean(),\n",
    "    df2.mean().mean(),\n",
    "    df5.mean().mean(),\n",
    "    df6.mean().mean(),\n",
    "    df7.mean().mean(),\n",
    "    df8.mean().mean(),\n",
    "    df9.mean().mean(),\n",
    "    df10.mean().mean(),\n",
    "    df11.mean().mean(),\n",
    "    df12.mean().mean(),\n",
    "    df13.mean().mean(),\n",
    "    df14.mean().mean()\n",
    "]\n",
    "\n",
    "# Define the labels\n",
    "labels = [\n",
    "    'TD2C_Ranking_1_1_Var',\n",
    "    'TD2C_Ranking_1_2_Var',\n",
    "    'TD2C_Ranking_2',\n",
    "    'TD2C_Ranking_3',\n",
    "    'TD2C_Ranking_NoCont',\n",
    "    'TD2C_R',\n",
    "    'TD2C_Ranking_PastFut',\n",
    "    'D2C_R',\n",
    "    'TD2C_Ranking_4',\n",
    "    'TD2C_Ranking_5',\n",
    "    'TD2C_Ranking_6',\n",
    "    'TD2C_Ranking_7'\n",
    "]\n",
    "\n",
    "# Define the colors\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen', 'mediumpurple', 'orange', 'lightblue', 'lightgreen', 'lightcoral', 'mediumpurple', 'orange', 'skyblue', 'lightcoral']\n",
    "\n",
    "# Barplot the mean of the ROC-AUC scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(labels, means, color=colors)\n",
    "plt.xticks(rotation=-90)\n",
    "plt.title('Mean Recall scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('Mean Recall score')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a pdf in folder (optional)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/recall_barplot_TD2C_Ranking_best_vs_TD2C.pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW SHOW THE ROUC-AUC RESULTS IN A DATAFRAME DOING THE AVERAGES FOR EACH PROCESS FOR EACH METHOD\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_recall_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_recall_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_recall_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_recall_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_recall_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_recall_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_recall_process)\n",
    "df8 = pd.DataFrame(TD2C_recall_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_recall_process)\n",
    "df10 = pd.DataFrame(D2C_recall_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_recall_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_recall_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_recall_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_recall_process)\n",
    "\n",
    "                   \n",
    "\n",
    "df1 = df1.T\n",
    "df2 = df2.T\n",
    "# df3 = df3.T\n",
    "# df4 = df4.T\n",
    "df5 = df5.T\n",
    "df6 = df6.T\n",
    "df7 = df7.T\n",
    "df8 = df8.T\n",
    "df9 = df9.T\n",
    "df10 = df10.T\n",
    "df11 = df11.T\n",
    "df12 = df12.T\n",
    "df13 = df13.T\n",
    "df14 = df14.T\n",
    "\n",
    "df1['method'] = 'TD2C_Ranking_1_1_Var'\n",
    "df2['method'] = 'TD2C_Ranking_1_2_Var'\n",
    "# df3['method'] = 'TD2C_Ranking_1_3_Var'\n",
    "# df4['method'] = 'TD2C_Ranking_1_10_Var'\n",
    "df5['method'] = 'TD2C_Ranking_2'\n",
    "df6['method'] = 'TD2C_Ranking_3'\n",
    "df11['method'] = 'TD2C_Ranking_4'\n",
    "df12['method'] = 'TD2C_Ranking_5'\n",
    "df13['method'] = 'TD2C_Ranking_6'\n",
    "df14['method'] = 'TD2C_Ranking_7'\n",
    "df7['method'] = 'TD2C_Ranking_NoCont'\n",
    "df8['method'] = 'TD2C_R'\n",
    "df9['method'] = 'TD2C_Ranking_PastFut'\n",
    "df10['method'] = 'D2C_R'\n",
    "\n",
    "df = pd.concat([df1, df2, df5, df6, df11, df7, df12, df13, df14, df8, df9, df10]) # , df3, df4\n",
    "\n",
    "df = df.reset_index()\n",
    "df = df.rename(columns={'index': 'process_id'})\n",
    "\n",
    "df = df.melt(id_vars=['process_id', 'method'], var_name='graph_id', value_name='Recall')\n",
    "\n",
    "df['Recall'] = df['Recall'].astype(float)\n",
    "\n",
    "df = df.groupby(['process_id', 'method']).mean().reset_index()\n",
    "\n",
    "df = df.pivot(index='process_id', columns='method', values='Recall')\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.rename(columns={'process_id': 'Process ID', \n",
    "                        'TD2C_+Ranking_1_1_Var_recall_process': 'TD2C_+Ranking_1_1_Var_recall_process',\n",
    "                        'TD2C_+Ranking_1_2_Var_recall_process': 'TD2C_+Ranking_1_2_Var_recall_process',\n",
    "                        # 'TD2C_+Ranking_1_3_Var_recall_process': 'TD2C_+Ranking_1_3_Var_recall_process',\n",
    "                        # 'TD2C_+Ranking_1_10_Var_recall_process': 'TD2C_+Ranking_1_10_Var_recall_process',\n",
    "                        'TD2C_+Ranking_2_recall_process': 'TD2C_+Ranking_2_recall_process',\n",
    "                        'TD2C_+Ranking_3_recall_process': 'TD2C_+Ranking_3_recall_process',\n",
    "                        'TD2C_+Ranking_4_recall_process': 'TD2C_+Ranking_4_recall_process',\n",
    "                        'TD2C_+Ranking_NoCont_recall_process': 'TD2C_+Ranking_NoCont_recall_process',\n",
    "                        'TD2C_R_recall_process': 'TD2C_R_recall_process',\n",
    "                        'TD2C_+Ranking_PastFut_recall_process': 'TD2C_+Ranking_PastFut_recall_process',\n",
    "                        'D2C_R_recall_process': 'D2C_R_recall_process'})\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# load the dataframe from the csv file\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking.csv')\n",
    "\n",
    "# Plot the dataframe as a heatmap\n",
    "df = df.set_index('Process ID')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df, cmap='coolwarm', annot=True, fmt=\".2f\")\n",
    "plt.title('Recall scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Methods')\n",
    "plt.ylabel('Process ID')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the plot as a pdf in folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/recall_heatmap_TD2C_Ranking.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now average each row of the dataframe\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking.csv')\n",
    "\n",
    "df = df.set_index('Process ID')\n",
    "\n",
    "df = df.mean(axis=1)\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.rename(columns={0: 'Recall'})\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking_mean_proc.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrame\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking.csv')\n",
    "\n",
    "# Strip any leading/trailing spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Plot the DataFrame as a barplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['Process ID'], df['TD2C_R'], color=colors)\n",
    "plt.title('Mean Recall scores for TD2C_Ranking processes, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Process ID')\n",
    "plt.ylabel('Mean Recall')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PDF in the folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/recall_barplot_TD2C_Ranking_mean_proc.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking.csv')\n",
    "\n",
    "# now average the results for each process\n",
    "df = df.mean()\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.rename(columns={'index': 'method', 0: 'recall'})\n",
    "\n",
    "df = df.sort_values(by='recall', ascending=False)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# drop Process ID 0 row\n",
    "df = df.drop(0)\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking_avg.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframe from the csv file\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking_avg.csv')\n",
    "\n",
    "# Plotting Barplot for methods for indexes 1 to 6\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['method'], df['recall'], color=colors)\n",
    "plt.xticks(rotation=-90)\n",
    "plt.title('Mean Recall scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Methods')\n",
    "plt.ylabel('Mean Recall')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the plot as a pdf in folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/recall_barplot_TD2C_Ranking_avg.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMENT OUT THE ONES YOU DIDN'T RUN\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_f1_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_f1_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_f1_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_f1_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_f1_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_f1_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_f1_process)\n",
    "df8 = pd.DataFrame(TD2C_f1_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_f1_process)\n",
    "df10 = pd.DataFrame(D2C_f1_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_f1_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_f1_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_f1_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_f1_process)\n",
    "\n",
    "# Processes 1-9\n",
    "\n",
    "# Combine data for boxplot\n",
    "combined_data = []\n",
    "\n",
    "# Use the first 9 columns (processes)\n",
    "for col in df5.columns[:10]:\n",
    "    combined_data.append(df1[col])\n",
    "    combined_data.append(df2[col])\n",
    "    # combined_data.append(df3[col])\n",
    "    # combined_data.append(df4[col])\n",
    "    combined_data.append(df5[col])\n",
    "    combined_data.append(df6[col])\n",
    "    combined_data.append(df11[col])\n",
    "    combined_data.append(df7[col])\n",
    "    combined_data.append(df8[col])\n",
    "    combined_data.append(df9[col])\n",
    "    combined_data.append(df10[col])\n",
    "    combined_data.append(df12[col])\n",
    "    combined_data.append(df13[col])\n",
    "    combined_data.append(df14[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns[:10]:\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_1_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_2_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_3_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_10_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_2')\n",
    "    labels.append(f'{col}  TD2C_Ranking_3')\n",
    "    labels.append(f'{col}  TD2C_Ranking_4')\n",
    "    labels.append(f'{col}  TD2C_Ranking_5')\n",
    "    labels.append(f'{col}  TD2C_Ranking_6')\n",
    "    labels.append(f'{col}  TD2C_Ranking_7')\n",
    "    labels.append(f'{col}  TD2C_Ranking_NoCont')\n",
    "    labels.append(f'{col}  TD2C_R')\n",
    "    labels.append(f'{col}  TD2C_Ranking_PastFut')\n",
    "    labels.append(f'{col}  D2C_R')\n",
    "\n",
    "# Plotting Boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral'] #, 'lightyellow']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title('Side-by-Side Boxplots F1 scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('Values')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a vertical line every 6 boxes\n",
    "for i in range(12, len(labels), 12):\n",
    "    plt.axvline(x=i + 0.5, color='black', linewidth=0.5)\n",
    "\n",
    "# Save the plot as a pdf in folder (optional)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/f1_boxplot_TD2C_Ranking_1:9.pdf')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Processes 10-20\n",
    "\n",
    "combined_data = []\n",
    "\n",
    "# Use the next 9 columns (processes)\n",
    "for col in df5.columns[10:18]:\n",
    "    combined_data.append(df1[col])\n",
    "    combined_data.append(df2[col])\n",
    "    # combined_data.append(df3[col])\n",
    "    # combined_data.append(df4[col])\n",
    "    combined_data.append(df5[col])\n",
    "    combined_data.append(df6[col])\n",
    "    combined_data.append(df11[col])\n",
    "    combined_data.append(df7[col])\n",
    "    combined_data.append(df8[col])\n",
    "    combined_data.append(df9[col])\n",
    "    combined_data.append(df10[col])\n",
    "    combined_data.append(df12[col])\n",
    "    combined_data.append(df13[col])\n",
    "    combined_data.append(df14[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns[10:18]:\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_1_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_2_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_3_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_10_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_2')\n",
    "    labels.append(f'{col}  TD2C_Ranking_3')\n",
    "    labels.append(f'{col}  TD2C_Ranking_4')\n",
    "    labels.append(f'{col}  TD2C_Ranking_5')\n",
    "    labels.append(f'{col}  TD2C_Ranking_6')\n",
    "    labels.append(f'{col}  TD2C_Ranking_7')\n",
    "    labels.append(f'{col}  TD2C_Ranking_NoCont')\n",
    "    labels.append(f'{col}  TD2C_R')\n",
    "    labels.append(f'{col}  TD2C_Ranking_PastFut')\n",
    "    labels.append(f'{col}  D2C_R')\n",
    "\n",
    "# Plotting Boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral'] #, 'lightyellow']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title('Side-by-Side Boxplots F1 scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('Values')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a vertical line every 6 boxes\n",
    "for i in range(12, len(labels), 12):\n",
    "    plt.axvline(x=i + 0.5, color='black', linewidth=0.5)\n",
    "\n",
    "# Save the plot as a pdf in folder (optional)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/f1_boxplot_TD2C_Ranking_10:20.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOTHER VISUALIZATION OF THE SAME PLOT\n",
    "\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_f1_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_f1_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_f1_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_f1_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_f1_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_f1_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_f1_process)\n",
    "df8 = pd.DataFrame(TD2C_f1_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_f1_process)\n",
    "df10 = pd.DataFrame(D2C_f1_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_f1_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_f1_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_f1_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_f1_process)\n",
    "\n",
    "\n",
    "# Colors to match the provided image more closely\n",
    "colors = ['lightgreen', 'lightblue', 'orange', 'mediumpurple', 'lightpink', 'lightcoral', 'lightyellow', 'lightgrey', 'lightgreen', 'lightblue', 'orange', 'mediumpurple', 'lightpink', 'lightcoral']\n",
    "\n",
    "# Determine the number of processes (columns)\n",
    "num_columns = len(df5.columns)\n",
    "\n",
    "# Calculate the number of rows and columns for subplots\n",
    "num_rows = 2  # 3 rows\n",
    "num_cols = 9  # 6 plots per row\n",
    "\n",
    "# Plotting Boxplot for Processes\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(24, 12))  # Adjust figsize as needed\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate over the columns in sequential order\n",
    "for i, col in enumerate(df5.columns):\n",
    "    data = [\n",
    "        df1[col], df2[col], df5[col], df6[col], df11[col], df7[col], df8[col], df9[col], df10[col], df12[col], df13[col], df14[col]\n",
    "    ]\n",
    "    \n",
    "    box = axes[i].boxplot(data, patch_artist=True)\n",
    "    \n",
    "    # Set colors for each box\n",
    "    for patch, color in zip(box['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    axes[i].set_title(f'Process {col}')\n",
    "    axes[i].set_xticklabels([\n",
    "        'TD2C_Ranking_1_1_Var', 'TD2C_Ranking_1_2_Var', 'TD2C_Ranking_2', 'TD2C_Ranking_3', 'TD2C_Ranking_4', 'TD2C_Ranking_5', 'TD2C_Ranking_6', 'TD2C_Ranking_7', 'TD2C_Ranking_NoCont', 'TD2C_R', 'TD2C_Ranking_PastFut', 'D2C_R'\n",
    "    ], rotation=-90)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/f1_boxplot_TD2C_Ranking_best_vs_TD2C.pdf')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DataFrames\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_f1_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_f1_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_f1_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_f1_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_f1_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_f1_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_f1_process)\n",
    "df8 = pd.DataFrame(TD2C_f1_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_f1_process)\n",
    "df10 = pd.DataFrame(D2C_f1_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_f1_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_f1_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_f1_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_f1_process)\n",
    "\n",
    "\n",
    "# Calculate the means\n",
    "means = [\n",
    "    df1.mean().mean(),\n",
    "    df2.mean().mean(),\n",
    "    df5.mean().mean(),\n",
    "    df6.mean().mean(),\n",
    "    df7.mean().mean(),\n",
    "    df8.mean().mean(),\n",
    "    df9.mean().mean(),\n",
    "    df10.mean().mean(),\n",
    "    df11.mean().mean(),\n",
    "    df12.mean().mean(),\n",
    "    df13.mean().mean(),\n",
    "    df14.mean().mean()\n",
    "]\n",
    "\n",
    "# Define the labels\n",
    "labels = [\n",
    "    'TD2C_Ranking_1_1_Var',\n",
    "    'TD2C_Ranking_1_2_Var',\n",
    "    'TD2C_Ranking_2',\n",
    "    'TD2C_Ranking_3',\n",
    "    'TD2C_Ranking_NoCont',\n",
    "    'TD2C_R',\n",
    "    'TD2C_Ranking_PastFut',\n",
    "    'D2C_R',\n",
    "    'TD2C_Ranking_4',\n",
    "    'TD2C_Ranking_5',\n",
    "    'TD2C_Ranking_6',\n",
    "    'TD2C_Ranking_7'\n",
    "]\n",
    "\n",
    "# Define the colors\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen', 'mediumpurple', 'orange', 'lightblue', 'lightgreen', 'lightcoral', 'mediumpurple', 'orange', 'skyblue', 'lightcoral']\n",
    "\n",
    "# Barplot the mean of the ROC-AUC scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(labels, means, color=colors)\n",
    "plt.xticks(rotation=-90)\n",
    "plt.title('Mean F1 scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('Mean F1 score')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a pdf in folder (optional)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/f1_barplot_TD2C_Ranking_best_vs_TD2C.pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW SHOW THE ROUC-AUC RESULTS IN A DATAFRAME DOING THE AVERAGES FOR EACH PROCESS FOR EACH METHOD\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_f1_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_f1_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_f1_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_f1_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_f1_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_f1_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_f1_process)\n",
    "df8 = pd.DataFrame(TD2C_f1_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_f1_process)\n",
    "df10 = pd.DataFrame(D2C_f1_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_f1_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_f1_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_f1_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_f1_process)\n",
    "\n",
    "df1 = df1.T\n",
    "df2 = df2.T\n",
    "# df3 = df3.T\n",
    "# df4 = df4.T\n",
    "df5 = df5.T\n",
    "df6 = df6.T\n",
    "df7 = df7.T\n",
    "df8 = df8.T\n",
    "df9 = df9.T\n",
    "df10 = df10.T\n",
    "df11 = df11.T\n",
    "df12 = df12.T\n",
    "df13 = df13.T\n",
    "df14 = df14.T\n",
    "\n",
    "df1['method'] = 'TD2C_Ranking_1_1_Var'\n",
    "df2['method'] = 'TD2C_Ranking_1_2_Var'\n",
    "# df3['method'] = 'TD2C_Ranking_1_3_Var'\n",
    "# df4['method'] = 'TD2C_Ranking_1_10_Var'\n",
    "df5['method'] = 'TD2C_Ranking_2'\n",
    "df6['method'] = 'TD2C_Ranking_3'\n",
    "df11['method'] = 'TD2C_Ranking_4'\n",
    "df12['method'] = 'TD2C_Ranking_5'\n",
    "df13['method'] = 'TD2C_Ranking_6'\n",
    "df14['method'] = 'TD2C_Ranking_7'\n",
    "df7['method'] = 'TD2C_Ranking_NoCont'\n",
    "df8['method'] = 'TD2C_R'\n",
    "df9['method'] = 'TD2C_Ranking_PastFut'\n",
    "df10['method'] = 'D2C_R'\n",
    "\n",
    "df = pd.concat([df1, df2, df5, df6, df11, df7, df12, df13, df14, df8, df9, df10]) # , df3, df4\n",
    "\n",
    "df = df.reset_index()\n",
    "df = df.rename(columns={'index': 'process_id'})\n",
    "\n",
    "df = df.melt(id_vars=['process_id', 'method'], var_name='graph_id', value_name='F1')\n",
    "\n",
    "df['F1'] = df['F1'].astype(float)\n",
    "\n",
    "df = df.groupby(['process_id', 'method']).mean().reset_index()\n",
    "\n",
    "df = df.pivot(index='process_id', columns='method', values='F1')\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.rename(columns={'process_id': 'Process ID', \n",
    "                        'TD2C_+Ranking_1_1_Var_f1_process': 'TD2C_+Ranking_1_1_Var_f1_process',\n",
    "                        'TD2C_+Ranking_1_2_Var_f1_process': 'TD2C_+Ranking_1_2_Var_f1_process',\n",
    "                        # 'TD2C_+Ranking_1_3_Var_f1_process': 'TD2C_+Ranking_1_3_Var_f1_process',\n",
    "                        # 'TD2C_+Ranking_1_10_Var_f1_process': 'TD2C_+Ranking_1_10_Var_f1_process',\n",
    "                        'TD2C_+Ranking_2_f1_process': 'TD2C_+Ranking_2_f1_process',\n",
    "                        'TD2C_+Ranking_3_f1_process': 'TD2C_+Ranking_3_f1_process',\n",
    "                        'TD2C_+Ranking_4_f1_process': 'TD2C_+Ranking_4_f1_process',\n",
    "                        'TD2C_+Ranking_NoCont_f1_process': 'TD2C_+Ranking_NoCont_f1_process',\n",
    "                        'TD2C_R_f1_process': 'TD2C_R_f1_process',\n",
    "                        'TD2C_+Ranking_PastFut_f1_process': 'TD2C_+Ranking_PastFut_f1_process',\n",
    "                        'D2C_R_f1_process': 'D2C_R_f1_process'})\n",
    "\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# load the dataframe from the csv file\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking.csv')\n",
    "\n",
    "# Plot the dataframe as a heatmap\n",
    "df = df.set_index('Process ID')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df, cmap='coolwarm', annot=True, fmt=\".2f\")\n",
    "plt.title('F1 scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Methods')\n",
    "plt.ylabel('Process ID')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the plot as a pdf in folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/f1_heatmap_TD2C_Ranking.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now average each row of the dataframe\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking.csv')\n",
    "\n",
    "df = df.set_index('Process ID')\n",
    "\n",
    "df = df.mean(axis=1)\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.rename(columns={0: 'F1'})\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking_mean_proc.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrame\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking.csv')\n",
    "\n",
    "# Strip any leading/trailing spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Plot the DataFrame as a barplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['Process ID'], df['TD2C_R'], color=colors)\n",
    "plt.title('Mean F1 scores for TD2C_Ranking processes, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Process ID')\n",
    "plt.ylabel('Mean F1')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PDF in the folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/f1_barplot_TD2C_Ranking_mean_proc.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking.csv')\n",
    "\n",
    "# now average the results for each process\n",
    "df = df.mean()\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.rename(columns={'index': 'method', 0: 'f1'})\n",
    "\n",
    "df = df.sort_values(by='f1', ascending=False)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# drop Process ID 0 row\n",
    "df = df.drop(0)\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking_avg.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframe from the csv file\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking_avg.csv')\n",
    "\n",
    "# Plotting Barplot for methods for indexes 1 to 6\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['method'], df['f1'], color=colors)\n",
    "plt.xticks(rotation=-90)\n",
    "plt.title('Mean F1 scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Methods')\n",
    "plt.ylabel('Mean F1')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the plot as a pdf in folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/f1_barplot_TD2C_Ranking_avg.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLOT SUMMARY - BEST METHOD OVERALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/roc_auc_td2c_ranking.csv')\n",
    "# boxplot for ROC-AUC\n",
    "df_r = df_r.set_index('Process ID')\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df_r, palette='coolwarm')\n",
    "plt.title('Boxplot of ROC-AUC scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Methods')\n",
    "plt.ylabel('ROC-AUC')\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=-90)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/roc_auc_boxplot_TD2C_all_methods.pdf')\n",
    "plt.show()\n",
    "\n",
    "df_p = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking.csv')\n",
    "# boxplot for Precision\n",
    "df_p = df_p.set_index('Process ID')\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df_p, palette='coolwarm')\n",
    "plt.title('Boxplot of Precision scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Methods')\n",
    "plt.ylabel('Precision')\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=-90)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/precision_boxplot_TD2C_all_methods.pdf')\n",
    "plt.show()\n",
    "\n",
    "df_r = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking.csv')\n",
    "# boxplot for Recall\n",
    "df_r = df_r.set_index('Process ID')\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df_r, palette='coolwarm')\n",
    "plt.title('Boxplot of Recall scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Methods')\n",
    "plt.ylabel('Recall')\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=-90)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/recall_boxplot_TD2C_all_methods.pdf')\n",
    "plt.show()\n",
    "\n",
    "df_f1 = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking.csv')\n",
    "# boxplot for F1\n",
    "df_f1 = df_f1.set_index('Process ID')\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df_f1, palette='coolwarm')\n",
    "plt.title('Boxplot of F1 scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Methods')\n",
    "plt.ylabel('F1')\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=-90)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/f1_boxplot_TD2C_all_methods.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Read CSV files\n",
    "df_r = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/roc_auc_td2c_ranking.csv')\n",
    "df_p = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking.csv')\n",
    "df_recall = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking.csv')\n",
    "df_f1 = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking.csv')\n",
    "\n",
    "# Set index\n",
    "df_r = df_r.set_index('Process ID')\n",
    "df_p = df_p.set_index('Process ID')\n",
    "df_recall = df_recall.set_index('Process ID')\n",
    "df_f1 = df_f1.set_index('Process ID')\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 12))\n",
    "\n",
    "# Plot ROC-AUC\n",
    "sns.boxplot(data=df_r, palette='coolwarm', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Boxplot of ROC-AUC scores for TD2C_Ranking methods')\n",
    "axes[0, 0].set_xlabel('Methods')\n",
    "axes[0, 0].set_ylabel('ROC-AUC')\n",
    "axes[0, 0].tick_params(axis='x', rotation=-90)\n",
    "\n",
    "# Plot Precision\n",
    "sns.boxplot(data=df_p, palette='coolwarm', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Boxplot of Precision scores for TD2C_Ranking methods')\n",
    "axes[0, 1].set_xlabel('Methods')\n",
    "axes[0, 1].set_ylabel('Precision')\n",
    "axes[0, 1].tick_params(axis='x', rotation=-90)\n",
    "\n",
    "# Plot Recall\n",
    "sns.boxplot(data=df_recall, palette='coolwarm', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Boxplot of Recall scores for TD2C_Ranking methods')\n",
    "axes[1, 0].set_xlabel('Methods')\n",
    "axes[1, 0].set_ylabel('Recall')\n",
    "axes[1, 0].tick_params(axis='x', rotation=-90)\n",
    "\n",
    "# Plot F1\n",
    "sns.boxplot(data=df_f1, palette='coolwarm', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Boxplot of F1 scores for TD2C_Ranking methods')\n",
    "axes[1, 1].set_xlabel('Methods')\n",
    "axes[1, 1].set_ylabel('F1')\n",
    "axes[1, 1].tick_params(axis='x', rotation=-90)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/combined_boxplot_TD2C_all_methods.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the DataFrames\n",
    "df_r = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/roc_auc_td2c_ranking.csv')\n",
    "df_r_av = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/roc_auc_td2c_ranking_avg.csv')\n",
    "df_p = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking.csv')\n",
    "df_p_av = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking_avg.csv')\n",
    "df_rec = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking.csv')\n",
    "df_rec_av = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking_avg.csv')\n",
    "df_f1 = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking.csv')\n",
    "df_f1_av = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking_avg.csv')\n",
    "\n",
    "# Remove the first column\n",
    "df_r = df_r.drop('Process ID', axis=1)\n",
    "df_p = df_p.drop('Process ID', axis=1)\n",
    "df_rec = df_rec.drop('Process ID', axis=1)\n",
    "df_f1 = df_f1.drop('Process ID', axis=1)\n",
    "\n",
    "# Sort the columns to match the order of the average DataFrames' rows\n",
    "df_r = df_r[df_r_av['method']]\n",
    "df_p = df_p[df_p_av['method']]\n",
    "df_rec = df_rec[df_rec_av['method']]\n",
    "df_f1 = df_f1[df_f1_av['method']]\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Boxplot for ROC-AUC\n",
    "sns.boxplot(data=df_r, orient='v', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Boxplot of ROC-AUC scores for TD2C_Ranking methods')\n",
    "axes[0, 0].set_xlabel('Methods')\n",
    "axes[0, 0].set_ylabel('ROC-AUC')\n",
    "axes[0, 0].tick_params(axis='x', rotation=90)\n",
    "\n",
    "# Boxplot for Precision\n",
    "sns.boxplot(data=df_p, orient='v', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Boxplot of Precision scores for TD2C_Ranking methods')\n",
    "axes[0, 1].set_xlabel('Methods')\n",
    "axes[0, 1].set_ylabel('Precision')\n",
    "axes[0, 1].tick_params(axis='x', rotation=90)\n",
    "\n",
    "# Boxplot for Recall\n",
    "sns.boxplot(data=df_rec, orient='v', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Boxplot of Recall scores for TD2C_Ranking methods')\n",
    "axes[1, 0].set_xlabel('Methods')\n",
    "axes[1, 0].set_ylabel('Recall')\n",
    "axes[1, 0].tick_params(axis='x', rotation=90)\n",
    "\n",
    "# Boxplot for F1\n",
    "sns.boxplot(data=df_f1, orient='v', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Boxplot of F1 scores for TD2C_Ranking methods')\n",
    "axes[1, 1].set_xlabel('Methods')\n",
    "axes[1, 1].set_ylabel('F1')\n",
    "axes[1, 1].tick_params(axis='x', rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# save the plot as a pdf in folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/boxplot_TD2C_all_metrics.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 5 methods for roc-auc\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/roc_auc_td2c_ranking_avg.csv')\n",
    "df_r = df.head(8)\n",
    "\n",
    "# for precision\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking_avg.csv')\n",
    "df_p = df.head(8)\n",
    "\n",
    "# for recall\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking_avg.csv')\n",
    "df_re = df.head(8)\n",
    "\n",
    "# for f1\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking_avg.csv')\n",
    "df_f = df.head(8)\n",
    "\n",
    "# merge the dataframes\n",
    "df = pd.merge(df_r, df_p, on='method')\n",
    "df = pd.merge(df, df_re, on='method')\n",
    "df = pd.merge(df, df_f, on='method')\n",
    "\n",
    "df = df.rename(columns={'roc_auc': 'ROC-AUC', 'precision': 'Precision', 'recall': 'Recall', 'f1': 'F1'})\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/top_td2c_methods_merged.csv', index=False)\n",
    "\n",
    "df # these methods are in the top 5 for all metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 5 methods for roc-auc\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/roc_auc_td2c_ranking_avg.csv')\n",
    "df_r = df.head(8)\n",
    "\n",
    "# for precision\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking_avg.csv')\n",
    "df_p = df.head(8)\n",
    "\n",
    "# for recall\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking_avg.csv')\n",
    "df_re = df.head(8)\n",
    "\n",
    "# for f1\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking_avg.csv')\n",
    "df_f = df.head(8)\n",
    "\n",
    "# combine the dataframes without merging\n",
    "df = pd.concat([df_r, df_p, df_re, df_f])\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df = df.rename(columns={'roc_auc': 'ROC-AUC', 'precision': 'Precision', 'recall': 'Recall', 'f1': 'F1'})\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/top_td2c_methods.csv', index=False)\n",
    "\n",
    "df # these methods are in the top 5 for at least one metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # top 5 methods for roc-auc\n",
    "df_r = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/roc_auc_td2c_ranking_avg.csv')\n",
    "df_r['points_r'] = [12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n",
    "\n",
    "# for precision\n",
    "df_p = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking_avg.csv')\n",
    "df_p['points_p'] = [12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n",
    "\n",
    "# for recall\n",
    "df_re = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking_avg.csv')\n",
    "df_re['points_re'] = [12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n",
    "\n",
    "# for f1\n",
    "df_f = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking_avg.csv')\n",
    "df_f['points_f'] = [12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n",
    "\n",
    "# merge the dataframes\n",
    "df = pd.merge(df_r, df_p, on='method')\n",
    "df = pd.merge(df, df_re, on='method')\n",
    "df = pd.merge(df, df_f, on='method')\n",
    "\n",
    "# sum the points for each method\n",
    "df['points'] = df['points_r'] + df['points_p'] + df['points_re'] + df['points_f']\n",
    "\n",
    "df = df.sort_values(by='points', ascending=False)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# drop points_r, points_p, points_re, points_f columns\n",
    "df = df.drop(columns=['points_r', 'points_p', 'points_re', 'points_f'])\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/top_td2c_methods_points.csv', index=False)\n",
    "\n",
    "# plot the points for each method\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['method'], df['points'], color=colors)\n",
    "plt.xticks(rotation=-90)\n",
    "plt.title('Points for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Methods')\n",
    "plt.ylabel('Points')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the plot as a pdf in folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/top_td2c_methods_points.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 5 methods for roc-auc\n",
    "df_r = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/roc_auc_td2c_ranking_avg.csv')\n",
    "# for precision\n",
    "df_p = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking_avg.csv')\n",
    "# for recall\n",
    "df_re = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking_avg.csv')\n",
    "# for f1\n",
    "df_f = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking_avg.csv')\n",
    "\n",
    "# merge the dataframes\n",
    "df = pd.merge(df_r, df_p, on='method')\n",
    "df = pd.merge(df, df_re, on='method')\n",
    "df = pd.merge(df, df_f, on='method')\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/td2c_methods_all_metrics_merged.csv', index=False)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the DataFrames\n",
    "df_r = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/roc_auc_td2c_ranking_avg.csv')\n",
    "df_p = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking_avg.csv')\n",
    "df_re = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking_avg.csv')\n",
    "df_f = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking_avg.csv')\n",
    "\n",
    "# Merge the DataFrames on 'method'\n",
    "df = pd.merge(df_r, df_p, on='method')\n",
    "df = pd.merge(df, df_re, on='method')\n",
    "df = pd.merge(df, df_f, on='method')\n",
    "\n",
    "# Rename columns for clarity\n",
    "df = df.rename(columns={'roc_auc': 'ROC-AUC', 'precision': 'Precision', 'recall': 'Recall', 'f1': 'F1'})\n",
    "\n",
    "# Number of methods\n",
    "n_methods = len(df['method'])\n",
    "\n",
    "# Positions of the bars on the x-axis\n",
    "bar_width = 0.2\n",
    "r1 = np.arange(n_methods)\n",
    "r2 = [x + bar_width for x in r1]\n",
    "r3 = [x + bar_width for x in r2]\n",
    "\n",
    "# Plotting Barplot for methods with separated bars\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(r1, df['Precision'], color='lightcoral', width=bar_width, edgecolor='grey', label='Precision')\n",
    "plt.bar(r2, df['Recall'], color='lightgreen', width=bar_width, edgecolor='grey', label='Recall')\n",
    "plt.bar(r3, df['F1'], color='mediumpurple', width=bar_width, edgecolor='grey', label='F1')\n",
    "\n",
    "# Adding xticks\n",
    "plt.xlabel('Methods', fontweight='bold')\n",
    "plt.xticks([r + bar_width for r in range(n_methods)], df['method'], rotation=-90)\n",
    "\n",
    "plt.title('Mean scores for TD2C_Ranking methods fro metrics Precision, Recall and F1 (Methods in ascending order of ROC-AUC)')\n",
    "plt.ylabel('Mean scores')\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PDF in the folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/top_td2c_methods_all_metrics_separated.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNNCMI for MI estimation (FOLDERS TO CHANGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMENT OUT THE ONES YOU DIDN'T RUN\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_rocs_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_rocs_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_rocs_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_rocs_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_rocs_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_rocs_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_rocs_process)\n",
    "df8 = pd.DataFrame(TD2C_rocs_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_rocs_process)\n",
    "df10 = pd.DataFrame(D2C_rocs_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_rocs_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_rocs_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_rocs_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_rocs_process)\n",
    "\n",
    "# Processes 1-9\n",
    "\n",
    "# Combine data for boxplot\n",
    "combined_data = []\n",
    "\n",
    "# Use the first 9 columns (processes)\n",
    "for col in df5.columns[:10]:\n",
    "    combined_data.append(df1[col])\n",
    "    combined_data.append(df2[col])\n",
    "    # combined_data.append(df3[col])\n",
    "    # combined_data.append(df4[col])\n",
    "    combined_data.append(df5[col])\n",
    "    combined_data.append(df6[col])\n",
    "    combined_data.append(df11[col])\n",
    "    combined_data.append(df7[col])\n",
    "    combined_data.append(df8[col])\n",
    "    combined_data.append(df9[col])\n",
    "    combined_data.append(df10[col])\n",
    "    combined_data.append(df12[col])\n",
    "    combined_data.append(df13[col])\n",
    "    combined_data.append(df14[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns[:10]:\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_1_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_2_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_3_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_10_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_2')\n",
    "    labels.append(f'{col}  TD2C_Ranking_3')\n",
    "    labels.append(f'{col}  TD2C_Ranking_4')\n",
    "    labels.append(f'{col}  TD2C_Ranking_5')\n",
    "    labels.append(f'{col}  TD2C_Ranking_6')\n",
    "    labels.append(f'{col}  TD2C_Ranking_7')\n",
    "    labels.append(f'{col}  TD2C_Ranking_NoCont')\n",
    "    labels.append(f'{col}  TD2C_R')\n",
    "    labels.append(f'{col}  TD2C_Ranking_PastFut')\n",
    "    labels.append(f'{col}  D2C_R')\n",
    "\n",
    "# Plotting Boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral'] #, 'lightyellow']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title('Side-by-Side Boxplots ROC-AUC scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('Values')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a vertical line every 6 boxes\n",
    "for i in range(12, len(labels), 12):\n",
    "    plt.axvline(x=i + 0.5, color='black', linewidth=0.5)\n",
    "\n",
    "# Save the plot as a pdf in folder (optional)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/rocauc_boxplot_TD2C_Ranking_1:9.pdf')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Processes 10-20\n",
    "\n",
    "combined_data = []\n",
    "\n",
    "# Use the next 9 columns (processes)\n",
    "for col in df5.columns[10:18]:\n",
    "    combined_data.append(df1[col])\n",
    "    combined_data.append(df2[col])\n",
    "    # combined_data.append(df3[col])\n",
    "    # combined_data.append(df4[col])\n",
    "    combined_data.append(df5[col])\n",
    "    combined_data.append(df6[col])\n",
    "    combined_data.append(df11[col])\n",
    "    combined_data.append(df7[col])\n",
    "    combined_data.append(df8[col])\n",
    "    combined_data.append(df9[col])\n",
    "    combined_data.append(df10[col])\n",
    "    combined_data.append(df12[col])\n",
    "    combined_data.append(df13[col])\n",
    "    combined_data.append(df14[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns[10:18]:\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_1_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_2_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_3_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_10_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_2')\n",
    "    labels.append(f'{col}  TD2C_Ranking_3')\n",
    "    labels.append(f'{col}  TD2C_Ranking_4')\n",
    "    labels.append(f'{col}  TD2C_Ranking_5')\n",
    "    labels.append(f'{col}  TD2C_Ranking_6')\n",
    "    labels.append(f'{col}  TD2C_Ranking_7')\n",
    "    labels.append(f'{col}  TD2C_Ranking_NoCont')\n",
    "    labels.append(f'{col}  TD2C_R')\n",
    "    labels.append(f'{col}  TD2C_Ranking_PastFut')\n",
    "    labels.append(f'{col}  D2C_R')\n",
    "\n",
    "# Plotting Boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral'] #, 'lightyellow']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title('Side-by-Side Boxplots ROC-AUC scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('Values')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a vertical line every 6 boxes\n",
    "for i in range(12, len(labels), 12):\n",
    "    plt.axvline(x=i + 0.5, color='black', linewidth=0.5)\n",
    "\n",
    "# Save the plot as a pdf in folder (optional)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/rocauc_boxplot_TD2C_Ranking_10:20.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOTHER VISUALIZATION OF THE SAME PLOT\n",
    "\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_rocs_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_rocs_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_rocs_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_rocs_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_rocs_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_rocs_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_rocs_process)\n",
    "df8 = pd.DataFrame(TD2C_rocs_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_rocs_process)\n",
    "df10 = pd.DataFrame(D2C_rocs_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_rocs_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_rocs_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_rocs_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_rocs_process)\n",
    "\n",
    "# Colors to match the provided image more closely\n",
    "colors = ['lightgreen', 'lightblue', 'orange', 'mediumpurple', 'lightpink', 'lightcoral', 'lightyellow', 'lightgrey', 'lightgreen', 'lightblue', 'orange', 'mediumpurple', 'lightpink', 'lightcoral']\n",
    "\n",
    "# Determine the number of processes (columns)\n",
    "num_columns = len(df5.columns)\n",
    "\n",
    "# Calculate the number of rows and columns for subplots\n",
    "num_rows = 2  # 3 rows\n",
    "num_cols = 9  # 6 plots per row\n",
    "\n",
    "# Plotting Boxplot for Processes\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(24, 12))  # Adjust figsize as needed\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate over the columns in sequential order\n",
    "for i, col in enumerate(df5.columns):\n",
    "    data = [\n",
    "        df1[col], df2[col], df5[col], df6[col], df11[col], df7[col], df8[col], df9[col], df10[col], df12[col], df13[col], df14[col]\n",
    "    ]\n",
    "    \n",
    "    box = axes[i].boxplot(data, patch_artist=True)\n",
    "    \n",
    "    # Set colors for each box\n",
    "    for patch, color in zip(box['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    axes[i].set_title(f'Process {col}')\n",
    "    axes[i].set_xticklabels([\n",
    "        'TD2C_Ranking_1_1_Var', 'TD2C_Ranking_1_2_Var', 'TD2C_Ranking_2', 'TD2C_Ranking_3', 'TD2C_Ranking_4', 'TD2C_Ranking_5', 'TD2C_Ranking_6', 'TD2C_Ranking_7', 'TD2C_Ranking_NoCont', 'TD2C_R', 'TD2C_Ranking_PastFut', 'D2C_R'\n",
    "    ], rotation=-90)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/rocouc_boxplot_TD2C_Ranking_best_vs_TD2C.pdf')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DataFrames\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_rocs_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_rocs_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_rocs_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_rocs_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_rocs_process)\n",
    "df8 = pd.DataFrame(TD2C_rocs_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_rocs_process)\n",
    "df10 = pd.DataFrame(D2C_rocs_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_rocs_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_rocs_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_rocs_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_rocs_process)\n",
    "\n",
    "# Calculate the means\n",
    "means = [\n",
    "    df1.mean().mean(),\n",
    "    df2.mean().mean(),\n",
    "    df5.mean().mean(),\n",
    "    df6.mean().mean(),\n",
    "    df7.mean().mean(),\n",
    "    df8.mean().mean(),\n",
    "    df9.mean().mean(),\n",
    "    df10.mean().mean(),\n",
    "    df11.mean().mean(),\n",
    "    df12.mean().mean(),\n",
    "    df13.mean().mean(),\n",
    "    df14.mean().mean()\n",
    "]\n",
    "\n",
    "# Define the labels\n",
    "labels = [\n",
    "    'TD2C_Ranking_1_1_Var',\n",
    "    'TD2C_Ranking_1_2_Var',\n",
    "    'TD2C_Ranking_2',\n",
    "    'TD2C_Ranking_3',\n",
    "    'TD2C_Ranking_NoCont',\n",
    "    'TD2C_R',\n",
    "    'TD2C_Ranking_PastFut',\n",
    "    'D2C_R',\n",
    "    'TD2C_Ranking_4',\n",
    "    'TD2C_Ranking_5',\n",
    "    'TD2C_Ranking_6',\n",
    "    'TD2C_Ranking_7'\n",
    "]\n",
    "\n",
    "# Define the colors\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen', 'mediumpurple', 'orange', 'lightblue', 'lightgreen', 'lightcoral', 'mediumpurple', 'orange', 'skyblue', 'lightcoral']\n",
    "\n",
    "# Barplot the mean of the ROC-AUC scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(labels, means, color=colors)\n",
    "plt.xticks(rotation=-90)\n",
    "plt.title('Mean ROC-AUC scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('Mean ROC-AUC score')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a pdf in folder (optional)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/rocauc_barplot_TD2C_Ranking_best_vs_TD2C.pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW SHOW THE ROUC-AUC RESULTS IN A DATAFRAME DOING THE AVERAGES FOR EACH PROCESS FOR EACH METHOD\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_rocs_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_rocs_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_rocs_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_rocs_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_rocs_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_rocs_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_rocs_process)\n",
    "df8 = pd.DataFrame(TD2C_rocs_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_rocs_process)\n",
    "df10 = pd.DataFrame(D2C_rocs_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_rocs_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_rocs_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_rocs_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_rocs_process)\n",
    "\n",
    "df1 = df1.T\n",
    "df2 = df2.T\n",
    "# df3 = df3.T\n",
    "# df4 = df4.T\n",
    "df5 = df5.T\n",
    "df6 = df6.T\n",
    "df7 = df7.T\n",
    "df8 = df8.T\n",
    "df9 = df9.T\n",
    "df10 = df10.T\n",
    "df11 = df11.T\n",
    "df12 = df12.T\n",
    "df13 = df13.T\n",
    "df14 = df14.T\n",
    "\n",
    "df1['method'] = 'TD2C_Ranking_1_1_Var'\n",
    "df2['method'] = 'TD2C_Ranking_1_2_Var'\n",
    "# df3['method'] = 'TD2C_Ranking_1_3_Var'\n",
    "# df4['method'] = 'TD2C_Ranking_1_10_Var'\n",
    "df5['method'] = 'TD2C_Ranking_2'\n",
    "df6['method'] = 'TD2C_Ranking_3'\n",
    "df11['method'] = 'TD2C_Ranking_4'\n",
    "df12['method'] = 'TD2C_Ranking_5'\n",
    "df13['method'] = 'TD2C_Ranking_6'\n",
    "df14['method'] = 'TD2C_Ranking_7'\n",
    "df7['method'] = 'TD2C_Ranking_NoCont'\n",
    "df8['method'] = 'TD2C_R'\n",
    "df9['method'] = 'TD2C_Ranking_PastFut'\n",
    "df10['method'] = 'D2C_R'\n",
    "\n",
    "df = pd.concat([df1, df2, df5, df6, df11, df7, df12, df13, df14, df8, df9, df10]) # , df3, df4\n",
    "\n",
    "df = df.reset_index()\n",
    "df = df.rename(columns={'index': 'process_id'})\n",
    "\n",
    "df = df.melt(id_vars=['process_id', 'method'], var_name='graph_id', value_name='roc_auc')\n",
    "\n",
    "df['roc_auc'] = df['roc_auc'].astype(float)\n",
    "\n",
    "df = df.groupby(['process_id', 'method']).mean().reset_index()\n",
    "\n",
    "df = df.pivot(index='process_id', columns='method', values='roc_auc')\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.rename(columns={'process_id': 'Process ID', \n",
    "                        'TD2C_+Ranking_1_1_Var_rocs_process': 'TD2C_+Ranking_1_1_Var_rocs_process', \n",
    "                        'TD2C_+Ranking_1_2_Var_rocs_process': 'TD2C_+Ranking_1_2_Var_rocs_process', \n",
    "                        # 'TD2C_+Ranking_1_3_Var_rocs_process': 'TD2C_+Ranking_1_3_Var_rocs_process',\n",
    "                        # 'TD2C_+Ranking_1_10_Var_rocs_process': 'TD2C_+Ranking_1_10_Var_rocs_process', \n",
    "                        'TD2C_+Ranking_2_rocs_process': 'TD2C_+Ranking_2_rocs_process', \n",
    "                        'TD2C_+Ranking_3_rocs_process': 'TD2C_+Ranking_3_rocs_process',\n",
    "                        'TD2C_+Ranking_4_rocs_process': 'TD2C_+Ranking_4_rocs_process', \n",
    "                        'TD2C_+Ranking_NoCont_rocs_process': 'TD2C_+Ranking_NoCont_rocs_process',\n",
    "                        'TD2C_R_rocs_process': 'TD2C_R_rocs_process',\n",
    "                        'TD2C_+Ranking_PastFut_rocs_process': 'TD2C_+Ranking_PastFut_rocs_process',\n",
    "                        'D2C_R_rocs_process': 'D2C_R_rocs_process'})\n",
    "\n",
    "# eliminate the column method and make the process_id the index of the dataframe\n",
    "\n",
    "\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/roc_auc_td2c_ranking.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# load the dataframe from the csv file\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/roc_auc_td2c_ranking.csv')\n",
    "\n",
    "# Plot the dataframe as a heatmap\n",
    "df = df.set_index('Process ID')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df, cmap='coolwarm', annot=True, fmt=\".2f\")\n",
    "plt.title('ROC-AUC scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Methods')\n",
    "plt.ylabel('Process ID')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the plot as a pdf in folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/rocauc_heatmap_TD2C_Ranking.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now average each row of the dataframe\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/roc_auc_td2c_ranking.csv')\n",
    "\n",
    "df = df.set_index('Process ID')\n",
    "\n",
    "df = df.mean(axis=1)\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.rename(columns={0: 'roc_auc'})\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/roc_auc_td2c_ranking_mean_proc.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrame\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/roc_auc_td2c_ranking.csv')\n",
    "\n",
    "# Strip any leading/trailing spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Plot the DataFrame as a barplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['Process ID'], df['TD2C_R'], color=colors)\n",
    "plt.title('Mean ROC-AUC scores for TD2C_Ranking processes, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Process ID')\n",
    "plt.ylabel('Mean ROC-AUC')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PDF in the folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/rocauc_barplot_TD2C_Ranking_mean_proc.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/roc_auc_td2c_ranking.csv')\n",
    "\n",
    "# now average the results for each process\n",
    "df = df.mean()\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.rename(columns={'index': 'method', 0: 'roc_auc'})\n",
    "\n",
    "df = df.sort_values(by='roc_auc', ascending=False)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# drop Process ID 0 row\n",
    "df = df.drop(0)\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/rocauc_td2c_ranking_avg.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframe from the csv file\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/roc_auc_td2c_ranking_avg.csv')\n",
    "\n",
    "# Plotting Barplot for methods for indexes 1 to 6\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['method'], df['roc_auc'], color=colors)\n",
    "plt.xticks(rotation=-90)\n",
    "plt.title('Mean ROC-AUC scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Methods')\n",
    "plt.ylabel('Mean ROC-AUC')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the plot as a pdf in folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/rocauc_barplot_TD2C_Ranking_avg.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMENT OUT THE ONES YOU DIDN'T RUN\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_precision_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_precision_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_precision_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_precision_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_precision_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_precision_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_precision_process)\n",
    "df8 = pd.DataFrame(TD2C_precision_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_precision_process)\n",
    "df10 = pd.DataFrame(D2C_precision_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_precision_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_precision_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_precision_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_precision_process)\n",
    "\n",
    "# Processes 1-9\n",
    "\n",
    "# Combine data for boxplot\n",
    "combined_data = []\n",
    "\n",
    "# Use the first 9 columns (processes)\n",
    "for col in df5.columns[:10]:\n",
    "    combined_data.append(df1[col])\n",
    "    combined_data.append(df2[col])\n",
    "    # combined_data.append(df3[col])\n",
    "    # combined_data.append(df4[col])\n",
    "    combined_data.append(df5[col])\n",
    "    combined_data.append(df6[col])\n",
    "    combined_data.append(df11[col])\n",
    "    combined_data.append(df7[col])\n",
    "    combined_data.append(df8[col])\n",
    "    combined_data.append(df9[col])\n",
    "    combined_data.append(df10[col])\n",
    "    combined_data.append(df12[col])\n",
    "    combined_data.append(df13[col])\n",
    "    combined_data.append(df14[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns[:10]:\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_1_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_2_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_3_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_10_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_2')\n",
    "    labels.append(f'{col}  TD2C_Ranking_3')\n",
    "    labels.append(f'{col}  TD2C_Ranking_4')\n",
    "    labels.append(f'{col}  TD2C_Ranking_5')\n",
    "    labels.append(f'{col}  TD2C_Ranking_6')\n",
    "    labels.append(f'{col}  TD2C_Ranking_7')\n",
    "    labels.append(f'{col}  TD2C_Ranking_NoCont')\n",
    "    labels.append(f'{col}  TD2C_R')\n",
    "    labels.append(f'{col}  TD2C_Ranking_PastFut')\n",
    "    labels.append(f'{col}  D2C_R')\n",
    "\n",
    "# Plotting Boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral'] #, 'lightyellow']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title('Side-by-Side Boxplots Precision scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('Values')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a vertical line every 6 boxes\n",
    "for i in range(12, len(labels), 12):\n",
    "    plt.axvline(x=i + 0.5, color='black', linewidth=0.5)\n",
    "\n",
    "# Save the plot as a pdf in folder (optional)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/precision_boxplot_TD2C_Ranking_1:9.pdf')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Processes 10-20\n",
    "\n",
    "combined_data = []\n",
    "\n",
    "# Use the next 9 columns (processes)\n",
    "for col in df5.columns[10:18]:\n",
    "    combined_data.append(df1[col])\n",
    "    combined_data.append(df2[col])\n",
    "    # combined_data.append(df3[col])\n",
    "    # combined_data.append(df4[col])\n",
    "    combined_data.append(df5[col])\n",
    "    combined_data.append(df6[col])\n",
    "    combined_data.append(df11[col])\n",
    "    combined_data.append(df7[col])\n",
    "    combined_data.append(df8[col])\n",
    "    combined_data.append(df9[col])\n",
    "    combined_data.append(df10[col])\n",
    "    combined_data.append(df12[col])\n",
    "    combined_data.append(df13[col])\n",
    "    combined_data.append(df14[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns[10:18]:\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_1_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_2_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_3_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_10_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_2')\n",
    "    labels.append(f'{col}  TD2C_Ranking_3')\n",
    "    labels.append(f'{col}  TD2C_Ranking_4')\n",
    "    labels.append(f'{col}  TD2C_Ranking_5')\n",
    "    labels.append(f'{col}  TD2C_Ranking_6')\n",
    "    labels.append(f'{col}  TD2C_Ranking_7')\n",
    "    labels.append(f'{col}  TD2C_Ranking_NoCont')\n",
    "    labels.append(f'{col}  TD2C_R')\n",
    "    labels.append(f'{col}  TD2C_Ranking_PastFut')\n",
    "    labels.append(f'{col}  D2C_R')\n",
    "\n",
    "# Plotting Boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral'] #, 'lightyellow']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title('Side-by-Side Boxplots Precision scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('Values')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a vertical line every 6 boxes\n",
    "for i in range(12, len(labels), 12):\n",
    "    plt.axvline(x=i + 0.5, color='black', linewidth=0.5)\n",
    "\n",
    "# Save the plot as a pdf in folder (optional)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/precision_boxplot_TD2C_Ranking_10:20.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOTHER VISUALIZATION OF THE SAME PLOT\n",
    "\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_precision_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_precision_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_precision_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_precision_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_precision_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_precision_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_precision_process)\n",
    "df8 = pd.DataFrame(TD2C_precision_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_precision_process)\n",
    "df10 = pd.DataFrame(D2C_precision_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_precision_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_precision_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_precision_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_precision_process)\n",
    "\n",
    "# Colors to match the provided image more closely\n",
    "colors = ['lightgreen', 'lightblue', 'orange', 'mediumpurple', 'lightpink', 'lightcoral', 'lightyellow', 'lightgrey', 'lightgreen', 'lightblue', 'orange', 'mediumpurple', 'lightpink', 'lightcoral']\n",
    "\n",
    "# Determine the number of processes (columns)\n",
    "num_columns = len(df5.columns)\n",
    "\n",
    "# Calculate the number of rows and columns for subplots\n",
    "num_rows = 2  # 3 rows\n",
    "num_cols = 9  # 6 plots per row\n",
    "\n",
    "# Plotting Boxplot for Processes\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(24, 12))  # Adjust figsize as needed\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate over the columns in sequential order\n",
    "for i, col in enumerate(df5.columns):\n",
    "    data = [\n",
    "        df1[col], df2[col], df5[col], df6[col], df11[col], df7[col], df8[col], df9[col], df10[col], df12[col], df13[col], df14[col]\n",
    "    ]\n",
    "    \n",
    "    box = axes[i].boxplot(data, patch_artist=True)\n",
    "    \n",
    "    # Set colors for each box\n",
    "    for patch, color in zip(box['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    axes[i].set_title(f'Process {col}')\n",
    "    axes[i].set_xticklabels([\n",
    "        'TD2C_Ranking_1_1_Var', 'TD2C_Ranking_1_2_Var', 'TD2C_Ranking_2', 'TD2C_Ranking_3', 'TD2C_Ranking_4', 'TD2C_Ranking_5', 'TD2C_Ranking_6', 'TD2C_Ranking_7', 'TD2C_Ranking_NoCont', 'TD2C_R', 'TD2C_Ranking_PastFut', 'D2C_R'\n",
    "    ], rotation=-90)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/precision_boxplot_TD2C_Ranking_best_vs_TD2C.pdf')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DataFrames\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_precision_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_precision_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_precision_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_precision_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_precision_process)\n",
    "df8 = pd.DataFrame(TD2C_precision_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_precision_process)\n",
    "df10 = pd.DataFrame(D2C_precision_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_precision_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_precision_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_precision_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_precision_process)\n",
    "\n",
    "\n",
    "# Calculate the means\n",
    "means = [\n",
    "    df1.mean().mean(),\n",
    "    df2.mean().mean(),\n",
    "    df5.mean().mean(),\n",
    "    df6.mean().mean(),\n",
    "    df7.mean().mean(),\n",
    "    df8.mean().mean(),\n",
    "    df9.mean().mean(),\n",
    "    df10.mean().mean(),\n",
    "    df11.mean().mean(),\n",
    "    df12.mean().mean(),\n",
    "    df13.mean().mean(),\n",
    "    df14.mean().mean()\n",
    "]\n",
    "\n",
    "# Define the labels\n",
    "labels = [\n",
    "    'TD2C_Ranking_1_1_Var',\n",
    "    'TD2C_Ranking_1_2_Var',\n",
    "    'TD2C_Ranking_2',\n",
    "    'TD2C_Ranking_3',\n",
    "    'TD2C_Ranking_NoCont',\n",
    "    'TD2C_R',\n",
    "    'TD2C_Ranking_PastFut',\n",
    "    'D2C_R',\n",
    "    'TD2C_Ranking_4',\n",
    "    'TD2C_Ranking_5',\n",
    "    'TD2C_Ranking_6',\n",
    "    'TD2C_Ranking_7'\n",
    "]\n",
    "\n",
    "# Define the colors\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen', 'mediumpurple', 'orange', 'lightblue', 'lightgreen', 'lightcoral', 'mediumpurple', 'orange', 'skyblue', 'lightcoral']\n",
    "\n",
    "# Barplot the mean of the ROC-AUC scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(labels, means, color=colors)\n",
    "plt.xticks(rotation=-90)\n",
    "plt.title('Mean Precision scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('Mean Precision score')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a pdf in folder (optional)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/precision_barplot_TD2C_Ranking_best_vs_TD2C.pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW SHOW THE ROUC-AUC RESULTS IN A DATAFRAME DOING THE AVERAGES FOR EACH PROCESS FOR EACH METHOD\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_precision_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_precision_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_precision_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_precision_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_precision_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_precision_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_precision_process)\n",
    "df8 = pd.DataFrame(TD2C_precision_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_precision_process)\n",
    "df10 = pd.DataFrame(D2C_precision_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_precision_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_precision_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_precision_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_precision_process)\n",
    "\n",
    "df1 = df1.T\n",
    "df2 = df2.T\n",
    "# df3 = df3.T\n",
    "# df4 = df4.T\n",
    "df5 = df5.T\n",
    "df6 = df6.T\n",
    "df7 = df7.T\n",
    "df8 = df8.T\n",
    "df9 = df9.T\n",
    "df10 = df10.T\n",
    "df11 = df11.T\n",
    "df12 = df12.T\n",
    "df13 = df13.T\n",
    "df14 = df14.T\n",
    "\n",
    "df1['method'] = 'TD2C_Ranking_1_1_Var'\n",
    "df2['method'] = 'TD2C_Ranking_1_2_Var'\n",
    "# df3['method'] = 'TD2C_Ranking_1_3_Var'\n",
    "# df4['method'] = 'TD2C_Ranking_1_10_Var'\n",
    "df5['method'] = 'TD2C_Ranking_2'\n",
    "df6['method'] = 'TD2C_Ranking_3'\n",
    "df11['method'] = 'TD2C_Ranking_4'\n",
    "df12['method'] = 'TD2C_Ranking_5'\n",
    "df13['method'] = 'TD2C_Ranking_6'\n",
    "df14['method'] = 'TD2C_Ranking_7'\n",
    "df7['method'] = 'TD2C_Ranking_NoCont'\n",
    "df8['method'] = 'TD2C_R'\n",
    "df9['method'] = 'TD2C_Ranking_PastFut'\n",
    "df10['method'] = 'D2C_R'\n",
    "\n",
    "df = pd.concat([df1, df2, df5, df6, df11, df7, df12, df13, df14, df8, df9, df10]) # , df3, df4\n",
    "\n",
    "df = df.reset_index()\n",
    "df = df.rename(columns={'index': 'process_id'})\n",
    "\n",
    "df = df.melt(id_vars=['process_id', 'method'], var_name='graph_id', value_name='Precision')\n",
    "\n",
    "df['Precision'] = df['Precision'].astype(float)\n",
    "\n",
    "df = df.groupby(['process_id', 'method']).mean().reset_index()\n",
    "\n",
    "df = df.pivot(index='process_id', columns='method', values='Precision')\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.rename(columns={'process_id': 'Process ID', \n",
    "                        'TD2C_+Ranking_1_1_Var_precision_process': 'TD2C_+Ranking_1_1_Var_precision_process',\n",
    "                        'TD2C_+Ranking_1_2_Var_precision_process': 'TD2C_+Ranking_1_2_Var_precision_process',\n",
    "                        # 'TD2C_+Ranking_1_3_Var_precision_process': 'TD2C_+Ranking_1_3_Var_precision_process',\n",
    "                        # 'TD2C_+Ranking_1_10_Var_precision_process': 'TD2C_+Ranking_1_10_Var_precision_process',\n",
    "                        'TD2C_+Ranking_2_precision_process': 'TD2C_+Ranking_2_precision_process',\n",
    "                        'TD2C_+Ranking_3_precision_process': 'TD2C_+Ranking_3_precision_process',\n",
    "                        'TD2C_+Ranking_4_precision_process': 'TD2C_+Ranking_4_precision_process',\n",
    "                        'TD2C_+Ranking_NoCont_precision_process': 'TD2C_+Ranking_NoCont_precision_process',\n",
    "                        'TD2C_R_precision_process': 'TD2C_R_precision_process',\n",
    "                        'TD2C_+Ranking_PastFut_precision_process': 'TD2C_+Ranking_PastFut_precision_process',\n",
    "                        'D2C_R_precision_process': 'D2C_R_precision_process'})\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# load the dataframe from the csv file\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking.csv')\n",
    "\n",
    "# Plot the dataframe as a heatmap\n",
    "df = df.set_index('Process ID')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df, cmap='coolwarm', annot=True, fmt=\".2f\")\n",
    "plt.title('Precision scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Methods')\n",
    "plt.ylabel('Process ID')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the plot as a pdf in folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/precision_heatmap_TD2C_Ranking.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now average each row of the dataframe\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking.csv')\n",
    "\n",
    "df = df.set_index('Process ID')\n",
    "\n",
    "df = df.mean(axis=1)\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.rename(columns={0: 'Precision'})\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking_mean_proc.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrame\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking.csv')\n",
    "\n",
    "# Strip any leading/trailing spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Plot the DataFrame as a barplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['Process ID'], df['TD2C_R'], color=colors)\n",
    "plt.title('Mean Precision scores for TD2C_Ranking processes, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Process ID')\n",
    "plt.ylabel('Mean Precision')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PDF in the folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/precision_barplot_TD2C_Ranking_mean_proc.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking.csv')\n",
    "\n",
    "# now average the results for each process\n",
    "df = df.mean()\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.rename(columns={'index': 'method', 0: 'precision'})\n",
    "\n",
    "df = df.sort_values(by='precision', ascending=False)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# drop Process ID 0 row\n",
    "df = df.drop(0)\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking_avg.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframe from the csv file\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/precision_td2c_ranking_avg.csv')\n",
    "\n",
    "# Plotting Barplot for methods for indexes 1 to 6\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['method'], df['precision'], color=colors)\n",
    "plt.xticks(rotation=-90)\n",
    "plt.title('Mean Precision scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Methods')\n",
    "plt.ylabel('Mean Precision')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the plot as a pdf in folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/precision_barplot_TD2C_Ranking_avg.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMENT OUT THE ONES YOU DIDN'T RUN\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_recall_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_recall_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_recall_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_recall_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_recall_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_recall_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_recall_process)\n",
    "df8 = pd.DataFrame(TD2C_recall_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_recall_process)\n",
    "df10 = pd.DataFrame(D2C_recall_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_recall_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_recall_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_recall_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_recall_process)\n",
    "\n",
    "\n",
    "# Processes 1-9\n",
    "\n",
    "# Combine data for boxplot\n",
    "combined_data = []\n",
    "\n",
    "# Use the first 9 columns (processes)\n",
    "for col in df5.columns[:10]:\n",
    "    combined_data.append(df1[col])\n",
    "    combined_data.append(df2[col])\n",
    "    # combined_data.append(df3[col])\n",
    "    # combined_data.append(df4[col])\n",
    "    combined_data.append(df5[col])\n",
    "    combined_data.append(df6[col])\n",
    "    combined_data.append(df11[col])\n",
    "    combined_data.append(df7[col])\n",
    "    combined_data.append(df8[col])\n",
    "    combined_data.append(df9[col])\n",
    "    combined_data.append(df10[col])\n",
    "    combined_data.append(df12[col])\n",
    "    combined_data.append(df13[col])\n",
    "    combined_data.append(df14[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns[:10]:\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_1_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_2_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_3_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_10_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_2')\n",
    "    labels.append(f'{col}  TD2C_Ranking_3')\n",
    "    labels.append(f'{col}  TD2C_Ranking_4')\n",
    "    labels.append(f'{col}  TD2C_Ranking_5')\n",
    "    labels.append(f'{col}  TD2C_Ranking_6')\n",
    "    labels.append(f'{col}  TD2C_Ranking_7')\n",
    "    labels.append(f'{col}  TD2C_Ranking_NoCont')\n",
    "    labels.append(f'{col}  TD2C_R')\n",
    "    labels.append(f'{col}  TD2C_Ranking_PastFut')\n",
    "    labels.append(f'{col}  D2C_R')\n",
    "\n",
    "# Plotting Boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral'] #, 'lightyellow']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title('Side-by-Side Boxplots Recall scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('Values')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a vertical line every 6 boxes\n",
    "for i in range(12, len(labels), 12):\n",
    "    plt.axvline(x=i + 0.5, color='black', linewidth=0.5)\n",
    "\n",
    "# Save the plot as a pdf in folder (optional)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/recall_boxplot_TD2C_Ranking_1:9.pdf')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Processes 10-20\n",
    "\n",
    "combined_data = []\n",
    "\n",
    "# Use the next 9 columns (processes)\n",
    "for col in df5.columns[10:18]:\n",
    "    combined_data.append(df1[col])\n",
    "    combined_data.append(df2[col])\n",
    "    # combined_data.append(df3[col])\n",
    "    # combined_data.append(df4[col])\n",
    "    combined_data.append(df5[col])\n",
    "    combined_data.append(df6[col])\n",
    "    combined_data.append(df11[col])\n",
    "    combined_data.append(df7[col])\n",
    "    combined_data.append(df8[col])\n",
    "    combined_data.append(df9[col])\n",
    "    combined_data.append(df10[col])\n",
    "    combined_data.append(df12[col])\n",
    "    combined_data.append(df13[col])\n",
    "    combined_data.append(df14[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns[10:18]:\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_1_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_2_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_3_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_10_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_2')\n",
    "    labels.append(f'{col}  TD2C_Ranking_3')\n",
    "    labels.append(f'{col}  TD2C_Ranking_4')\n",
    "    labels.append(f'{col}  TD2C_Ranking_5')\n",
    "    labels.append(f'{col}  TD2C_Ranking_6')\n",
    "    labels.append(f'{col}  TD2C_Ranking_7')\n",
    "    labels.append(f'{col}  TD2C_Ranking_NoCont')\n",
    "    labels.append(f'{col}  TD2C_R')\n",
    "    labels.append(f'{col}  TD2C_Ranking_PastFut')\n",
    "    labels.append(f'{col}  D2C_R')\n",
    "\n",
    "# Plotting Boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral'] #, 'lightyellow']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title('Side-by-Side Boxplots Recall scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('Values')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a vertical line every 6 boxes\n",
    "for i in range(12, len(labels), 12):\n",
    "    plt.axvline(x=i + 0.5, color='black', linewidth=0.5)\n",
    "\n",
    "# Save the plot as a pdf in folder (optional)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/recall_boxplot_TD2C_Ranking_10:20.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOTHER VISUALIZATION OF THE SAME PLOT\n",
    "\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_recall_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_recall_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_recall_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_recall_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_recall_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_recall_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_recall_process)\n",
    "df8 = pd.DataFrame(TD2C_recall_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_recall_process)\n",
    "df10 = pd.DataFrame(D2C_recall_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_recall_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_recall_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_recall_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_recall_process)\n",
    "\n",
    "# Colors to match the provided image more closely\n",
    "colors = ['lightgreen', 'lightblue', 'orange', 'mediumpurple', 'lightpink', 'lightcoral', 'lightyellow', 'lightgrey', 'lightgreen', 'lightblue', 'orange', 'mediumpurple', 'lightpink', 'lightcoral']\n",
    "\n",
    "# Determine the number of processes (columns)\n",
    "num_columns = len(df5.columns)\n",
    "\n",
    "# Calculate the number of rows and columns for subplots\n",
    "num_rows = 2  # 3 rows\n",
    "num_cols = 9  # 6 plots per row\n",
    "\n",
    "# Plotting Boxplot for Processes\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(24, 12))  # Adjust figsize as needed\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate over the columns in sequential order\n",
    "for i, col in enumerate(df5.columns):\n",
    "    data = [\n",
    "        df1[col], df2[col], df5[col], df6[col], df11[col], df7[col], df8[col], df9[col], df10[col], df12[col], df13[col], df14[col]\n",
    "    ]\n",
    "    \n",
    "    box = axes[i].boxplot(data, patch_artist=True)\n",
    "    \n",
    "    # Set colors for each box\n",
    "    for patch, color in zip(box['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    axes[i].set_title(f'Process {col}')\n",
    "    axes[i].set_xticklabels([\n",
    "        'TD2C_Ranking_1_1_Var', 'TD2C_Ranking_1_2_Var', 'TD2C_Ranking_2', 'TD2C_Ranking_3', 'TD2C_Ranking_4', 'TD2C_Ranking_5', 'TD2C_Ranking_6', 'TD2C_Ranking_7', 'TD2C_Ranking_NoCont', 'TD2C_R', 'TD2C_Ranking_PastFut', 'D2C_R'\n",
    "    ], rotation=-90)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/recall_boxplot_TD2C_Ranking_best_vs_TD2C.pdf')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DataFrames\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_recall_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_recall_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_recall_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_recall_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_recall_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_recall_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_recall_process)\n",
    "df8 = pd.DataFrame(TD2C_recall_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_recall_process)\n",
    "df10 = pd.DataFrame(D2C_recall_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_recall_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_recall_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_recall_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_recall_process)\n",
    "\n",
    "\n",
    "# Calculate the means\n",
    "means = [\n",
    "    df1.mean().mean(),\n",
    "    df2.mean().mean(),\n",
    "    df5.mean().mean(),\n",
    "    df6.mean().mean(),\n",
    "    df7.mean().mean(),\n",
    "    df8.mean().mean(),\n",
    "    df9.mean().mean(),\n",
    "    df10.mean().mean(),\n",
    "    df11.mean().mean(),\n",
    "    df12.mean().mean(),\n",
    "    df13.mean().mean(),\n",
    "    df14.mean().mean()\n",
    "]\n",
    "\n",
    "# Define the labels\n",
    "labels = [\n",
    "    'TD2C_Ranking_1_1_Var',\n",
    "    'TD2C_Ranking_1_2_Var',\n",
    "    'TD2C_Ranking_2',\n",
    "    'TD2C_Ranking_3',\n",
    "    'TD2C_Ranking_NoCont',\n",
    "    'TD2C_R',\n",
    "    'TD2C_Ranking_PastFut',\n",
    "    'D2C_R',\n",
    "    'TD2C_Ranking_4',\n",
    "    'TD2C_Ranking_5',\n",
    "    'TD2C_Ranking_6',\n",
    "    'TD2C_Ranking_7'\n",
    "]\n",
    "\n",
    "# Define the colors\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen', 'mediumpurple', 'orange', 'lightblue', 'lightgreen', 'lightcoral', 'mediumpurple', 'orange', 'skyblue', 'lightcoral']\n",
    "\n",
    "# Barplot the mean of the ROC-AUC scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(labels, means, color=colors)\n",
    "plt.xticks(rotation=-90)\n",
    "plt.title('Mean Recall scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('Mean Recall score')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a pdf in folder (optional)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/recall_barplot_TD2C_Ranking_best_vs_TD2C.pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW SHOW THE ROUC-AUC RESULTS IN A DATAFRAME DOING THE AVERAGES FOR EACH PROCESS FOR EACH METHOD\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_recall_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_recall_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_recall_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_recall_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_recall_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_recall_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_recall_process)\n",
    "df8 = pd.DataFrame(TD2C_recall_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_recall_process)\n",
    "df10 = pd.DataFrame(D2C_recall_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_recall_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_recall_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_recall_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_recall_process)\n",
    "\n",
    "                   \n",
    "\n",
    "df1 = df1.T\n",
    "df2 = df2.T\n",
    "# df3 = df3.T\n",
    "# df4 = df4.T\n",
    "df5 = df5.T\n",
    "df6 = df6.T\n",
    "df7 = df7.T\n",
    "df8 = df8.T\n",
    "df9 = df9.T\n",
    "df10 = df10.T\n",
    "df11 = df11.T\n",
    "df12 = df12.T\n",
    "df13 = df13.T\n",
    "df14 = df14.T\n",
    "\n",
    "df1['method'] = 'TD2C_Ranking_1_1_Var'\n",
    "df2['method'] = 'TD2C_Ranking_1_2_Var'\n",
    "# df3['method'] = 'TD2C_Ranking_1_3_Var'\n",
    "# df4['method'] = 'TD2C_Ranking_1_10_Var'\n",
    "df5['method'] = 'TD2C_Ranking_2'\n",
    "df6['method'] = 'TD2C_Ranking_3'\n",
    "df11['method'] = 'TD2C_Ranking_4'\n",
    "df12['method'] = 'TD2C_Ranking_5'\n",
    "df13['method'] = 'TD2C_Ranking_6'\n",
    "df14['method'] = 'TD2C_Ranking_7'\n",
    "df7['method'] = 'TD2C_Ranking_NoCont'\n",
    "df8['method'] = 'TD2C_R'\n",
    "df9['method'] = 'TD2C_Ranking_PastFut'\n",
    "df10['method'] = 'D2C_R'\n",
    "\n",
    "df = pd.concat([df1, df2, df5, df6, df11, df7, df12, df13, df14, df8, df9, df10]) # , df3, df4\n",
    "\n",
    "df = df.reset_index()\n",
    "df = df.rename(columns={'index': 'process_id'})\n",
    "\n",
    "df = df.melt(id_vars=['process_id', 'method'], var_name='graph_id', value_name='Recall')\n",
    "\n",
    "df['Recall'] = df['Recall'].astype(float)\n",
    "\n",
    "df = df.groupby(['process_id', 'method']).mean().reset_index()\n",
    "\n",
    "df = df.pivot(index='process_id', columns='method', values='Recall')\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.rename(columns={'process_id': 'Process ID', \n",
    "                        'TD2C_+Ranking_1_1_Var_recall_process': 'TD2C_+Ranking_1_1_Var_recall_process',\n",
    "                        'TD2C_+Ranking_1_2_Var_recall_process': 'TD2C_+Ranking_1_2_Var_recall_process',\n",
    "                        # 'TD2C_+Ranking_1_3_Var_recall_process': 'TD2C_+Ranking_1_3_Var_recall_process',\n",
    "                        # 'TD2C_+Ranking_1_10_Var_recall_process': 'TD2C_+Ranking_1_10_Var_recall_process',\n",
    "                        'TD2C_+Ranking_2_recall_process': 'TD2C_+Ranking_2_recall_process',\n",
    "                        'TD2C_+Ranking_3_recall_process': 'TD2C_+Ranking_3_recall_process',\n",
    "                        'TD2C_+Ranking_4_recall_process': 'TD2C_+Ranking_4_recall_process',\n",
    "                        'TD2C_+Ranking_NoCont_recall_process': 'TD2C_+Ranking_NoCont_recall_process',\n",
    "                        'TD2C_R_recall_process': 'TD2C_R_recall_process',\n",
    "                        'TD2C_+Ranking_PastFut_recall_process': 'TD2C_+Ranking_PastFut_recall_process',\n",
    "                        'D2C_R_recall_process': 'D2C_R_recall_process'})\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# load the dataframe from the csv file\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking.csv')\n",
    "\n",
    "# Plot the dataframe as a heatmap\n",
    "df = df.set_index('Process ID')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df, cmap='coolwarm', annot=True, fmt=\".2f\")\n",
    "plt.title('Recall scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Methods')\n",
    "plt.ylabel('Process ID')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the plot as a pdf in folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/recall_heatmap_TD2C_Ranking.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now average each row of the dataframe\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking.csv')\n",
    "\n",
    "df = df.set_index('Process ID')\n",
    "\n",
    "df = df.mean(axis=1)\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.rename(columns={0: 'Recall'})\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking_mean_proc.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrame\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking.csv')\n",
    "\n",
    "# Strip any leading/trailing spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Plot the DataFrame as a barplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['Process ID'], df['TD2C_R'], color=colors)\n",
    "plt.title('Mean Recall scores for TD2C_Ranking processes, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Process ID')\n",
    "plt.ylabel('Mean Recall')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PDF in the folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/recall_barplot_TD2C_Ranking_mean_proc.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking.csv')\n",
    "\n",
    "# now average the results for each process\n",
    "df = df.mean()\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.rename(columns={'index': 'method', 0: 'recall'})\n",
    "\n",
    "df = df.sort_values(by='recall', ascending=False)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# drop Process ID 0 row\n",
    "df = df.drop(0)\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking_avg.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframe from the csv file\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/recall_td2c_ranking_avg.csv')\n",
    "\n",
    "# Plotting Barplot for methods for indexes 1 to 6\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['method'], df['recall'], color=colors)\n",
    "plt.xticks(rotation=-90)\n",
    "plt.title('Mean Recall scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Methods')\n",
    "plt.ylabel('Mean Recall')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the plot as a pdf in folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/recall_barplot_TD2C_Ranking_avg.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMENT OUT THE ONES YOU DIDN'T RUN\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_f1_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_f1_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_f1_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_f1_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_f1_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_f1_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_f1_process)\n",
    "df8 = pd.DataFrame(TD2C_f1_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_f1_process)\n",
    "df10 = pd.DataFrame(D2C_f1_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_f1_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_f1_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_f1_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_f1_process)\n",
    "\n",
    "# Processes 1-9\n",
    "\n",
    "# Combine data for boxplot\n",
    "combined_data = []\n",
    "\n",
    "# Use the first 9 columns (processes)\n",
    "for col in df5.columns[:10]:\n",
    "    combined_data.append(df1[col])\n",
    "    combined_data.append(df2[col])\n",
    "    # combined_data.append(df3[col])\n",
    "    # combined_data.append(df4[col])\n",
    "    combined_data.append(df5[col])\n",
    "    combined_data.append(df6[col])\n",
    "    combined_data.append(df11[col])\n",
    "    combined_data.append(df7[col])\n",
    "    combined_data.append(df8[col])\n",
    "    combined_data.append(df9[col])\n",
    "    combined_data.append(df10[col])\n",
    "    combined_data.append(df12[col])\n",
    "    combined_data.append(df13[col])\n",
    "    combined_data.append(df14[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns[:10]:\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_1_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_2_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_3_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_10_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_2')\n",
    "    labels.append(f'{col}  TD2C_Ranking_3')\n",
    "    labels.append(f'{col}  TD2C_Ranking_4')\n",
    "    labels.append(f'{col}  TD2C_Ranking_5')\n",
    "    labels.append(f'{col}  TD2C_Ranking_6')\n",
    "    labels.append(f'{col}  TD2C_Ranking_7')\n",
    "    labels.append(f'{col}  TD2C_Ranking_NoCont')\n",
    "    labels.append(f'{col}  TD2C_R')\n",
    "    labels.append(f'{col}  TD2C_Ranking_PastFut')\n",
    "    labels.append(f'{col}  D2C_R')\n",
    "\n",
    "# Plotting Boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral'] #, 'lightyellow']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title('Side-by-Side Boxplots F1 scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('Values')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a vertical line every 6 boxes\n",
    "for i in range(12, len(labels), 12):\n",
    "    plt.axvline(x=i + 0.5, color='black', linewidth=0.5)\n",
    "\n",
    "# Save the plot as a pdf in folder (optional)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/f1_boxplot_TD2C_Ranking_1:9.pdf')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Processes 10-20\n",
    "\n",
    "combined_data = []\n",
    "\n",
    "# Use the next 9 columns (processes)\n",
    "for col in df5.columns[10:18]:\n",
    "    combined_data.append(df1[col])\n",
    "    combined_data.append(df2[col])\n",
    "    # combined_data.append(df3[col])\n",
    "    # combined_data.append(df4[col])\n",
    "    combined_data.append(df5[col])\n",
    "    combined_data.append(df6[col])\n",
    "    combined_data.append(df11[col])\n",
    "    combined_data.append(df7[col])\n",
    "    combined_data.append(df8[col])\n",
    "    combined_data.append(df9[col])\n",
    "    combined_data.append(df10[col])\n",
    "    combined_data.append(df12[col])\n",
    "    combined_data.append(df13[col])\n",
    "    combined_data.append(df14[col])\n",
    "\n",
    "# Create labels for x-axis\n",
    "labels = []\n",
    "for col in df1.columns[10:18]:\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_1_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_2_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_3_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_1_10_Var')\n",
    "    labels.append(f'{col}  TD2C_Ranking_2')\n",
    "    labels.append(f'{col}  TD2C_Ranking_3')\n",
    "    labels.append(f'{col}  TD2C_Ranking_4')\n",
    "    labels.append(f'{col}  TD2C_Ranking_5')\n",
    "    labels.append(f'{col}  TD2C_Ranking_6')\n",
    "    labels.append(f'{col}  TD2C_Ranking_7')\n",
    "    labels.append(f'{col}  TD2C_Ranking_NoCont')\n",
    "    labels.append(f'{col}  TD2C_R')\n",
    "    labels.append(f'{col}  TD2C_Ranking_PastFut')\n",
    "    labels.append(f'{col}  D2C_R')\n",
    "\n",
    "# Plotting Boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(combined_data, patch_artist=True)\n",
    "\n",
    "# Color customization\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral'] #, 'lightyellow']\n",
    "for patch, i in zip(box['boxes'], range(len(box['boxes']))):\n",
    "    patch.set_facecolor(colors[i % 3])\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=-90)\n",
    "plt.title('Side-by-Side Boxplots F1 scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('Values')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a vertical line every 6 boxes\n",
    "for i in range(12, len(labels), 12):\n",
    "    plt.axvline(x=i + 0.5, color='black', linewidth=0.5)\n",
    "\n",
    "# Save the plot as a pdf in folder (optional)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/f1_boxplot_TD2C_Ranking_10:20.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOTHER VISUALIZATION OF THE SAME PLOT\n",
    "\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_f1_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_f1_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_f1_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_f1_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_f1_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_f1_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_f1_process)\n",
    "df8 = pd.DataFrame(TD2C_f1_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_f1_process)\n",
    "df10 = pd.DataFrame(D2C_f1_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_f1_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_f1_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_f1_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_f1_process)\n",
    "\n",
    "\n",
    "# Colors to match the provided image more closely\n",
    "colors = ['lightgreen', 'lightblue', 'orange', 'mediumpurple', 'lightpink', 'lightcoral', 'lightyellow', 'lightgrey', 'lightgreen', 'lightblue', 'orange', 'mediumpurple', 'lightpink', 'lightcoral']\n",
    "\n",
    "# Determine the number of processes (columns)\n",
    "num_columns = len(df5.columns)\n",
    "\n",
    "# Calculate the number of rows and columns for subplots\n",
    "num_rows = 2  # 3 rows\n",
    "num_cols = 9  # 6 plots per row\n",
    "\n",
    "# Plotting Boxplot for Processes\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(24, 12))  # Adjust figsize as needed\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate over the columns in sequential order\n",
    "for i, col in enumerate(df5.columns):\n",
    "    data = [\n",
    "        df1[col], df2[col], df5[col], df6[col], df11[col], df7[col], df8[col], df9[col], df10[col], df12[col], df13[col], df14[col]\n",
    "    ]\n",
    "    \n",
    "    box = axes[i].boxplot(data, patch_artist=True)\n",
    "    \n",
    "    # Set colors for each box\n",
    "    for patch, color in zip(box['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    axes[i].set_title(f'Process {col}')\n",
    "    axes[i].set_xticklabels([\n",
    "        'TD2C_Ranking_1_1_Var', 'TD2C_Ranking_1_2_Var', 'TD2C_Ranking_2', 'TD2C_Ranking_3', 'TD2C_Ranking_4', 'TD2C_Ranking_5', 'TD2C_Ranking_6', 'TD2C_Ranking_7', 'TD2C_Ranking_NoCont', 'TD2C_R', 'TD2C_Ranking_PastFut', 'D2C_R'\n",
    "    ], rotation=-90)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/f1_boxplot_TD2C_Ranking_best_vs_TD2C.pdf')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DataFrames\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_f1_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_f1_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_f1_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_f1_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_f1_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_f1_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_f1_process)\n",
    "df8 = pd.DataFrame(TD2C_f1_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_f1_process)\n",
    "df10 = pd.DataFrame(D2C_f1_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_f1_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_f1_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_f1_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_f1_process)\n",
    "\n",
    "\n",
    "# Calculate the means\n",
    "means = [\n",
    "    df1.mean().mean(),\n",
    "    df2.mean().mean(),\n",
    "    df5.mean().mean(),\n",
    "    df6.mean().mean(),\n",
    "    df7.mean().mean(),\n",
    "    df8.mean().mean(),\n",
    "    df9.mean().mean(),\n",
    "    df10.mean().mean(),\n",
    "    df11.mean().mean(),\n",
    "    df12.mean().mean(),\n",
    "    df13.mean().mean(),\n",
    "    df14.mean().mean()\n",
    "]\n",
    "\n",
    "# Define the labels\n",
    "labels = [\n",
    "    'TD2C_Ranking_1_1_Var',\n",
    "    'TD2C_Ranking_1_2_Var',\n",
    "    'TD2C_Ranking_2',\n",
    "    'TD2C_Ranking_3',\n",
    "    'TD2C_Ranking_NoCont',\n",
    "    'TD2C_R',\n",
    "    'TD2C_Ranking_PastFut',\n",
    "    'D2C_R',\n",
    "    'TD2C_Ranking_4',\n",
    "    'TD2C_Ranking_5',\n",
    "    'TD2C_Ranking_6',\n",
    "    'TD2C_Ranking_7'\n",
    "]\n",
    "\n",
    "# Define the colors\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen', 'mediumpurple', 'orange', 'lightblue', 'lightgreen', 'lightcoral', 'mediumpurple', 'orange', 'skyblue', 'lightcoral']\n",
    "\n",
    "# Barplot the mean of the ROC-AUC scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(labels, means, color=colors)\n",
    "plt.xticks(rotation=-90)\n",
    "plt.title('Mean F1 scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Processes')\n",
    "plt.ylabel('Mean F1 score')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a pdf in folder (optional)\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/f1_barplot_TD2C_Ranking_best_vs_TD2C.pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW SHOW THE ROUC-AUC RESULTS IN A DATAFRAME DOING THE AVERAGES FOR EACH PROCESS FOR EACH METHOD\n",
    "df1 = pd.DataFrame(TD2C_Ranking_1_1_Var_f1_process)\n",
    "df2 = pd.DataFrame(TD2C_Ranking_1_2_Var_f1_process)\n",
    "# df3 = pd.DataFrame(TD2C_Ranking_1_3_Var_f1_process)\n",
    "# df4 = pd.DataFrame(TD2C_Ranking_1_10_Var_f1_process)\n",
    "df5 = pd.DataFrame(TD2C_Ranking_2_f1_process)\n",
    "df6 = pd.DataFrame(TD2C_Ranking_3_f1_process)\n",
    "df7 = pd.DataFrame(TD2C_Ranking_NoCont_f1_process)\n",
    "df8 = pd.DataFrame(TD2C_f1_process)\n",
    "df9 = pd.DataFrame(TD2C_Ranking_PastFut_f1_process)\n",
    "df10 = pd.DataFrame(D2C_f1_process)\n",
    "df11 = pd.DataFrame(TD2C_Ranking_4_f1_process)\n",
    "df12 = pd.DataFrame(TD2C_Ranking_5_f1_process)\n",
    "df13 = pd.DataFrame(TD2C_Ranking_6_f1_process)\n",
    "df14 = pd.DataFrame(TD2C_Ranking_7_f1_process)\n",
    "\n",
    "df1 = df1.T\n",
    "df2 = df2.T\n",
    "# df3 = df3.T\n",
    "# df4 = df4.T\n",
    "df5 = df5.T\n",
    "df6 = df6.T\n",
    "df7 = df7.T\n",
    "df8 = df8.T\n",
    "df9 = df9.T\n",
    "df10 = df10.T\n",
    "df11 = df11.T\n",
    "df12 = df12.T\n",
    "df13 = df13.T\n",
    "df14 = df14.T\n",
    "\n",
    "df1['method'] = 'TD2C_Ranking_1_1_Var'\n",
    "df2['method'] = 'TD2C_Ranking_1_2_Var'\n",
    "# df3['method'] = 'TD2C_Ranking_1_3_Var'\n",
    "# df4['method'] = 'TD2C_Ranking_1_10_Var'\n",
    "df5['method'] = 'TD2C_Ranking_2'\n",
    "df6['method'] = 'TD2C_Ranking_3'\n",
    "df11['method'] = 'TD2C_Ranking_4'\n",
    "df12['method'] = 'TD2C_Ranking_5'\n",
    "df13['method'] = 'TD2C_Ranking_6'\n",
    "df14['method'] = 'TD2C_Ranking_7'\n",
    "df7['method'] = 'TD2C_Ranking_NoCont'\n",
    "df8['method'] = 'TD2C_R'\n",
    "df9['method'] = 'TD2C_Ranking_PastFut'\n",
    "df10['method'] = 'D2C_R'\n",
    "\n",
    "df = pd.concat([df1, df2, df5, df6, df11, df7, df12, df13, df14, df8, df9, df10]) # , df3, df4\n",
    "\n",
    "df = df.reset_index()\n",
    "df = df.rename(columns={'index': 'process_id'})\n",
    "\n",
    "df = df.melt(id_vars=['process_id', 'method'], var_name='graph_id', value_name='F1')\n",
    "\n",
    "df['F1'] = df['F1'].astype(float)\n",
    "\n",
    "df = df.groupby(['process_id', 'method']).mean().reset_index()\n",
    "\n",
    "df = df.pivot(index='process_id', columns='method', values='F1')\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.rename(columns={'process_id': 'Process ID', \n",
    "                        'TD2C_+Ranking_1_1_Var_f1_process': 'TD2C_+Ranking_1_1_Var_f1_process',\n",
    "                        'TD2C_+Ranking_1_2_Var_f1_process': 'TD2C_+Ranking_1_2_Var_f1_process',\n",
    "                        # 'TD2C_+Ranking_1_3_Var_f1_process': 'TD2C_+Ranking_1_3_Var_f1_process',\n",
    "                        # 'TD2C_+Ranking_1_10_Var_f1_process': 'TD2C_+Ranking_1_10_Var_f1_process',\n",
    "                        'TD2C_+Ranking_2_f1_process': 'TD2C_+Ranking_2_f1_process',\n",
    "                        'TD2C_+Ranking_3_f1_process': 'TD2C_+Ranking_3_f1_process',\n",
    "                        'TD2C_+Ranking_4_f1_process': 'TD2C_+Ranking_4_f1_process',\n",
    "                        'TD2C_+Ranking_NoCont_f1_process': 'TD2C_+Ranking_NoCont_f1_process',\n",
    "                        'TD2C_R_f1_process': 'TD2C_R_f1_process',\n",
    "                        'TD2C_+Ranking_PastFut_f1_process': 'TD2C_+Ranking_PastFut_f1_process',\n",
    "                        'D2C_R_f1_process': 'D2C_R_f1_process'})\n",
    "\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# load the dataframe from the csv file\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking.csv')\n",
    "\n",
    "# Plot the dataframe as a heatmap\n",
    "df = df.set_index('Process ID')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df, cmap='coolwarm', annot=True, fmt=\".2f\")\n",
    "plt.title('F1 scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Methods')\n",
    "plt.ylabel('Process ID')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the plot as a pdf in folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/f1_heatmap_TD2C_Ranking.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now average each row of the dataframe\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking.csv')\n",
    "\n",
    "df = df.set_index('Process ID')\n",
    "\n",
    "df = df.mean(axis=1)\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.rename(columns={0: 'F1'})\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking_mean_proc.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrame\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking.csv')\n",
    "\n",
    "# Strip any leading/trailing spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Plot the DataFrame as a barplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['Process ID'], df['TD2C_R'], color=colors)\n",
    "plt.title('Mean F1 scores for TD2C_Ranking processes, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Process ID')\n",
    "plt.ylabel('Mean F1')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PDF in the folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/f1_barplot_TD2C_Ranking_mean_proc.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking.csv')\n",
    "\n",
    "# now average the results for each process\n",
    "df = df.mean()\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.rename(columns={'index': 'method', 0: 'f1'})\n",
    "\n",
    "df = df.sort_values(by='f1', ascending=False)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# drop Process ID 0 row\n",
    "df = df.drop(0)\n",
    "\n",
    "# save the dataframe to a csv file to folder\n",
    "df.to_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking_avg.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframe from the csv file\n",
    "df = pd.read_csv('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/metrics/f1_td2c_ranking_avg.csv')\n",
    "\n",
    "# Plotting Barplot for methods for indexes 1 to 6\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['method'], df['f1'], color=colors)\n",
    "plt.xticks(rotation=-90)\n",
    "plt.title('Mean F1 scores for TD2C_Ranking methods, with Regression to estimate MI (5 variables processes)')\n",
    "plt.xlabel('Methods')\n",
    "plt.ylabel('Mean F1')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the plot as a pdf in folder\n",
    "plt.savefig('/home/jpalombarini/td2c/notebooks/contributions/td2c_extesions/results/Regression/plots/f1_barplot_TD2C_Ranking_avg.pdf')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
