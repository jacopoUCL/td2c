{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "\n",
    "from d2c.benchmark import D2CWrapper\n",
    "\n",
    "from d2c.descriptors.loader import DataLoader\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/jpalombarini/td2c/notebooks/contributions/Real_data_validation/model (2).pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHOOSE THE BEST WAY TO LOAD THE DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# immport numpy\n",
    "def load_data(filepath):\n",
    "    data = np.loadtxt(filepath)\n",
    "    return data\n",
    "\n",
    "names = ['ex.txt', 'ex copy.txt', 'ex copy 2.txt']\n",
    "ts_list = [load_data(os.path.join('/home/jpalombarini/td2c/notebooks/contributions/Real_data_validation/useful_data', name)) for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas\n",
    "\n",
    "def load_data(filepath):\n",
    "    data = pd.read_csv(filepath, delimiter=',', header=None).values\n",
    "    return data\n",
    "\n",
    "names = ['preprocessed_1.pkl', 'preprocessed_2.pkl']\n",
    "ts_list = [load_data(os.path.join('/home/jpalombarini/td2c/notebooks/contributions/Real_data_validation/useful_data', name)) for name in names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import in the same way but from pickle\n",
    "def load_data(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "# Example usage\n",
    "\n",
    "names = ['P1_N5_Nj2_n0.01.pkl', 'P2_N5_Nj2_n0.01.pkl', 'P3_N5_Nj2_n0.01.pkl']\n",
    "ts_list = [load_data(os.path.join('/home/jpalombarini/td2c/notebooks/contributions/Real_data_validation/useful_data', name)) for name in names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_data(data):\n",
    "    for i, col in enumerate(data.T):\n",
    "        unique_values = np.unique(col)\n",
    "        if len(unique_values) == 1:\n",
    "            print(f\"Column {i} is constant with value {unique_values[0]}.\")\n",
    "        elif len(unique_values) == 0:\n",
    "            print(f\"Column {i} is empty.\")\n",
    "\n",
    "for ts in ts_list:\n",
    "    inspect_data(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove first row of each ts\n",
    "ts_list = [ts[1:] for ts in ts_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numeric each ts\n",
    "ts_list = [ts.astype(float) for ts in ts_list]\n",
    "\n",
    "# remove rows with NaNs\n",
    "ts_list = [ts[~np.isnan(ts).any(axis=1)] for ts in ts_list]\n",
    "\n",
    "# remove columns with empty values\n",
    "ts_list = [ts[:, ~np.all(np.isnan(ts), axis=0)] for ts in ts_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_list[0].shape, ts_list[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ts in enumerate(ts_list):\n",
    "    print(f\"Inspecting time series {i+1}:\")\n",
    "    print(ts.dtype)  # Check the data type of the array\n",
    "    print(ts[:5])  # Print the first few rows to inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_std(data):\n",
    "    for i, col in enumerate(data.T):\n",
    "        if np.std(col) == 0:\n",
    "            print(f\"Warning: Column {i} has zero standard deviation.\")\n",
    "\n",
    "for ts in ts_list:\n",
    "    check_std(ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    std_dev = np.std(data, axis=0)\n",
    "    # Avoid division by zero\n",
    "    std_dev[std_dev == 0] = 1\n",
    "    return (data - np.mean(data, axis=0)) / std_dev\n",
    "\n",
    "# Apply this normalization before passing the data to the model\n",
    "ts_list = [normalize_data(ts) for ts in ts_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_dict = dict(zip(names, ts_list))\n",
    "for key, value in ts_dict.items():\n",
    "    print(key, value.shape)\n",
    "\n",
    "# save first dim of each ts in a list named 'maxlags'\n",
    "maxlags = [ts.shape[0] for ts in ts_list]\n",
    "\n",
    "# save second dim of each ts in a list named 'n_variables'\n",
    "n_variables = [ts.shape[1] for ts in ts_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2cwrapper = D2CWrapper(ts_list=ts_list, \n",
    "                        n_variables=n_variables[0], \n",
    "                        model=model, \n",
    "                        maxlags=maxlags[0], \n",
    "                        n_jobs=1, \n",
    "                        full=True, \n",
    "                        quantiles=True,\n",
    "                        filename='d2c_results',\n",
    "                        normalize=True, \n",
    "                        cmi='original', \n",
    "                        mb_estimator='original')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2cwrapper.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_df = d2cwrapper.get_causal_dfs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
